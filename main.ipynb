{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6697157b-c721-4209-8844-4e9a96b04103",
   "metadata": {},
   "source": [
    "Dataset: https://www.kaggle.com/datasets/sbhatti/financial-sentiment-analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb08fe1c-7084-4b52-b42b-908e131633ff",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def read_csv(fname: str) -> pd.DataFrame:\n",
    "    return pd.read_csv(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1776e80c-5faf-4ce9-bc9b-1ea8ff9dd56c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The GeoSolutions technology will leverage Bene...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>$ESI on lows, down $1.50 to $2.50 BK a real po...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>For the last quarter of 2010 , Componenta 's n...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>According to the Finnish-Russian Chamber of Co...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Swedish buyout firm has sold its remaining...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Sentence Sentiment\n",
       "0  The GeoSolutions technology will leverage Bene...  positive\n",
       "1  $ESI on lows, down $1.50 to $2.50 BK a real po...  negative\n",
       "2  For the last quarter of 2010 , Componenta 's n...  positive\n",
       "3  According to the Finnish-Russian Chamber of Co...   neutral\n",
       "4  The Swedish buyout firm has sold its remaining...   neutral"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = read_csv('data.csv')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "973c4b29-9ca1-44d4-9b73-23ae0081313a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5842</td>\n",
       "      <td>5842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>5322</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Operating loss totalled EUR 0.9 mn , down from...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>2</td>\n",
       "      <td>3130</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Sentence Sentiment\n",
       "count                                                5842      5842\n",
       "unique                                               5322         3\n",
       "top     Operating loss totalled EUR 0.9 mn , down from...   neutral\n",
       "freq                                                    2      3130"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7ebb932c-4147-4ef0-9908-1a3197475e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(fname: str) -> tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    data = read_csv(fname)\n",
    "    return data.Sentence, data.Sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "705c31c9-5f2c-4670-a616-fc37a2e0915b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentiment\n",
       "neutral     0.535775\n",
       "positive    0.317015\n",
       "negative    0.147210\n",
       "Name: count, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = read_data('data.csv')\n",
    "(y.value_counts() / y.size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cae7e6d0-c325-4923-8606-85920b5d3434",
   "metadata": {},
   "source": [
    "Traditional ML models can handle string output, but deep learning models require numeric output. Some loss functions (f1) actually require one-hot encoded, but we'll just use some other loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "737089eb-73fa-4d9c-b519-ff16a9686194",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e8f33447-b2e9-4fd4-b305-253670c83286",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['negative', 'neutral', 'positive'], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_encoder.inverse_transform([0, 1, 2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e6a0e5b-a3eb-4e8d-b8c3-ef54e9ae7dd3",
   "metadata": {},
   "source": [
    "We can use class weights (= inverse of the distribution) to train our models should we wish to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d4e78dc3-10c3-4e67-b666-34e20bd01bc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: np.float64(6.793023255813953),\n",
       " 1: np.float64(1.8664536741214057),\n",
       " 2: np.float64(3.1544276457883367)}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DISTRIBUTION = { i: (y == i).sum() / y.size for i in [0, 1, 2] }\n",
    "CLASS_WEIGHTS = { i: 1 / DISTRIBUTION[i] for i in [0, 1, 2] }\n",
    "CLASS_WEIGHTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "813fe934-342d-49b6-ba18-29561f30f64b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b76d5d8-df3e-4ba0-a30c-5060f3fb3b83",
   "metadata": {},
   "source": [
    "Let's extract a test dataset and put it away."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "30e466dd-bd73-434a-9f61-aea03f7ef423",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "TEST_SPLIT = 0.1\n",
    "VALIDATION_SPLIT = 0.15\n",
    "\n",
    "X, X_test, y, y_test = train_test_split(X, y, random_state=0, stratify=y, test_size=TEST_SPLIT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a97bddf1-be81-49af-b574-7d3d4f3ba925",
   "metadata": {},
   "source": [
    "### Evalution - Scoring Methods\n",
    "\n",
    "Choice of metric depends on how we plan to use this model. Note that this is imbalanced classification, so plain accuracy might not be the best metric. Since there's no specific goal in mind, I'm looking at a bunch of metrics to get an overall evaluation of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "19bed9c0-5cce-4bdd-a483-4355c7e1e883",
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "\n",
    "class ScoringMethod(Enum):\n",
    "    CLASSIFICATION_REPORT = 0\n",
    "    CONFUSION_MATRIX = 1\n",
    "    CROSS_VAL_SCORE = 2\n",
    "    SUMMARY = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9876ae95-4f73-45d1-815d-2a14fb1873f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    balanced_accuracy_score,\n",
    "    f1_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    cohen_kappa_score,\n",
    ")\n",
    "\n",
    "def custom_summary(y_val: np.ndarray, y_pred: np.ndarray) -> dict[str, float]:\n",
    "    return {\n",
    "        \"accuracy\": accuracy_score(y_val, y_pred),\n",
    "        \"balanced_accuracy\": float(balanced_accuracy_score(y_val, y_pred)),\n",
    "        \"f1_macro\": float(f1_score(y_val, y_pred, average=\"macro\")),\n",
    "        \"f1_weighted\": float(f1_score(y_val, y_pred, average=\"weighted\")),\n",
    "        \"precision_weighted\": float(precision_score(y_val, y_pred, average=\"weighted\")),\n",
    "        \"cohen_kappa\": float(cohen_kappa_score(y_val, y_pred, weights=\"linear\")),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d0f8f28d-4a72-450d-b645-858e0b3840bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, cross_validate, StratifiedKFold\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "METRICS = (\n",
    "    \"accuracy\",\n",
    "    \"balanced_accuracy\",\n",
    "    \"f1_macro\",\n",
    "    \"f1_weighted\",\n",
    "    \"precision_weighted\",\n",
    ")\n",
    "\n",
    "def score(model,\n",
    "          X: np.ndarray,\n",
    "          y: np.ndarray,\n",
    "          method: ScoringMethod = ScoringMethod.CROSS_VAL_SCORE,\n",
    "          scoring: str = \"balanced_accuracy\"):\n",
    "\n",
    "    if method == ScoringMethod.CROSS_VAL_SCORE:\n",
    "        results = cross_validate(model, X, y, scoring=METRICS, cv=3, n_jobs=-1)\n",
    "        return {\n",
    "            f\"cv_{metric}\": results[f\"test_{metric}\"].mean()\n",
    "            for metric in METRICS\n",
    "        }\n",
    "\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X,\n",
    "                                                      y,\n",
    "                                                      random_state=0,\n",
    "                                                      stratify=y,\n",
    "                                                      test_size=VALIDATION_SPLIT)\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_val)\n",
    "\n",
    "    return {\n",
    "        ScoringMethod.CLASSIFICATION_REPORT: classification_report,\n",
    "        ScoringMethod.CONFUSION_MATRIX: confusion_matrix,\n",
    "        ScoringMethod.SUMMARY: custom_summary,\n",
    "    }.get(method)(y_val, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1ad4b9a4-9b05-4c61-932e-f41017c2dac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "def plot_confusion_matrix(confusion_matrix: np.ndarray):\n",
    "    ConfusionMatrixDisplay(confusion_matrix, display_labels=model.classes_).plot() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff80143b-f78d-4078-9660-093c57fbf779",
   "metadata": {},
   "source": [
    "### Extremely Basic Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9cde0cdd-67a2-40b5-b5a2-ea8d2b09bb91",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator\n",
    "\n",
    "class RandomModel(BaseEstimator):\n",
    "    def fit(self, X, y=None):\n",
    "        if y is None:\n",
    "            self.distribution = { 0: 1/3, 1: 1/3, 2: 1/3 }\n",
    "        else:\n",
    "            n = y.size\n",
    "            self.distribution = {\n",
    "                i: (y == i).sum() / n\n",
    "                for i in [0, 1, 2]\n",
    "            }\n",
    "\n",
    "    def predict(self, X):\n",
    "        return pd.Series(np.random.choice(\n",
    "            list(self.distribution.keys()),\n",
    "            size=X.size,\n",
    "            p=list(self.distribution.values())\n",
    "        ), name = \"Sentiment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e5eb87a1-67e3-4078-a0ec-53ef16d3494c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 12,  62,  42],\n",
       "       [ 69, 225, 129],\n",
       "       [ 40, 138,  72]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score(RandomModel(), X, y, ScoringMethod.CONFUSION_MATRIX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "76a07468-8666-4658-ad8d-022c81e450d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.39923954372623577,\n",
       " 'balanced_accuracy': 0.30889008450857314,\n",
       " 'f1_macro': 0.3083160697178291,\n",
       " 'f1_weighted': 0.3970393223392711,\n",
       " 'precision_weighted': 0.39492872102437837,\n",
       " 'cohen_kappa': -0.04282117662133644}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score(RandomModel(), X, y, ScoringMethod.SUMMARY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "df236f6f-e2fb-4065-af9d-52ede3a77228",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SingleSentimentModel(BaseEstimator):\n",
    "    def __init__(self, sentiment: int = 0):\n",
    "        self.sentiment = sentiment\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        pass\n",
    "\n",
    "    def predict(self, X):\n",
    "        return [self.sentiment] * X.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "47740cb0-7a70-4a6f-b8c1-ea17e39a90d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.5361216730038023,\n",
       " 'balanced_accuracy': 0.3333333333333333,\n",
       " 'f1_macro': 0.23267326732673266,\n",
       " 'f1_weighted': 0.37422354402740654,\n",
       " 'precision_weighted': 0.2874264482643959,\n",
       " 'cohen_kappa': 0.0}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score(SingleSentimentModel(sentiment=1), X, y, ScoringMethod.SUMMARY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e29918c-a147-47ed-a703-3d271b74d4b1",
   "metadata": {},
   "source": [
    "As noted earlier, accuracy might not be the best metric as this is an imbalanced classification. We see that picking neutral for everything gives us a better accuracy than picking a random sentiment, but is worse according to every other metric."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "646c0aee-05a0-411b-b508-45d9e2a46c4d",
   "metadata": {},
   "source": [
    "## Text processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f7342daa-a1b3-4714-993c-3c992eef0221",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/recurze/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /home/recurze/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/recurze/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/recurze/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
      "[nltk_data]     /home/recurze/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package universal_tagset to\n",
      "[nltk_data]     /home/recurze/nltk_data...\n",
      "[nltk_data]   Package universal_tagset is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "nltk.download(\"punkt\")  # stemmer\n",
    "nltk.download(\"punkt_tab\")  # word_tokenize\n",
    "nltk.download(\"stopwords\")\n",
    "nltk.download(\"wordnet\")  # lemmatizer\n",
    "nltk.download('averaged_perceptron_tagger_eng') # pos_tag\n",
    "nltk.download('universal_tagset')  # pos_tag"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "082e833e-ca79-449e-8f4f-05b941f72f70",
   "metadata": {},
   "source": [
    "#### Preprocessor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89c5d7c6-b0e7-435d-a4c9-1a238ebe12e8",
   "metadata": {},
   "source": [
    "Clean up code by removing some unwanted elements and lowercasing the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "78db03f7-d859-42da-a014-f7ff8b776c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def preprocessor(text: str) -> str:\n",
    "    regex_url = r\"(http|www)\\S+\"\n",
    "    regex_twitter_mentions = r\"@\\w+\"\n",
    "    regex_ticker = r\"\\$[A-Za-z]{1,5}(\\.[A-Za-z]{1,3})?\"\n",
    "    regex_punctuation = r\"[^\\w\\s']+\"\n",
    "\n",
    "    replacements = [\n",
    "        (regex_url, \"\"),\n",
    "        (regex_twitter_mentions, \"\"),\n",
    "        #(regex_ticker, \"\"),\n",
    "        #(regex_punctuation, \"\"),\n",
    "    ]\n",
    "\n",
    "    text = text.lower()\n",
    "    for pattern, replacement in replacements:\n",
    "        text = re.sub(pattern, replacement, text)\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0d7f43c3-410b-4d67-af21-654bd92e28ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('$STX long play, another consistent profit zone.. check it out https://t.co/DQfuzOzYlh https://t.co/ggne4ayzqn',\n",
       " '$stx long play, another consistent profit zone.. check it out  ')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[1000], preprocessor(X[1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "85141e63-6a6d-4c16-b53c-52efe0a0e21a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Finnish fibers and plastic products maker Suominen Corporation said its net loss from continuing operations narrowed to 1.8 mln euro ( $ 2.3 mln ) in 2006 from 3.7 mln euro ( $ 4.8 mln ) in 2005 .',\n",
       " 'finnish fibers and plastic products maker suominen corporation said its net loss from continuing operations narrowed to 1.8 mln euro ( $ 2.3 mln ) in 2006 from 3.7 mln euro ( $ 4.8 mln ) in 2005 .')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[3147], preprocessor(X[3147])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88e9059c-1ab9-4ed4-a3ea-1ce515998044",
   "metadata": {},
   "source": [
    "#### StemTokenizer\n",
    "\n",
    "See https://en.wikipedia.org/wiki/Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7a1858c3-5019-47c5-8207-689ab7d22578",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('For 2009 , net profit was EUR 3 million and the company paid a dividend of EUR 1.30 apiece .',\n",
       " ['for',\n",
       "  '2009',\n",
       "  ',',\n",
       "  'net',\n",
       "  'profit',\n",
       "  'wa',\n",
       "  'eur',\n",
       "  '3',\n",
       "  'million',\n",
       "  'and',\n",
       "  'the',\n",
       "  'compani',\n",
       "  'paid',\n",
       "  'a',\n",
       "  'dividend',\n",
       "  'of',\n",
       "  'eur',\n",
       "  '1.30',\n",
       "  'apiec',\n",
       "  '.'])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "class StemTokenizer:\n",
    "    # https://scikit-learn.org/stable/modules/feature_extraction.html#customizing-the-vectorizer-classes\n",
    "\n",
    "    def __init__(self):\n",
    "        self.stemmer = PorterStemmer()\n",
    "\n",
    "    def __call__(self, text: str) -> list[str]:\n",
    "        return [self.stemmer.stem(token) for token in nltk.word_tokenize(text)]\n",
    "\n",
    "X[1], StemTokenizer()(preprocessor(X[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff1a87b5-83c9-45f5-8edc-6fb27e8b8442",
   "metadata": {},
   "source": [
    "#### LemmaTokenizer\n",
    "\n",
    "See https://en.wikipedia.org/wiki/Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ad6a6b20-9cc5-4cb7-a851-b9b211364cdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('For 2009 , net profit was EUR 3 million and the company paid a dividend of EUR 1.30 apiece .',\n",
       " ['for',\n",
       "  '2009',\n",
       "  ',',\n",
       "  'net',\n",
       "  'profit',\n",
       "  'be',\n",
       "  'eur',\n",
       "  '3',\n",
       "  'million',\n",
       "  'and',\n",
       "  'the',\n",
       "  'company',\n",
       "  'pay',\n",
       "  'a',\n",
       "  'dividend',\n",
       "  'of',\n",
       "  'eur',\n",
       "  '1.30',\n",
       "  'apiece',\n",
       "  '.'])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "\n",
    "class LemmaTokenizer:\n",
    "    # https://scikit-learn.org/stable/modules/feature_extraction.html#customizing-the-vectorizer-classes\n",
    "\n",
    "    def __init__(self):\n",
    "        self.lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "    def __call__(self, text: str) -> list[str]:\n",
    "        # https://github.com/slavpetrov/universal-pos-tags\n",
    "        # https://www.nltk.org/api/nltk.stem.wordnet.html#nltk.stem.wordnet.WordNetLemmatizer.lemmatize\n",
    "\n",
    "        tagged_tokens = nltk.pos_tag(nltk.word_tokenize(text), tagset=\"universal\")\n",
    "        pos_tag_map = { \"VERB\": 'v', \"ADJ\": 'a', \"ADV\": 'r' }\n",
    "        return [\n",
    "            self.lemmatizer.lemmatize(token, pos=pos_tag_map.get(pos, 'n'))\n",
    "            for token, pos in tagged_tokens\n",
    "        ]\n",
    "\n",
    "X[1], LemmaTokenizer()(preprocessor(X[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a47b980a-0e48-429c-8e71-66bd49fda5c8",
   "metadata": {},
   "source": [
    "#### Stop Words\n",
    "\n",
    "Common words like \"a\" and \"the\" are present in most text, but do not provide any information about the sentiment of the text. Such words are called stop words. We may as well remove them. Note, however, that \"not\" is also in the list of stop words. So blindly removing stop words might not be a good idea (take this sentence for example: removing not negates the intended meaning)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1438c429-ca1a-4cd0-a577-9fda3e20f691",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "STOPWORDS = stopwords.words('english')\n",
    "\n",
    "'not' in STOPWORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "35694949-e9e9-4bef-959e-747ad88f60af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    }
   ],
   "source": [
    "print(STOPWORDS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c8b0da6-758e-4e7d-87c4-de811a877a8e",
   "metadata": {},
   "source": [
    "We want to remove stop words but not negation words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a46768fb-f9b9-4c44-9c7d-a5cc13e99c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "negation_words = [\n",
    "    \"aren't\", \"couldn't\", \"didn't\", \"doesn't\", \"don't\", \"hadn't\", \"hasn't\", \"haven't\", \"isn't\", \"mightn't\",\n",
    "    \"mustn't\", \"needn't\", \"shan't\", \"shouldn't\", \"wasn't\", \"weren't\", \"won't\", \"wouldn't\", 'above', 'after',\n",
    "    'against', 'ain', 'all', 'any', 'aren', 'before', 'below', 'but', 'couldn', 'didn',\n",
    "    'doesn', 'don', 'down', 'few', 'from', 'further', 'hadn', 'hasn', 'haven', 'in',\n",
    "    'isn', 'ma', 'mightn', 'more', 'most', 'mustn', 'needn', 'no', 'nor', 'not',\n",
    "    'off', 'on', 'only', 'out', 'over', 'shan', 'shouldn', 'some', 'such', 't',\n",
    "    'to', 'too', 'under', 'up', 'very', 'wasn', 'weren', 'won', 'wouldn',\n",
    "]\n",
    "\n",
    "# The additions are because stop_words need to be compatible with the tokenizers used\n",
    "LemmaSTOPWORDS = [word for word in STOPWORDS if word not in negation_words] +  [\"'d\", \"'ll\", \"'re\", \"'s\", \"'ve\"]\n",
    "StemSTOPWORDS = LemmaSTOPWORDS +  ['becau', 'becaus', 'doe', 'dure', 'ha', 'hi', 'onc', 'ourselv', 'themselv', 'thi', 'wa', 'whi', 'yourselv']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17576f9f-cc31-4785-85e4-6ca5f7908631",
   "metadata": {},
   "source": [
    "## Basic Vectorizers\n",
    "\n",
    "Input is text but machines like numbers. Let's convert the sentences into words into numbers.\n",
    "\n",
    "`CountVectorizer` gives us a matrix of token counts. It does not retain the order of the words. Each sentence is simply considered a bag-of-words (BOW) and nothing more.\n",
    "\n",
    "`TfidfVectorizer` gives us the Term Frequency (TF: how many times a word appears in a document) - Inverse Document Frequency (IDF: how many documents a particular word appears in)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8f025c58-d67a-46c1-8f99-f2c88fbabe3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_a7700_row3_col1, #T_a7700_row5_col2, #T_a7700_row5_col3, #T_a7700_row12_col0, #T_a7700_row12_col4 {\n",
       "  background-color: green;\n",
       "}\n",
       "#T_a7700_row6_col0, #T_a7700_row6_col4, #T_a7700_row14_col1, #T_a7700_row14_col2, #T_a7700_row14_col3 {\n",
       "  background-color: red;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_a7700\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_a7700_level0_col0\" class=\"col_heading level0 col0\" >cv_accuracy</th>\n",
       "      <th id=\"T_a7700_level0_col1\" class=\"col_heading level0 col1\" >cv_balanced_accuracy</th>\n",
       "      <th id=\"T_a7700_level0_col2\" class=\"col_heading level0 col2\" >cv_f1_macro</th>\n",
       "      <th id=\"T_a7700_level0_col3\" class=\"col_heading level0 col3\" >cv_f1_weighted</th>\n",
       "      <th id=\"T_a7700_level0_col4\" class=\"col_heading level0 col4\" >cv_precision_weighted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_a7700_level0_row0\" class=\"row_heading level0 row0\" >cv / logisitic</th>\n",
       "      <td id=\"T_a7700_row0_col0\" class=\"data row0 col0\" >0.680047</td>\n",
       "      <td id=\"T_a7700_row0_col1\" class=\"data row0 col1\" >0.577015</td>\n",
       "      <td id=\"T_a7700_row0_col2\" class=\"data row0 col2\" >0.582860</td>\n",
       "      <td id=\"T_a7700_row0_col3\" class=\"data row0 col3\" >0.671563</td>\n",
       "      <td id=\"T_a7700_row0_col4\" class=\"data row0 col4\" >0.667795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a7700_level0_row1\" class=\"row_heading level0 row1\" >cv+pre / logisitic</th>\n",
       "      <td id=\"T_a7700_row1_col0\" class=\"data row1 col0\" >0.679287</td>\n",
       "      <td id=\"T_a7700_row1_col1\" class=\"data row1 col1\" >0.577971</td>\n",
       "      <td id=\"T_a7700_row1_col2\" class=\"data row1 col2\" >0.583448</td>\n",
       "      <td id=\"T_a7700_row1_col3\" class=\"data row1 col3\" >0.670873</td>\n",
       "      <td id=\"T_a7700_row1_col4\" class=\"data row1 col4\" >0.666957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a7700_level0_row2\" class=\"row_heading level0 row2\" >cv+stem / logisitic</th>\n",
       "      <td id=\"T_a7700_row2_col0\" class=\"data row2 col0\" >0.699451</td>\n",
       "      <td id=\"T_a7700_row2_col1\" class=\"data row2 col1\" >0.598691</td>\n",
       "      <td id=\"T_a7700_row2_col2\" class=\"data row2 col2\" >0.604167</td>\n",
       "      <td id=\"T_a7700_row2_col3\" class=\"data row2 col3\" >0.692112</td>\n",
       "      <td id=\"T_a7700_row2_col4\" class=\"data row2 col4\" >0.688358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a7700_level0_row3\" class=\"row_heading level0 row3\" >cv+pre+stem / logisitic</th>\n",
       "      <td id=\"T_a7700_row3_col0\" class=\"data row3 col0\" >0.699832</td>\n",
       "      <td id=\"T_a7700_row3_col1\" class=\"data row3 col1\" >0.601739</td>\n",
       "      <td id=\"T_a7700_row3_col2\" class=\"data row3 col2\" >0.607477</td>\n",
       "      <td id=\"T_a7700_row3_col3\" class=\"data row3 col3\" >0.692994</td>\n",
       "      <td id=\"T_a7700_row3_col4\" class=\"data row3 col4\" >0.689727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a7700_level0_row4\" class=\"row_heading level0 row4\" >cv+lemma / logisitic</th>\n",
       "      <td id=\"T_a7700_row4_col0\" class=\"data row4 col0\" >0.698501</td>\n",
       "      <td id=\"T_a7700_row4_col1\" class=\"data row4 col1\" >0.599306</td>\n",
       "      <td id=\"T_a7700_row4_col2\" class=\"data row4 col2\" >0.605259</td>\n",
       "      <td id=\"T_a7700_row4_col3\" class=\"data row4 col3\" >0.691680</td>\n",
       "      <td id=\"T_a7700_row4_col4\" class=\"data row4 col4\" >0.688557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a7700_level0_row5\" class=\"row_heading level0 row5\" >cv+pre+lemma / logisitic</th>\n",
       "      <td id=\"T_a7700_row5_col0\" class=\"data row5 col0\" >0.700593</td>\n",
       "      <td id=\"T_a7700_row5_col1\" class=\"data row5 col1\" >0.601723</td>\n",
       "      <td id=\"T_a7700_row5_col2\" class=\"data row5 col2\" >0.607820</td>\n",
       "      <td id=\"T_a7700_row5_col3\" class=\"data row5 col3\" >0.693634</td>\n",
       "      <td id=\"T_a7700_row5_col4\" class=\"data row5 col4\" >0.690449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a7700_level0_row6\" class=\"row_heading level0 row6\" >cv+pre+bigram / logisitic</th>\n",
       "      <td id=\"T_a7700_row6_col0\" class=\"data row6 col0\" >0.615751</td>\n",
       "      <td id=\"T_a7700_row6_col1\" class=\"data row6 col1\" >0.471664</td>\n",
       "      <td id=\"T_a7700_row6_col2\" class=\"data row6 col2\" >0.472975</td>\n",
       "      <td id=\"T_a7700_row6_col3\" class=\"data row6 col3\" >0.586592</td>\n",
       "      <td id=\"T_a7700_row6_col4\" class=\"data row6 col4\" >0.590977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a7700_level0_row7\" class=\"row_heading level0 row7\" >cv+pre+lemma+bigram / logisitic</th>\n",
       "      <td id=\"T_a7700_row7_col0\" class=\"data row7 col0\" >0.643715</td>\n",
       "      <td id=\"T_a7700_row7_col1\" class=\"data row7 col1\" >0.506603</td>\n",
       "      <td id=\"T_a7700_row7_col2\" class=\"data row7 col2\" >0.508633</td>\n",
       "      <td id=\"T_a7700_row7_col3\" class=\"data row7 col3\" >0.619840</td>\n",
       "      <td id=\"T_a7700_row7_col4\" class=\"data row7 col4\" >0.615127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a7700_level0_row8\" class=\"row_heading level0 row8\" >tfidf / logisitic</th>\n",
       "      <td id=\"T_a7700_row8_col0\" class=\"data row8 col0\" >0.705728</td>\n",
       "      <td id=\"T_a7700_row8_col1\" class=\"data row8 col1\" >0.561955</td>\n",
       "      <td id=\"T_a7700_row8_col2\" class=\"data row8 col2\" >0.566866</td>\n",
       "      <td id=\"T_a7700_row8_col3\" class=\"data row8 col3\" >0.675064</td>\n",
       "      <td id=\"T_a7700_row8_col4\" class=\"data row8 col4\" >0.682156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a7700_level0_row9\" class=\"row_heading level0 row9\" >tfidf+pre / logisitic</th>\n",
       "      <td id=\"T_a7700_row9_col0\" class=\"data row9 col0\" >0.700783</td>\n",
       "      <td id=\"T_a7700_row9_col1\" class=\"data row9 col1\" >0.559476</td>\n",
       "      <td id=\"T_a7700_row9_col2\" class=\"data row9 col2\" >0.565082</td>\n",
       "      <td id=\"T_a7700_row9_col3\" class=\"data row9 col3\" >0.671131</td>\n",
       "      <td id=\"T_a7700_row9_col4\" class=\"data row9 col4\" >0.678160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a7700_level0_row10\" class=\"row_heading level0 row10\" >tfidf+stem / logisitic</th>\n",
       "      <td id=\"T_a7700_row10_col0\" class=\"data row10 col0\" >0.717902</td>\n",
       "      <td id=\"T_a7700_row10_col1\" class=\"data row10 col1\" >0.577215</td>\n",
       "      <td id=\"T_a7700_row10_col2\" class=\"data row10 col2\" >0.583077</td>\n",
       "      <td id=\"T_a7700_row10_col3\" class=\"data row10 col3\" >0.689414</td>\n",
       "      <td id=\"T_a7700_row10_col4\" class=\"data row10 col4\" >0.693883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a7700_level0_row11\" class=\"row_heading level0 row11\" >tfidf+pre+stem / logisitic</th>\n",
       "      <td id=\"T_a7700_row11_col0\" class=\"data row11 col0\" >0.715619</td>\n",
       "      <td id=\"T_a7700_row11_col1\" class=\"data row11 col1\" >0.575237</td>\n",
       "      <td id=\"T_a7700_row11_col2\" class=\"data row11 col2\" >0.580872</td>\n",
       "      <td id=\"T_a7700_row11_col3\" class=\"data row11 col3\" >0.687359</td>\n",
       "      <td id=\"T_a7700_row11_col4\" class=\"data row11 col4\" >0.690867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a7700_level0_row12\" class=\"row_heading level0 row12\" >tfidf+lemma / logisitic</th>\n",
       "      <td id=\"T_a7700_row12_col0\" class=\"data row12 col0\" >0.719615</td>\n",
       "      <td id=\"T_a7700_row12_col1\" class=\"data row12 col1\" >0.580600</td>\n",
       "      <td id=\"T_a7700_row12_col2\" class=\"data row12 col2\" >0.588259</td>\n",
       "      <td id=\"T_a7700_row12_col3\" class=\"data row12 col3\" >0.692115</td>\n",
       "      <td id=\"T_a7700_row12_col4\" class=\"data row12 col4\" >0.697842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a7700_level0_row13\" class=\"row_heading level0 row13\" >tfidf+pre+lemma / logisitic</th>\n",
       "      <td id=\"T_a7700_row13_col0\" class=\"data row13 col0\" >0.718663</td>\n",
       "      <td id=\"T_a7700_row13_col1\" class=\"data row13 col1\" >0.578989</td>\n",
       "      <td id=\"T_a7700_row13_col2\" class=\"data row13 col2\" >0.586197</td>\n",
       "      <td id=\"T_a7700_row13_col3\" class=\"data row13 col3\" >0.690847</td>\n",
       "      <td id=\"T_a7700_row13_col4\" class=\"data row13 col4\" >0.696193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a7700_level0_row14\" class=\"row_heading level0 row14\" >tfidf+pre+bigram / logisitic</th>\n",
       "      <td id=\"T_a7700_row14_col0\" class=\"data row14 col0\" >0.618034</td>\n",
       "      <td id=\"T_a7700_row14_col1\" class=\"data row14 col1\" >0.444133</td>\n",
       "      <td id=\"T_a7700_row14_col2\" class=\"data row14 col2\" >0.432841</td>\n",
       "      <td id=\"T_a7700_row14_col3\" class=\"data row14 col3\" >0.557356</td>\n",
       "      <td id=\"T_a7700_row14_col4\" class=\"data row14 col4\" >0.611346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a7700_level0_row15\" class=\"row_heading level0 row15\" >tfidf+pre+lemma+bigram / logisitic</th>\n",
       "      <td id=\"T_a7700_row15_col0\" class=\"data row15 col0\" >0.653797</td>\n",
       "      <td id=\"T_a7700_row15_col1\" class=\"data row15 col1\" >0.484196</td>\n",
       "      <td id=\"T_a7700_row15_col2\" class=\"data row15 col2\" >0.477741</td>\n",
       "      <td id=\"T_a7700_row15_col3\" class=\"data row15 col3\" >0.603491</td>\n",
       "      <td id=\"T_a7700_row15_col4\" class=\"data row15 col4\" >0.629390</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x789779d308c0>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from itertools import product\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "classifiers = [(LogisticRegression(max_iter=200, n_jobs=-1), \"logisitic\")]\n",
    "vectorizers = [\n",
    "    (CountVectorizer(), \"cv\"),\n",
    "    (CountVectorizer(preprocessor=preprocessor), \"cv+pre\"),\n",
    "    (CountVectorizer(tokenizer=StemTokenizer(), token_pattern=None), \"cv+stem\"),\n",
    "    (CountVectorizer(preprocessor=preprocessor, tokenizer=StemTokenizer(), token_pattern=None), \"cv+pre+stem\"),\n",
    "    (CountVectorizer(tokenizer=LemmaTokenizer(), token_pattern=None), \"cv+lemma\"),\n",
    "    (CountVectorizer(preprocessor=preprocessor, tokenizer=LemmaTokenizer(), token_pattern=None), \"cv+pre+lemma\"),\n",
    "    \n",
    "    (CountVectorizer(preprocessor=preprocessor, ngram_range=(2, 2)), \"cv+pre+bigram\"),\n",
    "    (CountVectorizer(preprocessor=preprocessor, tokenizer=LemmaTokenizer(), token_pattern=None, ngram_range=(2, 2)), \"cv+pre+lemma+bigram\"),\n",
    "\n",
    "    (TfidfVectorizer(), \"tfidf\"),\n",
    "    (TfidfVectorizer(preprocessor=preprocessor), \"tfidf+pre\"),\n",
    "    (TfidfVectorizer(tokenizer=StemTokenizer(), token_pattern=None), \"tfidf+stem\"),\n",
    "    (TfidfVectorizer(preprocessor=preprocessor, tokenizer=StemTokenizer(), token_pattern=None), \"tfidf+pre+stem\"),\n",
    "    (TfidfVectorizer(tokenizer=LemmaTokenizer(), token_pattern=None), \"tfidf+lemma\"),\n",
    "    (TfidfVectorizer(preprocessor=preprocessor, tokenizer=LemmaTokenizer(), token_pattern=None), \"tfidf+pre+lemma\"),\n",
    "    \n",
    "    (TfidfVectorizer(preprocessor=preprocessor, ngram_range=(2, 2)), \"tfidf+pre+bigram\"),\n",
    "    (TfidfVectorizer(preprocessor=preprocessor, tokenizer=LemmaTokenizer(), token_pattern=None, ngram_range=(2, 2)), \"tfidf+pre+lemma+bigram\"),\n",
    "]\n",
    "\n",
    "restab = {}\n",
    "for (vectorizer, vec_name), (classifier, clf_name) in product(vectorizers, classifiers):\n",
    "    model = Pipeline([\n",
    "        (\"vectorizer\", vectorizer),\n",
    "        (\"classifier\", classifier),\n",
    "    ])\n",
    "    restab[f\"{vec_name} / {clf_name}\"] = score(model, X, y)\n",
    "\n",
    "pd.DataFrame(restab).T.style.highlight_max(color=\"green\", axis=0).highlight_min(color=\"red\", axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ca2859c-b9de-4434-89fc-9a4a8864c0f8",
   "metadata": {},
   "source": [
    "Turns out our custom preprocessor makes the models slightly slightly worse. We are removing more than we should. But do urls and usernames really contain valuable information? Lemmatization is better than Stemming but it's more time consuming. Bigrams are a let down though. But lemmatization helps bigrams."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab9b354d-d6a1-4029-9416-763d5d0f183a",
   "metadata": {},
   "source": [
    "## Basic Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d54f375e-f2ed-4895-b348-4a96287133dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_d7043_row1_col4, #T_d7043_row10_col0, #T_d7043_row14_col1, #T_d7043_row14_col2, #T_d7043_row14_col3 {\n",
       "  background-color: red;\n",
       "}\n",
       "#T_d7043_row7_col0, #T_d7043_row8_col1, #T_d7043_row8_col2, #T_d7043_row8_col3, #T_d7043_row15_col4 {\n",
       "  background-color: green;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_d7043\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_d7043_level0_col0\" class=\"col_heading level0 col0\" >cv_accuracy</th>\n",
       "      <th id=\"T_d7043_level0_col1\" class=\"col_heading level0 col1\" >cv_balanced_accuracy</th>\n",
       "      <th id=\"T_d7043_level0_col2\" class=\"col_heading level0 col2\" >cv_f1_macro</th>\n",
       "      <th id=\"T_d7043_level0_col3\" class=\"col_heading level0 col3\" >cv_f1_weighted</th>\n",
       "      <th id=\"T_d7043_level0_col4\" class=\"col_heading level0 col4\" >cv_precision_weighted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_d7043_level0_row0\" class=\"row_heading level0 row0\" >tf+stem / rf</th>\n",
       "      <td id=\"T_d7043_row0_col0\" class=\"data row0 col0\" >0.662167</td>\n",
       "      <td id=\"T_d7043_row0_col1\" class=\"data row0 col1\" >0.516634</td>\n",
       "      <td id=\"T_d7043_row0_col2\" class=\"data row0 col2\" >0.516029</td>\n",
       "      <td id=\"T_d7043_row0_col3\" class=\"data row0 col3\" >0.634756</td>\n",
       "      <td id=\"T_d7043_row0_col4\" class=\"data row0 col4\" >0.627652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d7043_level0_row1\" class=\"row_heading level0 row1\" >tf+lemma / rf</th>\n",
       "      <td id=\"T_d7043_row1_col0\" class=\"data row1 col0\" >0.662928</td>\n",
       "      <td id=\"T_d7043_row1_col1\" class=\"data row1 col1\" >0.516119</td>\n",
       "      <td id=\"T_d7043_row1_col2\" class=\"data row1 col2\" >0.514607</td>\n",
       "      <td id=\"T_d7043_row1_col3\" class=\"data row1 col3\" >0.634515</td>\n",
       "      <td id=\"T_d7043_row1_col4\" class=\"data row1 col4\" >0.626854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d7043_level0_row2\" class=\"row_heading level0 row2\" >tf+stem / gbc</th>\n",
       "      <td id=\"T_d7043_row2_col0\" class=\"data row2 col0\" >0.709913</td>\n",
       "      <td id=\"T_d7043_row2_col1\" class=\"data row2 col1\" >0.578278</td>\n",
       "      <td id=\"T_d7043_row2_col2\" class=\"data row2 col2\" >0.587098</td>\n",
       "      <td id=\"T_d7043_row2_col3\" class=\"data row2 col3\" >0.686592</td>\n",
       "      <td id=\"T_d7043_row2_col4\" class=\"data row2 col4\" >0.687472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d7043_level0_row3\" class=\"row_heading level0 row3\" >tf+lemma / gbc</th>\n",
       "      <td id=\"T_d7043_row3_col0\" class=\"data row3 col0\" >0.711624</td>\n",
       "      <td id=\"T_d7043_row3_col1\" class=\"data row3 col1\" >0.581723</td>\n",
       "      <td id=\"T_d7043_row3_col2\" class=\"data row3 col2\" >0.591279</td>\n",
       "      <td id=\"T_d7043_row3_col3\" class=\"data row3 col3\" >0.688979</td>\n",
       "      <td id=\"T_d7043_row3_col4\" class=\"data row3 col4\" >0.690511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d7043_level0_row4\" class=\"row_heading level0 row4\" >tf+stem / ridge_sparse</th>\n",
       "      <td id=\"T_d7043_row4_col0\" class=\"data row4 col0\" >0.705538</td>\n",
       "      <td id=\"T_d7043_row4_col1\" class=\"data row4 col1\" >0.590454</td>\n",
       "      <td id=\"T_d7043_row4_col2\" class=\"data row4 col2\" >0.596942</td>\n",
       "      <td id=\"T_d7043_row4_col3\" class=\"data row4 col3\" >0.691499</td>\n",
       "      <td id=\"T_d7043_row4_col4\" class=\"data row4 col4\" >0.686424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d7043_level0_row5\" class=\"row_heading level0 row5\" >tf+lemma / ridge_sparse</th>\n",
       "      <td id=\"T_d7043_row5_col0\" class=\"data row5 col0\" >0.705729</td>\n",
       "      <td id=\"T_d7043_row5_col1\" class=\"data row5 col1\" >0.589687</td>\n",
       "      <td id=\"T_d7043_row5_col2\" class=\"data row5 col2\" >0.596744</td>\n",
       "      <td id=\"T_d7043_row5_col3\" class=\"data row5 col3\" >0.691827</td>\n",
       "      <td id=\"T_d7043_row5_col4\" class=\"data row5 col4\" >0.687117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d7043_level0_row6\" class=\"row_heading level0 row6\" >tf+stem / logistic</th>\n",
       "      <td id=\"T_d7043_row6_col0\" class=\"data row6 col0\" >0.717902</td>\n",
       "      <td id=\"T_d7043_row6_col1\" class=\"data row6 col1\" >0.577215</td>\n",
       "      <td id=\"T_d7043_row6_col2\" class=\"data row6 col2\" >0.583077</td>\n",
       "      <td id=\"T_d7043_row6_col3\" class=\"data row6 col3\" >0.689414</td>\n",
       "      <td id=\"T_d7043_row6_col4\" class=\"data row6 col4\" >0.693883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d7043_level0_row7\" class=\"row_heading level0 row7\" >tf+lemma / logistic</th>\n",
       "      <td id=\"T_d7043_row7_col0\" class=\"data row7 col0\" >0.719615</td>\n",
       "      <td id=\"T_d7043_row7_col1\" class=\"data row7 col1\" >0.580600</td>\n",
       "      <td id=\"T_d7043_row7_col2\" class=\"data row7 col2\" >0.588259</td>\n",
       "      <td id=\"T_d7043_row7_col3\" class=\"data row7 col3\" >0.692115</td>\n",
       "      <td id=\"T_d7043_row7_col4\" class=\"data row7 col4\" >0.697842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d7043_level0_row8\" class=\"row_heading level0 row8\" >tf+stem / linear_svc</th>\n",
       "      <td id=\"T_d7043_row8_col0\" class=\"data row8 col0\" >0.702684</td>\n",
       "      <td id=\"T_d7043_row8_col1\" class=\"data row8 col1\" >0.598054</td>\n",
       "      <td id=\"T_d7043_row8_col2\" class=\"data row8 col2\" >0.603595</td>\n",
       "      <td id=\"T_d7043_row8_col3\" class=\"data row8 col3\" >0.693049</td>\n",
       "      <td id=\"T_d7043_row8_col4\" class=\"data row8 col4\" >0.688135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d7043_level0_row9\" class=\"row_heading level0 row9\" >tf+lemma / linear_svc</th>\n",
       "      <td id=\"T_d7043_row9_col0\" class=\"data row9 col0\" >0.700403</td>\n",
       "      <td id=\"T_d7043_row9_col1\" class=\"data row9 col1\" >0.597542</td>\n",
       "      <td id=\"T_d7043_row9_col2\" class=\"data row9 col2\" >0.603185</td>\n",
       "      <td id=\"T_d7043_row9_col3\" class=\"data row9 col3\" >0.691860</td>\n",
       "      <td id=\"T_d7043_row9_col4\" class=\"data row9 col4\" >0.687369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d7043_level0_row10\" class=\"row_heading level0 row10\" >tf+stem / kNN</th>\n",
       "      <td id=\"T_d7043_row10_col0\" class=\"data row10 col0\" >0.641430</td>\n",
       "      <td id=\"T_d7043_row10_col1\" class=\"data row10 col1\" >0.540765</td>\n",
       "      <td id=\"T_d7043_row10_col2\" class=\"data row10 col2\" >0.547382</td>\n",
       "      <td id=\"T_d7043_row10_col3\" class=\"data row10 col3\" >0.632550</td>\n",
       "      <td id=\"T_d7043_row10_col4\" class=\"data row10 col4\" >0.632875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d7043_level0_row11\" class=\"row_heading level0 row11\" >tf+lemma / kNN</th>\n",
       "      <td id=\"T_d7043_row11_col0\" class=\"data row11 col0\" >0.642571</td>\n",
       "      <td id=\"T_d7043_row11_col1\" class=\"data row11 col1\" >0.541970</td>\n",
       "      <td id=\"T_d7043_row11_col2\" class=\"data row11 col2\" >0.548968</td>\n",
       "      <td id=\"T_d7043_row11_col3\" class=\"data row11 col3\" >0.632862</td>\n",
       "      <td id=\"T_d7043_row11_col4\" class=\"data row11 col4\" >0.633425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d7043_level0_row12\" class=\"row_heading level0 row12\" >tf+stem / rocchio</th>\n",
       "      <td id=\"T_d7043_row12_col0\" class=\"data row12 col0\" >0.645616</td>\n",
       "      <td id=\"T_d7043_row12_col1\" class=\"data row12 col1\" >0.577255</td>\n",
       "      <td id=\"T_d7043_row12_col2\" class=\"data row12 col2\" >0.574434</td>\n",
       "      <td id=\"T_d7043_row12_col3\" class=\"data row12 col3\" >0.645487</td>\n",
       "      <td id=\"T_d7043_row12_col4\" class=\"data row12 col4\" >0.650439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d7043_level0_row13\" class=\"row_heading level0 row13\" >tf+lemma / rocchio</th>\n",
       "      <td id=\"T_d7043_row13_col0\" class=\"data row13 col0\" >0.645235</td>\n",
       "      <td id=\"T_d7043_row13_col1\" class=\"data row13 col1\" >0.574980</td>\n",
       "      <td id=\"T_d7043_row13_col2\" class=\"data row13 col2\" >0.572755</td>\n",
       "      <td id=\"T_d7043_row13_col3\" class=\"data row13 col3\" >0.644514</td>\n",
       "      <td id=\"T_d7043_row13_col4\" class=\"data row13 col4\" >0.649034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d7043_level0_row14\" class=\"row_heading level0 row14\" >tf+stem / multinomial_nb</th>\n",
       "      <td id=\"T_d7043_row14_col0\" class=\"data row14 col0\" >0.648660</td>\n",
       "      <td id=\"T_d7043_row14_col1\" class=\"data row14 col1\" >0.461196</td>\n",
       "      <td id=\"T_d7043_row14_col2\" class=\"data row14 col2\" >0.440028</td>\n",
       "      <td id=\"T_d7043_row14_col3\" class=\"data row14 col3\" >0.576303</td>\n",
       "      <td id=\"T_d7043_row14_col4\" class=\"data row14 col4\" >0.707322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d7043_level0_row15\" class=\"row_heading level0 row15\" >tf+lemma / multinomial_nb</th>\n",
       "      <td id=\"T_d7043_row15_col0\" class=\"data row15 col0\" >0.649230</td>\n",
       "      <td id=\"T_d7043_row15_col1\" class=\"data row15 col1\" >0.461701</td>\n",
       "      <td id=\"T_d7043_row15_col2\" class=\"data row15 col2\" >0.441037</td>\n",
       "      <td id=\"T_d7043_row15_col3\" class=\"data row15 col3\" >0.576810</td>\n",
       "      <td id=\"T_d7043_row15_col4\" class=\"data row15 col4\" >0.716617</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7896eb451a30>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import RidgeClassifier, SGDClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier, NearestCentroid\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "classifiers = [\n",
    "    # trees\n",
    "    (RandomForestClassifier(n_jobs=-1), \"rf\"),\n",
    "    (GradientBoostingClassifier(), \"gbc\"),\n",
    "    # linear\n",
    "    (RidgeClassifier(solver=\"sparse_cg\"), \"ridge_sparse\"),\n",
    "    (LogisticRegression(n_jobs=-1), \"logistic\"),\n",
    "    # SVM\n",
    "    (LinearSVC(), \"linear_svc\"),\n",
    "    # Nearest neighbors\n",
    "    (KNeighborsClassifier(n_jobs=-1), \"kNN\"),\n",
    "    (NearestCentroid(), \"rocchio\"),\n",
    "    # Bayes\n",
    "    (MultinomialNB(), \"multinomial_nb\"),\n",
    "]\n",
    "\n",
    "vectorizers = [\n",
    "    (TfidfVectorizer(tokenizer=StemTokenizer(), token_pattern=None), \"tf+stem\"),\n",
    "    (TfidfVectorizer(tokenizer=LemmaTokenizer(), token_pattern=None), \"tf+lemma\"),\n",
    "]\n",
    "\n",
    "restab = {}\n",
    "for (classifier, clf_name), (vectorizer, vec_name) in product(classifiers, vectorizers):\n",
    "    model = Pipeline([\n",
    "        (\"vectorizer\", vectorizer),\n",
    "        (\"classifier\", classifier),\n",
    "    ])\n",
    "    restab[f\"{vec_name} / {clf_name}\"] = score(model, X, y)\n",
    "\n",
    "pd.DataFrame(restab).T.style.highlight_max(color=\"green\", axis=0).highlight_min(color=\"red\", axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e6aef54-5658-4ffd-a37c-e6ac766baa45",
   "metadata": {},
   "source": [
    "Logistic regression and SVMs are promising. Naive Bayes seems to have surprisingly good weighted precision compared to the best performing models while being terrible at every other metric."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ddcbce1-56f7-4ff3-96d0-92913de879e9",
   "metadata": {},
   "source": [
    "## Stop word removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7a9fa923-1259-4eef-b094-ee408414135e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_e457e_row0_col1, #T_e457e_row0_col2, #T_e457e_row0_col3, #T_e457e_row6_col0, #T_e457e_row14_col4 {\n",
       "  background-color: green;\n",
       "}\n",
       "#T_e457e_row9_col4, #T_e457e_row12_col0, #T_e457e_row12_col1, #T_e457e_row12_col2, #T_e457e_row12_col3 {\n",
       "  background-color: red;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_e457e\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_e457e_level0_col0\" class=\"col_heading level0 col0\" >cv_accuracy</th>\n",
       "      <th id=\"T_e457e_level0_col1\" class=\"col_heading level0 col1\" >cv_balanced_accuracy</th>\n",
       "      <th id=\"T_e457e_level0_col2\" class=\"col_heading level0 col2\" >cv_f1_macro</th>\n",
       "      <th id=\"T_e457e_level0_col3\" class=\"col_heading level0 col3\" >cv_f1_weighted</th>\n",
       "      <th id=\"T_e457e_level0_col4\" class=\"col_heading level0 col4\" >cv_precision_weighted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_e457e_level0_row0\" class=\"row_heading level0 row0\" >tf+stem / linear svc</th>\n",
       "      <td id=\"T_e457e_row0_col0\" class=\"data row0 col0\" >0.702684</td>\n",
       "      <td id=\"T_e457e_row0_col1\" class=\"data row0 col1\" >0.598054</td>\n",
       "      <td id=\"T_e457e_row0_col2\" class=\"data row0 col2\" >0.603595</td>\n",
       "      <td id=\"T_e457e_row0_col3\" class=\"data row0 col3\" >0.693049</td>\n",
       "      <td id=\"T_e457e_row0_col4\" class=\"data row0 col4\" >0.688135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e457e_level0_row1\" class=\"row_heading level0 row1\" >tf+stem+stop / linear svc</th>\n",
       "      <td id=\"T_e457e_row1_col0\" class=\"data row1 col0\" >0.696787</td>\n",
       "      <td id=\"T_e457e_row1_col1\" class=\"data row1 col1\" >0.592793</td>\n",
       "      <td id=\"T_e457e_row1_col2\" class=\"data row1 col2\" >0.598419</td>\n",
       "      <td id=\"T_e457e_row1_col3\" class=\"data row1 col3\" >0.687213</td>\n",
       "      <td id=\"T_e457e_row1_col4\" class=\"data row1 col4\" >0.682086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e457e_level0_row2\" class=\"row_heading level0 row2\" >tf+lemma / linear svc</th>\n",
       "      <td id=\"T_e457e_row2_col0\" class=\"data row2 col0\" >0.700403</td>\n",
       "      <td id=\"T_e457e_row2_col1\" class=\"data row2 col1\" >0.597542</td>\n",
       "      <td id=\"T_e457e_row2_col2\" class=\"data row2 col2\" >0.603185</td>\n",
       "      <td id=\"T_e457e_row2_col3\" class=\"data row2 col3\" >0.691860</td>\n",
       "      <td id=\"T_e457e_row2_col4\" class=\"data row2 col4\" >0.687369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e457e_level0_row3\" class=\"row_heading level0 row3\" >tf+lemma+stop / linear svc</th>\n",
       "      <td id=\"T_e457e_row3_col0\" class=\"data row3 col0\" >0.694885</td>\n",
       "      <td id=\"T_e457e_row3_col1\" class=\"data row3 col1\" >0.594965</td>\n",
       "      <td id=\"T_e457e_row3_col2\" class=\"data row3 col2\" >0.600319</td>\n",
       "      <td id=\"T_e457e_row3_col3\" class=\"data row3 col3\" >0.686717</td>\n",
       "      <td id=\"T_e457e_row3_col4\" class=\"data row3 col4\" >0.682194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e457e_level0_row4\" class=\"row_heading level0 row4\" >tf+stem / logistic</th>\n",
       "      <td id=\"T_e457e_row4_col0\" class=\"data row4 col0\" >0.717902</td>\n",
       "      <td id=\"T_e457e_row4_col1\" class=\"data row4 col1\" >0.577215</td>\n",
       "      <td id=\"T_e457e_row4_col2\" class=\"data row4 col2\" >0.583077</td>\n",
       "      <td id=\"T_e457e_row4_col3\" class=\"data row4 col3\" >0.689414</td>\n",
       "      <td id=\"T_e457e_row4_col4\" class=\"data row4 col4\" >0.693883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e457e_level0_row5\" class=\"row_heading level0 row5\" >tf+stem+stop / logistic</th>\n",
       "      <td id=\"T_e457e_row5_col0\" class=\"data row5 col0\" >0.709533</td>\n",
       "      <td id=\"T_e457e_row5_col1\" class=\"data row5 col1\" >0.567364</td>\n",
       "      <td id=\"T_e457e_row5_col2\" class=\"data row5 col2\" >0.574770</td>\n",
       "      <td id=\"T_e457e_row5_col3\" class=\"data row5 col3\" >0.680507</td>\n",
       "      <td id=\"T_e457e_row5_col4\" class=\"data row5 col4\" >0.687407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e457e_level0_row6\" class=\"row_heading level0 row6\" >tf+lemma / logistic</th>\n",
       "      <td id=\"T_e457e_row6_col0\" class=\"data row6 col0\" >0.719615</td>\n",
       "      <td id=\"T_e457e_row6_col1\" class=\"data row6 col1\" >0.580600</td>\n",
       "      <td id=\"T_e457e_row6_col2\" class=\"data row6 col2\" >0.588259</td>\n",
       "      <td id=\"T_e457e_row6_col3\" class=\"data row6 col3\" >0.692115</td>\n",
       "      <td id=\"T_e457e_row6_col4\" class=\"data row6 col4\" >0.697842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e457e_level0_row7\" class=\"row_heading level0 row7\" >tf+lemma+stop / logistic</th>\n",
       "      <td id=\"T_e457e_row7_col0\" class=\"data row7 col0\" >0.709343</td>\n",
       "      <td id=\"T_e457e_row7_col1\" class=\"data row7 col1\" >0.567246</td>\n",
       "      <td id=\"T_e457e_row7_col2\" class=\"data row7 col2\" >0.574710</td>\n",
       "      <td id=\"T_e457e_row7_col3\" class=\"data row7 col3\" >0.680251</td>\n",
       "      <td id=\"T_e457e_row7_col4\" class=\"data row7 col4\" >0.687437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e457e_level0_row8\" class=\"row_heading level0 row8\" >tf+stem / ridge_sparse</th>\n",
       "      <td id=\"T_e457e_row8_col0\" class=\"data row8 col0\" >0.705538</td>\n",
       "      <td id=\"T_e457e_row8_col1\" class=\"data row8 col1\" >0.590454</td>\n",
       "      <td id=\"T_e457e_row8_col2\" class=\"data row8 col2\" >0.596942</td>\n",
       "      <td id=\"T_e457e_row8_col3\" class=\"data row8 col3\" >0.691499</td>\n",
       "      <td id=\"T_e457e_row8_col4\" class=\"data row8 col4\" >0.686424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e457e_level0_row9\" class=\"row_heading level0 row9\" >tf+stem+stop / ridge_sparse</th>\n",
       "      <td id=\"T_e457e_row9_col0\" class=\"data row9 col0\" >0.699640</td>\n",
       "      <td id=\"T_e457e_row9_col1\" class=\"data row9 col1\" >0.586383</td>\n",
       "      <td id=\"T_e457e_row9_col2\" class=\"data row9 col2\" >0.594094</td>\n",
       "      <td id=\"T_e457e_row9_col3\" class=\"data row9 col3\" >0.686144</td>\n",
       "      <td id=\"T_e457e_row9_col4\" class=\"data row9 col4\" >0.681981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e457e_level0_row10\" class=\"row_heading level0 row10\" >tf+lemma / ridge_sparse</th>\n",
       "      <td id=\"T_e457e_row10_col0\" class=\"data row10 col0\" >0.705729</td>\n",
       "      <td id=\"T_e457e_row10_col1\" class=\"data row10 col1\" >0.589687</td>\n",
       "      <td id=\"T_e457e_row10_col2\" class=\"data row10 col2\" >0.596744</td>\n",
       "      <td id=\"T_e457e_row10_col3\" class=\"data row10 col3\" >0.691827</td>\n",
       "      <td id=\"T_e457e_row10_col4\" class=\"data row10 col4\" >0.687117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e457e_level0_row11\" class=\"row_heading level0 row11\" >tf+lemma+stop / ridge_sparse</th>\n",
       "      <td id=\"T_e457e_row11_col0\" class=\"data row11 col0\" >0.699831</td>\n",
       "      <td id=\"T_e457e_row11_col1\" class=\"data row11 col1\" >0.586040</td>\n",
       "      <td id=\"T_e457e_row11_col2\" class=\"data row11 col2\" >0.593552</td>\n",
       "      <td id=\"T_e457e_row11_col3\" class=\"data row11 col3\" >0.686755</td>\n",
       "      <td id=\"T_e457e_row11_col4\" class=\"data row11 col4\" >0.682482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e457e_level0_row12\" class=\"row_heading level0 row12\" >tf+stem / multinomial_nb</th>\n",
       "      <td id=\"T_e457e_row12_col0\" class=\"data row12 col0\" >0.648660</td>\n",
       "      <td id=\"T_e457e_row12_col1\" class=\"data row12 col1\" >0.461196</td>\n",
       "      <td id=\"T_e457e_row12_col2\" class=\"data row12 col2\" >0.440028</td>\n",
       "      <td id=\"T_e457e_row12_col3\" class=\"data row12 col3\" >0.576303</td>\n",
       "      <td id=\"T_e457e_row12_col4\" class=\"data row12 col4\" >0.707322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e457e_level0_row13\" class=\"row_heading level0 row13\" >tf+stem+stop / multinomial_nb</th>\n",
       "      <td id=\"T_e457e_row13_col0\" class=\"data row13 col0\" >0.656649</td>\n",
       "      <td id=\"T_e457e_row13_col1\" class=\"data row13 col1\" >0.471191</td>\n",
       "      <td id=\"T_e457e_row13_col2\" class=\"data row13 col2\" >0.452874</td>\n",
       "      <td id=\"T_e457e_row13_col3\" class=\"data row13 col3\" >0.588271</td>\n",
       "      <td id=\"T_e457e_row13_col4\" class=\"data row13 col4\" >0.696757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e457e_level0_row14\" class=\"row_heading level0 row14\" >tf+lemma / multinomial_nb</th>\n",
       "      <td id=\"T_e457e_row14_col0\" class=\"data row14 col0\" >0.649230</td>\n",
       "      <td id=\"T_e457e_row14_col1\" class=\"data row14 col1\" >0.461701</td>\n",
       "      <td id=\"T_e457e_row14_col2\" class=\"data row14 col2\" >0.441037</td>\n",
       "      <td id=\"T_e457e_row14_col3\" class=\"data row14 col3\" >0.576810</td>\n",
       "      <td id=\"T_e457e_row14_col4\" class=\"data row14 col4\" >0.716617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e457e_level0_row15\" class=\"row_heading level0 row15\" >tf+lemma+stop / multinomial_nb</th>\n",
       "      <td id=\"T_e457e_row15_col0\" class=\"data row15 col0\" >0.655888</td>\n",
       "      <td id=\"T_e457e_row15_col1\" class=\"data row15 col1\" >0.470309</td>\n",
       "      <td id=\"T_e457e_row15_col2\" class=\"data row15 col2\" >0.451781</td>\n",
       "      <td id=\"T_e457e_row15_col3\" class=\"data row15 col3\" >0.587070</td>\n",
       "      <td id=\"T_e457e_row15_col4\" class=\"data row15 col4\" >0.707421</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x789764b194f0>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifiers = [\n",
    "    (LinearSVC(), \"linear svc\"),\n",
    "    (LogisticRegression(n_jobs=-1), \"logistic\"),\n",
    "    (RidgeClassifier(solver=\"sparse_cg\"), \"ridge_sparse\"),\n",
    "    (MultinomialNB(), \"multinomial_nb\"),\n",
    "]\n",
    "\n",
    "vectorizers = [\n",
    "    (TfidfVectorizer(tokenizer=StemTokenizer(), token_pattern=None), \"tf+stem\"),\n",
    "    (TfidfVectorizer(tokenizer=StemTokenizer(), token_pattern=None, stop_words=StemSTOPWORDS), \"tf+stem+stop\"),\n",
    "    (TfidfVectorizer(tokenizer=LemmaTokenizer(), token_pattern=None), \"tf+lemma\"),\n",
    "    (TfidfVectorizer(tokenizer=LemmaTokenizer(), token_pattern=None, stop_words=LemmaSTOPWORDS), \"tf+lemma+stop\"),\n",
    "]\n",
    "\n",
    "\n",
    "restab = {}\n",
    "for (classifier, clf_name), (vectorizer, vec_name) in product(classifiers, vectorizers):\n",
    "    model = Pipeline([\n",
    "        (\"vectorizer\", vectorizer),\n",
    "        (\"classifier\", classifier),\n",
    "    ])\n",
    "    restab[f\"{vec_name} / {clf_name}\"] = score(model, X, y)\n",
    "\n",
    "pd.DataFrame(restab).T.style.highlight_max(color=\"green\", axis=0).highlight_min(color=\"red\", axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfd84fb9-8978-4343-b8dd-d85708969596",
   "metadata": {},
   "source": [
    "Only Naive Bayes benefits from stop word removal except wrt weighted precision. Other models seem to dislike the lack of stop words."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00deabd3-84a8-4e13-9cdb-875ed87b5525",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning: RandomizedSearch\n",
    "\n",
    "I'd like to do a full grid search but it's very expensive and there are a lot of parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4e0671f2-c423-44e8-a23c-ace7d760148d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any\n",
    "from scipy.stats import uniform\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "\n",
    "def tune(classifier, classifier_parameters: dict[str, Any], n_iter: int = 50):\n",
    "    model = Pipeline([\n",
    "        (\"vectorizer\", TfidfVectorizer()),\n",
    "        (\"classifier\", classifier),\n",
    "    ])\n",
    "\n",
    "    parameters = {\n",
    "        \"vectorizer__token_pattern\": [None],\n",
    "        \"vectorizer__tokenizer\": [StemTokenizer(), LemmaTokenizer()],\n",
    "        \"vectorizer__max_features\": [1024, 2048, 4096, 8192, None],\n",
    "    } | classifier_parameters\n",
    "\n",
    "    clf = RandomizedSearchCV(model, parameters, n_iter=n_iter, cv=3, n_jobs=-1, scoring=\"accuracy\", verbose=1)\n",
    "    clf.fit(X, y)\n",
    "    return clf.best_estimator_, clf.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4abbc16d-7d26-4d3b-b6f6-0817c472c091",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 50 candidates, totalling 150 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(Pipeline(steps=[('vectorizer',\n",
       "                  TfidfVectorizer(max_features=2048, token_pattern=None,\n",
       "                                  tokenizer=<__main__.StemTokenizer object at 0x789764b8b440>)),\n",
       "                 ('classifier',\n",
       "                  LogisticRegression(C=np.float64(1.5367043404467962),\n",
       "                                     max_iter=200, n_jobs=-1))]),\n",
       " np.float64(0.7243692265748388))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = LogisticRegression()\n",
    "classifier_parameters = {\n",
    "    \"classifier__max_iter\": [200],\n",
    "    \"classifier__n_jobs\": [-1],\n",
    "    \"classifier__C\": uniform(0, 10),\n",
    "    \"classifier__solver\": [\"lbfgs\", \"newton-cg\"],\n",
    "}\n",
    "tune(classifier, classifier_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "79e60aff-4537-4ad3-8601-608fb76d0bcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.7338403041825095,\n",
       " 'balanced_accuracy': 0.6070089399744572,\n",
       " 'f1_macro': 0.6187656984194256,\n",
       " 'f1_weighted': 0.7127198980449911,\n",
       " 'precision_weighted': 0.715232009152425,\n",
       " 'cohen_kappa': 0.504715838497183}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = LogisticRegression(n_jobs=-1, max_iter=200, solver=\"newton-cg\")\n",
    "vectorizer = TfidfVectorizer(max_features=2048, tokenizer=LemmaTokenizer(), token_pattern=None)\n",
    "\n",
    "model = Pipeline([\n",
    "    (\"vectorizer\", vectorizer),\n",
    "    (\"classifier\", classifier),\n",
    "])\n",
    "\n",
    "score(model, X, y, method=ScoringMethod.SUMMARY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "921a6e27-bc3b-417c-b5a9-278f4f1baef4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 26,  67,  23],\n",
       "       [ 18, 376,  29],\n",
       "       [  8,  65, 177]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score(model, X, y, method=ScoringMethod.CONFUSION_MATRIX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c2a919da-8824-4425-a953-3312d98af278",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 50 candidates, totalling 150 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(Pipeline(steps=[('vectorizer',\n",
       "                  TfidfVectorizer(max_features=1024, token_pattern=None,\n",
       "                                  tokenizer=<__main__.LemmaTokenizer object at 0x789764bdb7a0>)),\n",
       "                 ('classifier',\n",
       "                  MultinomialNB(alpha=np.float64(0.4841938550112149)))]),\n",
       " np.float64(0.7000202305940415))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = MultinomialNB()\n",
    "classifier_parameters = {\n",
    "    \"classifier__alpha\": uniform(0, 1)\n",
    "}\n",
    "tune(classifier, classifier_parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f09fcbc6-8181-473b-8f80-f538e3ed01f9",
   "metadata": {},
   "source": [
    "I feel like looking at the best accuracy is a mistake. But we can easily re-run while optimizing for a different metric. Interestingly, Naive Bayes can be tuned to make comparable, accuracy-wise."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4010250e-8881-44e5-9a42-186f084864d5",
   "metadata": {},
   "source": [
    "## Deep Learning\n",
    "\n",
    "References:\n",
    "* https://www.tensorflow.org/tutorials/keras/text_classification\n",
    "* https://www.tensorflow.org/text/tutorials/text_classification_rnn\n",
    "* https://www.tensorflow.org/text/guide/word_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "109d9c58-bb6d-4b4e-82ad-e01134c29071",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# https://www.tensorflow.org/text/tutorials/text_classification_rnn#setup\n",
    "def plot_training(history, metric: str, title: str = \"\"):\n",
    "    plt.plot(history.history[metric])\n",
    "    plt.plot(history.history['val_'+metric], '')\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(metric)\n",
    "    plt.legend([metric, 'val_'+metric])\n",
    "    plt.title(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4836477-6895-4216-a91d-27056f905d5d",
   "metadata": {},
   "source": [
    "Nice little function, but I don't see much use. Simply looking at the training output gives us a sufficient idea."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d35415d3-b0da-4594-9d1a-9ebf34bf999d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-04 23:30:39.585273: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-11-04 23:30:39.585680: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-04 23:30:39.588076: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-04 23:30:39.595399: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1730734239.609577   58659 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1730734239.613674   58659 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-04 23:30:39.628163: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from typing import Callable\n",
    "from tensorflow.keras import layers, Sequential\n",
    "\n",
    "VOCAB_SIZE = 2048\n",
    "\n",
    "def lstm(units: int = 64,\n",
    "         vocab_size: int = VOCAB_SIZE,\n",
    "         standardize: str | Callable = \"lower_and_strip_punctuation\"):\n",
    "    return Sequential([\n",
    "        layers.TextVectorization(max_tokens=vocab_size, standardize=standardize),\n",
    "        layers.Embedding(\n",
    "            input_dim=vocab_size,\n",
    "            output_dim=units,\n",
    "            mask_zero=True,\n",
    "        ),\n",
    "        layers.Bidirectional(layers.LSTM(units)),\n",
    "        layers.Dense(units, activation=\"relu\"),\n",
    "        layers.Dense(3),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c6f53232-0e02-4871-bfe8-f14be35b9e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.math import softmax\n",
    "from tensorflow.keras import losses, callbacks\n",
    "\n",
    "def compile(model,\n",
    "            loss=losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "            optimizer=\"adam\",\n",
    "            metrics=[\"sparse_categorical_crossentropy\", \"accuracy\"]):\n",
    "    model.compile(loss=loss,\n",
    "                  optimizer=optimizer,\n",
    "                  metrics=metrics,\n",
    "                  weighted_metrics=metrics)\n",
    "\n",
    "def train(model,\n",
    "          X_train: np.ndarray,\n",
    "          y_train: np.ndarray,\n",
    "          X_val: np.ndarray,\n",
    "          y_val: np.ndarray,\n",
    "          epochs: int,\n",
    "          batch_size: int | None,\n",
    "          early_stopping: bool):\n",
    "\n",
    "    model.fit(X_train,\n",
    "              y_train,\n",
    "              validation_data=(X_val, y_val),\n",
    "              epochs=epochs,\n",
    "              batch_size=batch_size,\n",
    "              #class_weight=CLASS_WEIGHTS,\n",
    "              callbacks=[\n",
    "                  callbacks.EarlyStopping(patience=5, restore_best_weights=True)\n",
    "              ] if early_stopping else None)\n",
    "\n",
    "def predict(model, X):\n",
    "    return np.argmax(softmax(model.predict(X)), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fc33957-c93d-4fbb-933d-e70f25567572",
   "metadata": {},
   "source": [
    "To combat overfitting, we use a validation dataset and early stopping. The other option is to add dropout layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7539430b-5a3d-4b77-a410-d3c0ac23c62d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adapt_and_compile(model, X_train: np.ndarray):\n",
    "    vectorizer = model.layers[0]\n",
    "    if vectorizer.get_vocabulary() == ['', '[UNK]']:\n",
    "        vectorizer.adapt(X_train)\n",
    "    compile(model)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13eecb65-a967-42de-b50e-24d061c3d4d7",
   "metadata": {},
   "source": [
    "Write `score_dl` and `cross_validate_dl` specifically for deep learning models: they require additional setup. I attempted creating a class to be similar to `sklearn`, but it's simpler to write ad-hoc functions. Morever, we need to also tune the model. Classes do not make it easier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "57889951-17c5-455e-915e-4327b531fe77",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def cross_validate_dl(build_model: Callable,\n",
    "                      X: np.ndarray,\n",
    "                      y: np.ndarray,\n",
    "                      epochs: int,\n",
    "                      batch_size: int | None,\n",
    "                      early_stopping: bool) -> dict[str, float]:\n",
    "    results = defaultdict(list)\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=3)\n",
    "    for i, (train_idx, val_idx) in enumerate(skf.split(X, y)):\n",
    "        X_train, y_train = X[train_idx], y[train_idx]\n",
    "        X_val, y_val = X[val_idx], y[val_idx]\n",
    "\n",
    "        print(f\"Fold {i}\")\n",
    "        model = adapt_and_compile(build_model(), X_train)\n",
    "        history = train(model,\n",
    "                        X_train,\n",
    "                        y_train,\n",
    "                        X_val,\n",
    "                        y_val,\n",
    "                        epochs=epochs,\n",
    "                        batch_size=batch_size,\n",
    "                        early_stopping=early_stopping)\n",
    "        y_pred = predict(model, X_val)\n",
    "\n",
    "        summary = custom_summary(y_val, y_pred)\n",
    "        for metric in summary:\n",
    "            results[metric].append(summary[metric])\n",
    "\n",
    "    return {\n",
    "        f\"cv_{metric}\": sum(results[metric]) / len(results[metric])\n",
    "        for metric in results\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c707ea94-74a4-48d5-beb6-02f9f8cb6f95",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def score_dl(build_model: Callable,\n",
    "             X: np.ndarray,\n",
    "             y: np.ndarray,\n",
    "             method: ScoringMethod = ScoringMethod.SUMMARY,\n",
    "             scoring: str = \"balanced_accuracy\",\n",
    "             epochs: int = 1,\n",
    "             batch_size: int | None = None,\n",
    "             early_stopping: bool = False) -> str | np.ndarray | dict[str, float]:\n",
    "\n",
    "    if method == ScoringMethod.CROSS_VAL_SCORE:\n",
    "        return cross_validate_dl(build_model,\n",
    "                                 X,\n",
    "                                 y,\n",
    "                                 epochs=epochs,\n",
    "                                 batch_size=batch_size,\n",
    "                                 early_stopping=early_stopping)\n",
    "\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X,\n",
    "                                                      y,\n",
    "                                                      random_state=0,\n",
    "                                                      stratify=y,\n",
    "                                                      test_size=VALIDATION_SPLIT)\n",
    "\n",
    "    model = adapt_and_compile(build_model(), X_train)\n",
    "    history = train(model,\n",
    "                    X_train,\n",
    "                    y_train,\n",
    "                    X_val,\n",
    "                    y_val,\n",
    "                    epochs=epochs,\n",
    "                    batch_size=batch_size,\n",
    "                    early_stopping=early_stopping)\n",
    "    y_pred = predict(model, X_val)\n",
    "\n",
    "    return {\n",
    "        ScoringMethod.CLASSIFICATION_REPORT: classification_report,\n",
    "        ScoringMethod.CONFUSION_MATRIX: confusion_matrix,\n",
    "        ScoringMethod.SUMMARY: custom_summary,\n",
    "    }.get(method)(y_val, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e3b1e8a3-5598-4cc2-bba6-977770a19982",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-04 23:30:40.806548: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:152] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 4/45\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.3781 - loss: 1.0965 - sparse_categorical_crossentropy: 4.2113 - weighted_accuracy: 0.3781 - weighted_sparse_categorical_crossentropy: 4.2113"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-04 23:30:43.998911: E tensorflow/core/util/util.cc:131] oneDNN supports DT_BOOL only on platforms with AVX-512. Falling back to the default Eigen-based implementation if present.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 34ms/step - accuracy: 0.5040 - loss: 1.0239 - sparse_categorical_crossentropy: 3.2662 - weighted_accuracy: 0.5040 - weighted_sparse_categorical_crossentropy: 3.2662 - val_accuracy: 0.6122 - val_loss: 0.8772 - val_sparse_categorical_crossentropy: 3.6881 - val_weighted_accuracy: 0.6122 - val_weighted_sparse_categorical_crossentropy: 3.6881\n",
      "Epoch 2/20\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.6572 - loss: 0.8045 - sparse_categorical_crossentropy: 3.4364 - weighted_accuracy: 0.6572 - weighted_sparse_categorical_crossentropy: 3.4364 - val_accuracy: 0.6755 - val_loss: 0.7421 - val_sparse_categorical_crossentropy: 3.8094 - val_weighted_accuracy: 0.6755 - val_weighted_sparse_categorical_crossentropy: 3.8094\n",
      "Epoch 3/20\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.7713 - loss: 0.5770 - sparse_categorical_crossentropy: 2.4290 - weighted_accuracy: 0.7713 - weighted_sparse_categorical_crossentropy: 2.4290 - val_accuracy: 0.7148 - val_loss: 0.6574 - val_sparse_categorical_crossentropy: 2.3744 - val_weighted_accuracy: 0.7148 - val_weighted_sparse_categorical_crossentropy: 2.3744\n",
      "Epoch 4/20\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.8366 - loss: 0.3954 - sparse_categorical_crossentropy: 1.0539 - weighted_accuracy: 0.8366 - weighted_sparse_categorical_crossentropy: 1.0539 - val_accuracy: 0.6933 - val_loss: 0.7058 - val_sparse_categorical_crossentropy: 2.2764 - val_weighted_accuracy: 0.6933 - val_weighted_sparse_categorical_crossentropy: 2.2764\n",
      "Epoch 5/20\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.8739 - loss: 0.3098 - sparse_categorical_crossentropy: 0.6859 - weighted_accuracy: 0.8739 - weighted_sparse_categorical_crossentropy: 0.6859 - val_accuracy: 0.6730 - val_loss: 0.7709 - val_sparse_categorical_crossentropy: 2.4277 - val_weighted_accuracy: 0.6730 - val_weighted_sparse_categorical_crossentropy: 2.4277\n",
      "Epoch 6/20\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.8898 - loss: 0.2533 - sparse_categorical_crossentropy: 0.5121 - weighted_accuracy: 0.8898 - weighted_sparse_categorical_crossentropy: 0.5121 - val_accuracy: 0.6717 - val_loss: 0.8629 - val_sparse_categorical_crossentropy: 2.4799 - val_weighted_accuracy: 0.6717 - val_weighted_sparse_categorical_crossentropy: 2.4799\n",
      "Epoch 7/20\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.8904 - loss: 0.2241 - sparse_categorical_crossentropy: 0.4149 - weighted_accuracy: 0.8904 - weighted_sparse_categorical_crossentropy: 0.4149 - val_accuracy: 0.6717 - val_loss: 1.0069 - val_sparse_categorical_crossentropy: 2.7636 - val_weighted_accuracy: 0.6717 - val_weighted_sparse_categorical_crossentropy: 2.7636\n",
      "Epoch 8/20\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.9095 - loss: 0.1834 - sparse_categorical_crossentropy: 0.3286 - weighted_accuracy: 0.9095 - weighted_sparse_categorical_crossentropy: 0.3286 - val_accuracy: 0.6781 - val_loss: 1.0906 - val_sparse_categorical_crossentropy: 2.6582 - val_weighted_accuracy: 0.6781 - val_weighted_sparse_categorical_crossentropy: 2.6582\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.714828897338403,\n",
       " 'balanced_accuracy': 0.6199279910871988,\n",
       " 'f1_macro': 0.6323837759302812,\n",
       " 'f1_weighted': 0.706612084425848,\n",
       " 'precision_weighted': 0.7066984472116347,\n",
       " 'cohen_kappa': 0.49044606634267496}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_dl(lstm, X, y, epochs=20, batch_size=100, early_stopping=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "133c6e39-3f3c-424e-9d3e-cc00afafecdf",
   "metadata": {},
   "source": [
    "Comparable to traditional models. Disappointing? Does seem to have better balanced accuracy and macro-averaged f1 score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "988d92f9-bd1f-496f-aa58-2ba1f688c171",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 34ms/step - accuracy: 0.5106 - loss: 1.0250 - sparse_categorical_crossentropy: 5.1629 - weighted_accuracy: 0.5106 - weighted_sparse_categorical_crossentropy: 5.1629 - val_accuracy: 0.6248 - val_loss: 0.8725 - val_sparse_categorical_crossentropy: 4.5797 - val_weighted_accuracy: 0.6248 - val_weighted_sparse_categorical_crossentropy: 4.5797\n",
      "Epoch 2/20\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.6392 - loss: 0.8285 - sparse_categorical_crossentropy: 4.0718 - weighted_accuracy: 0.6392 - weighted_sparse_categorical_crossentropy: 4.0718 - val_accuracy: 0.6806 - val_loss: 0.7420 - val_sparse_categorical_crossentropy: 4.0781 - val_weighted_accuracy: 0.6806 - val_weighted_sparse_categorical_crossentropy: 4.0781\n",
      "Epoch 3/20\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.7564 - loss: 0.5890 - sparse_categorical_crossentropy: 3.0413 - weighted_accuracy: 0.7564 - weighted_sparse_categorical_crossentropy: 3.0413 - val_accuracy: 0.7034 - val_loss: 0.6512 - val_sparse_categorical_crossentropy: 3.3116 - val_weighted_accuracy: 0.7034 - val_weighted_sparse_categorical_crossentropy: 3.3116\n",
      "Epoch 4/20\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.8251 - loss: 0.4188 - sparse_categorical_crossentropy: 1.6531 - weighted_accuracy: 0.8251 - weighted_sparse_categorical_crossentropy: 1.6531 - val_accuracy: 0.7060 - val_loss: 0.7598 - val_sparse_categorical_crossentropy: 3.4577 - val_weighted_accuracy: 0.7060 - val_weighted_sparse_categorical_crossentropy: 3.4577\n",
      "Epoch 5/20\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.8610 - loss: 0.3264 - sparse_categorical_crossentropy: 1.0059 - weighted_accuracy: 0.8610 - weighted_sparse_categorical_crossentropy: 1.0059 - val_accuracy: 0.6946 - val_loss: 0.7313 - val_sparse_categorical_crossentropy: 3.2638 - val_weighted_accuracy: 0.6946 - val_weighted_sparse_categorical_crossentropy: 3.2638\n",
      "Epoch 6/20\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.8885 - loss: 0.2574 - sparse_categorical_crossentropy: 0.6178 - weighted_accuracy: 0.8885 - weighted_sparse_categorical_crossentropy: 0.6178 - val_accuracy: 0.6946 - val_loss: 0.8657 - val_sparse_categorical_crossentropy: 3.2029 - val_weighted_accuracy: 0.6946 - val_weighted_sparse_categorical_crossentropy: 3.2029\n",
      "Epoch 7/20\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 37ms/step - accuracy: 0.8920 - loss: 0.2247 - sparse_categorical_crossentropy: 0.5067 - weighted_accuracy: 0.8920 - weighted_sparse_categorical_crossentropy: 0.5067 - val_accuracy: 0.6717 - val_loss: 0.9671 - val_sparse_categorical_crossentropy: 3.2194 - val_weighted_accuracy: 0.6717 - val_weighted_sparse_categorical_crossentropy: 3.2194\n",
      "Epoch 8/20\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - accuracy: 0.9021 - loss: 0.2029 - sparse_categorical_crossentropy: 0.3857 - weighted_accuracy: 0.9021 - weighted_sparse_categorical_crossentropy: 0.3857 - val_accuracy: 0.6717 - val_loss: 1.0941 - val_sparse_categorical_crossentropy: 3.1827 - val_weighted_accuracy: 0.6717 - val_weighted_sparse_categorical_crossentropy: 3.1827\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 37,  53,  26],\n",
       "       [ 34, 346,  43],\n",
       "       [ 20,  58, 172]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_dl(lstm, X, y, epochs=20, batch_size=100, early_stopping=True, method=ScoringMethod.CONFUSION_MATRIX)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3d04426-df85-4cdc-a658-4e155413b5f3",
   "metadata": {},
   "source": [
    "Need to check confusion matrices regularly so that we know the models are actually trying to learn all the classes and not just the majority ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c5090345",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lstm2(units: int = 32, vocab_size: int = VOCAB_SIZE):\n",
    "    return Sequential([\n",
    "        layers.TextVectorization(max_tokens=vocab_size),\n",
    "        layers.Embedding(\n",
    "            input_dim=vocab_size,\n",
    "            output_dim=units,\n",
    "            mask_zero=True,\n",
    "        ),\n",
    "        layers.Bidirectional(layers.LSTM(units, return_sequences=True)),\n",
    "        layers.Bidirectional(layers.LSTM(units)),\n",
    "        layers.Dense(units, activation=\"relu\"),\n",
    "        layers.Dense(3),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "bba4bdab-b173-429e-a63a-2f28b87134cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_embed(units: int = 64, vocab_size: int = VOCAB_SIZE):\n",
    "    model = Sequential([\n",
    "        layers.TextVectorization(max_tokens=vocab_size),\n",
    "        layers.Embedding(input_dim=vocab_size, \n",
    "                         output_dim=units,\n",
    "                         mask_zero=True),\n",
    "        layers.GlobalAveragePooling1D(),\n",
    "        layers.Dropout(0.2),\n",
    "        layers.Dense(3),\n",
    "    ])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "685bcaeb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0\n",
      "Epoch 1/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 48ms/step - accuracy: 0.5211 - loss: 1.0328 - sparse_categorical_crossentropy: 4.4071 - weighted_accuracy: 0.5211 - weighted_sparse_categorical_crossentropy: 4.4071 - val_accuracy: 0.5859 - val_loss: 0.9114 - val_sparse_categorical_crossentropy: 4.0287 - val_weighted_accuracy: 0.5859 - val_weighted_sparse_categorical_crossentropy: 4.0287\n",
      "Epoch 2/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.6349 - loss: 0.8418 - sparse_categorical_crossentropy: 3.8435 - weighted_accuracy: 0.6349 - weighted_sparse_categorical_crossentropy: 3.8435 - val_accuracy: 0.6423 - val_loss: 0.8160 - val_sparse_categorical_crossentropy: 4.1357 - val_weighted_accuracy: 0.6423 - val_weighted_sparse_categorical_crossentropy: 4.1357\n",
      "Epoch 3/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.7208 - loss: 0.6920 - sparse_categorical_crossentropy: 3.4668 - weighted_accuracy: 0.7208 - weighted_sparse_categorical_crossentropy: 3.4668 - val_accuracy: 0.6777 - val_loss: 0.7808 - val_sparse_categorical_crossentropy: 4.2083 - val_weighted_accuracy: 0.6777 - val_weighted_sparse_categorical_crossentropy: 4.2083\n",
      "Epoch 4/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.7925 - loss: 0.4842 - sparse_categorical_crossentropy: 2.1997 - weighted_accuracy: 0.7925 - weighted_sparse_categorical_crossentropy: 2.1997 - val_accuracy: 0.6851 - val_loss: 0.7747 - val_sparse_categorical_crossentropy: 3.2820 - val_weighted_accuracy: 0.6851 - val_weighted_sparse_categorical_crossentropy: 3.2820\n",
      "Epoch 5/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.8486 - loss: 0.3460 - sparse_categorical_crossentropy: 0.9019 - weighted_accuracy: 0.8486 - weighted_sparse_categorical_crossentropy: 0.9019 - val_accuracy: 0.6811 - val_loss: 0.8696 - val_sparse_categorical_crossentropy: 3.1698 - val_weighted_accuracy: 0.6811 - val_weighted_sparse_categorical_crossentropy: 3.1698\n",
      "Epoch 6/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.8865 - loss: 0.2618 - sparse_categorical_crossentropy: 0.5223 - weighted_accuracy: 0.8865 - weighted_sparse_categorical_crossentropy: 0.5223 - val_accuracy: 0.6657 - val_loss: 0.9687 - val_sparse_categorical_crossentropy: 3.1557 - val_weighted_accuracy: 0.6657 - val_weighted_sparse_categorical_crossentropy: 3.1557\n",
      "Epoch 7/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.8879 - loss: 0.2551 - sparse_categorical_crossentropy: 0.5840 - weighted_accuracy: 0.8879 - weighted_sparse_categorical_crossentropy: 0.5840 - val_accuracy: 0.6657 - val_loss: 1.0212 - val_sparse_categorical_crossentropy: 3.2362 - val_weighted_accuracy: 0.6657 - val_weighted_sparse_categorical_crossentropy: 3.2362\n",
      "Epoch 8/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.9078 - loss: 0.1952 - sparse_categorical_crossentropy: 0.3822 - weighted_accuracy: 0.9078 - weighted_sparse_categorical_crossentropy: 0.3822 - val_accuracy: 0.6657 - val_loss: 1.1010 - val_sparse_categorical_crossentropy: 3.2522 - val_weighted_accuracy: 0.6657 - val_weighted_sparse_categorical_crossentropy: 3.2522\n",
      "Epoch 9/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.8929 - loss: 0.2638 - sparse_categorical_crossentropy: 0.7315 - weighted_accuracy: 0.8929 - weighted_sparse_categorical_crossentropy: 0.7315 - val_accuracy: 0.6583 - val_loss: 1.1331 - val_sparse_categorical_crossentropy: 3.5957 - val_weighted_accuracy: 0.6583 - val_weighted_sparse_categorical_crossentropy: 3.5957\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step\n",
      "Fold 1\n",
      "Epoch 1/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 41ms/step - accuracy: 0.5008 - loss: 1.0348 - sparse_categorical_crossentropy: 6.1272 - weighted_accuracy: 0.5008 - weighted_sparse_categorical_crossentropy: 6.1272 - val_accuracy: 0.5559 - val_loss: 0.8999 - val_sparse_categorical_crossentropy: 5.9966 - val_weighted_accuracy: 0.5559 - val_weighted_sparse_categorical_crossentropy: 5.9966\n",
      "Epoch 2/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.6070 - loss: 0.8595 - sparse_categorical_crossentropy: 5.0394 - weighted_accuracy: 0.6070 - weighted_sparse_categorical_crossentropy: 5.0394 - val_accuracy: 0.6490 - val_loss: 0.8034 - val_sparse_categorical_crossentropy: 4.2294 - val_weighted_accuracy: 0.6490 - val_weighted_sparse_categorical_crossentropy: 4.2294\n",
      "Epoch 3/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.6879 - loss: 0.7109 - sparse_categorical_crossentropy: 3.5668 - weighted_accuracy: 0.6879 - weighted_sparse_categorical_crossentropy: 3.5668 - val_accuracy: 0.6941 - val_loss: 0.7586 - val_sparse_categorical_crossentropy: 3.8577 - val_weighted_accuracy: 0.6941 - val_weighted_sparse_categorical_crossentropy: 3.8577\n",
      "Epoch 4/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.7942 - loss: 0.4948 - sparse_categorical_crossentropy: 2.1499 - weighted_accuracy: 0.7942 - weighted_sparse_categorical_crossentropy: 2.1499 - val_accuracy: 0.7158 - val_loss: 0.7433 - val_sparse_categorical_crossentropy: 3.2142 - val_weighted_accuracy: 0.7158 - val_weighted_sparse_categorical_crossentropy: 3.2142\n",
      "Epoch 5/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.8642 - loss: 0.3249 - sparse_categorical_crossentropy: 0.9378 - weighted_accuracy: 0.8642 - weighted_sparse_categorical_crossentropy: 0.9378 - val_accuracy: 0.7140 - val_loss: 0.8122 - val_sparse_categorical_crossentropy: 2.9766 - val_weighted_accuracy: 0.7140 - val_weighted_sparse_categorical_crossentropy: 2.9766\n",
      "Epoch 6/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.8914 - loss: 0.2604 - sparse_categorical_crossentropy: 0.5388 - weighted_accuracy: 0.8914 - weighted_sparse_categorical_crossentropy: 0.5388 - val_accuracy: 0.7015 - val_loss: 0.9549 - val_sparse_categorical_crossentropy: 3.1099 - val_weighted_accuracy: 0.7015 - val_weighted_sparse_categorical_crossentropy: 3.1099\n",
      "Epoch 7/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.8941 - loss: 0.2213 - sparse_categorical_crossentropy: 0.3987 - weighted_accuracy: 0.8941 - weighted_sparse_categorical_crossentropy: 0.3987 - val_accuracy: 0.6958 - val_loss: 0.9842 - val_sparse_categorical_crossentropy: 3.1168 - val_weighted_accuracy: 0.6958 - val_weighted_sparse_categorical_crossentropy: 3.1168\n",
      "Epoch 8/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.9199 - loss: 0.1704 - sparse_categorical_crossentropy: 0.2296 - weighted_accuracy: 0.9199 - weighted_sparse_categorical_crossentropy: 0.2296 - val_accuracy: 0.6792 - val_loss: 1.1260 - val_sparse_categorical_crossentropy: 3.1258 - val_weighted_accuracy: 0.6792 - val_weighted_sparse_categorical_crossentropy: 3.1258\n",
      "Epoch 9/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.9237 - loss: 0.1545 - sparse_categorical_crossentropy: 0.2224 - weighted_accuracy: 0.9237 - weighted_sparse_categorical_crossentropy: 0.2224 - val_accuracy: 0.6804 - val_loss: 1.3234 - val_sparse_categorical_crossentropy: 3.2481 - val_weighted_accuracy: 0.6804 - val_weighted_sparse_categorical_crossentropy: 3.2481\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step\n",
      "Fold 2\n",
      "Epoch 1/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 43ms/step - accuracy: 0.5036 - loss: 1.0382 - sparse_categorical_crossentropy: 5.1500 - weighted_accuracy: 0.5036 - weighted_sparse_categorical_crossentropy: 5.1500 - val_accuracy: 0.5371 - val_loss: 0.9206 - val_sparse_categorical_crossentropy: 4.7857 - val_weighted_accuracy: 0.5371 - val_weighted_sparse_categorical_crossentropy: 4.7857\n",
      "Epoch 2/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.5608 - loss: 0.8865 - sparse_categorical_crossentropy: 5.4103 - weighted_accuracy: 0.5608 - weighted_sparse_categorical_crossentropy: 5.4103 - val_accuracy: 0.6553 - val_loss: 0.8194 - val_sparse_categorical_crossentropy: 3.9153 - val_weighted_accuracy: 0.6553 - val_weighted_sparse_categorical_crossentropy: 3.9153\n",
      "Epoch 3/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.6710 - loss: 0.7368 - sparse_categorical_crossentropy: 3.7294 - weighted_accuracy: 0.6710 - weighted_sparse_categorical_crossentropy: 3.7294 - val_accuracy: 0.6929 - val_loss: 0.7524 - val_sparse_categorical_crossentropy: 3.5602 - val_weighted_accuracy: 0.6929 - val_weighted_sparse_categorical_crossentropy: 3.5602\n",
      "Epoch 4/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.8061 - loss: 0.4762 - sparse_categorical_crossentropy: 1.8068 - weighted_accuracy: 0.8061 - weighted_sparse_categorical_crossentropy: 1.8068 - val_accuracy: 0.6941 - val_loss: 0.6993 - val_sparse_categorical_crossentropy: 2.9648 - val_weighted_accuracy: 0.6941 - val_weighted_sparse_categorical_crossentropy: 2.9648\n",
      "Epoch 5/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.8588 - loss: 0.3341 - sparse_categorical_crossentropy: 0.9032 - weighted_accuracy: 0.8588 - weighted_sparse_categorical_crossentropy: 0.9032 - val_accuracy: 0.6924 - val_loss: 0.7942 - val_sparse_categorical_crossentropy: 3.0312 - val_weighted_accuracy: 0.6924 - val_weighted_sparse_categorical_crossentropy: 3.0312\n",
      "Epoch 6/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.8782 - loss: 0.2781 - sparse_categorical_crossentropy: 0.7221 - weighted_accuracy: 0.8782 - weighted_sparse_categorical_crossentropy: 0.7221 - val_accuracy: 0.6826 - val_loss: 0.9006 - val_sparse_categorical_crossentropy: 3.0060 - val_weighted_accuracy: 0.6826 - val_weighted_sparse_categorical_crossentropy: 3.0060\n",
      "Epoch 7/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.9010 - loss: 0.2269 - sparse_categorical_crossentropy: 0.3992 - weighted_accuracy: 0.9010 - weighted_sparse_categorical_crossentropy: 0.3992 - val_accuracy: 0.6632 - val_loss: 1.0440 - val_sparse_categorical_crossentropy: 3.2485 - val_weighted_accuracy: 0.6632 - val_weighted_sparse_categorical_crossentropy: 3.2485\n",
      "Epoch 8/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.9195 - loss: 0.1715 - sparse_categorical_crossentropy: 0.2625 - weighted_accuracy: 0.9195 - weighted_sparse_categorical_crossentropy: 0.2625 - val_accuracy: 0.6661 - val_loss: 1.2279 - val_sparse_categorical_crossentropy: 3.2680 - val_weighted_accuracy: 0.6661 - val_weighted_sparse_categorical_crossentropy: 3.2680\n",
      "Epoch 9/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.9144 - loss: 0.2018 - sparse_categorical_crossentropy: 0.3809 - weighted_accuracy: 0.9144 - weighted_sparse_categorical_crossentropy: 0.3809 - val_accuracy: 0.6627 - val_loss: 1.1484 - val_sparse_categorical_crossentropy: 3.6109 - val_weighted_accuracy: 0.6627 - val_weighted_sparse_categorical_crossentropy: 3.6109\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step\n",
      "Fold 0\n",
      "Epoch 1/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 60ms/step - accuracy: 0.5150 - loss: 1.0419 - sparse_categorical_crossentropy: 4.4026 - weighted_accuracy: 0.5150 - weighted_sparse_categorical_crossentropy: 4.4026 - val_accuracy: 0.5357 - val_loss: 0.9398 - val_sparse_categorical_crossentropy: 2.8853 - val_weighted_accuracy: 0.5357 - val_weighted_sparse_categorical_crossentropy: 2.8853\n",
      "Epoch 2/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - accuracy: 0.5765 - loss: 0.8888 - sparse_categorical_crossentropy: 2.7975 - weighted_accuracy: 0.5765 - weighted_sparse_categorical_crossentropy: 2.7975 - val_accuracy: 0.6195 - val_loss: 0.8693 - val_sparse_categorical_crossentropy: 3.8401 - val_weighted_accuracy: 0.6195 - val_weighted_sparse_categorical_crossentropy: 3.8401\n",
      "Epoch 3/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 49ms/step - accuracy: 0.6838 - loss: 0.7644 - sparse_categorical_crossentropy: 3.6927 - weighted_accuracy: 0.6838 - weighted_sparse_categorical_crossentropy: 3.6927 - val_accuracy: 0.6435 - val_loss: 0.8262 - val_sparse_categorical_crossentropy: 4.4880 - val_weighted_accuracy: 0.6435 - val_weighted_sparse_categorical_crossentropy: 4.4880\n",
      "Epoch 4/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 46ms/step - accuracy: 0.7465 - loss: 0.6405 - sparse_categorical_crossentropy: 3.5180 - weighted_accuracy: 0.7465 - weighted_sparse_categorical_crossentropy: 3.5180 - val_accuracy: 0.6737 - val_loss: 0.7968 - val_sparse_categorical_crossentropy: 4.6175 - val_weighted_accuracy: 0.6737 - val_weighted_sparse_categorical_crossentropy: 4.6175\n",
      "Epoch 5/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - accuracy: 0.7763 - loss: 0.5475 - sparse_categorical_crossentropy: 3.1613 - weighted_accuracy: 0.7763 - weighted_sparse_categorical_crossentropy: 3.1613 - val_accuracy: 0.6788 - val_loss: 0.8807 - val_sparse_categorical_crossentropy: 4.1803 - val_weighted_accuracy: 0.6788 - val_weighted_sparse_categorical_crossentropy: 4.1803\n",
      "Epoch 6/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 51ms/step - accuracy: 0.8193 - loss: 0.4434 - sparse_categorical_crossentropy: 1.8076 - weighted_accuracy: 0.8193 - weighted_sparse_categorical_crossentropy: 1.8076 - val_accuracy: 0.6863 - val_loss: 0.9169 - val_sparse_categorical_crossentropy: 3.9318 - val_weighted_accuracy: 0.6863 - val_weighted_sparse_categorical_crossentropy: 3.9318\n",
      "Epoch 7/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 51ms/step - accuracy: 0.8793 - loss: 0.3126 - sparse_categorical_crossentropy: 1.0924 - weighted_accuracy: 0.8793 - weighted_sparse_categorical_crossentropy: 1.0924 - val_accuracy: 0.6754 - val_loss: 0.9475 - val_sparse_categorical_crossentropy: 3.3819 - val_weighted_accuracy: 0.6754 - val_weighted_sparse_categorical_crossentropy: 3.3819\n",
      "Epoch 8/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 50ms/step - accuracy: 0.9052 - loss: 0.2497 - sparse_categorical_crossentropy: 0.6280 - weighted_accuracy: 0.9052 - weighted_sparse_categorical_crossentropy: 0.6280 - val_accuracy: 0.6651 - val_loss: 1.0677 - val_sparse_categorical_crossentropy: 3.3983 - val_weighted_accuracy: 0.6651 - val_weighted_sparse_categorical_crossentropy: 3.3983\n",
      "Epoch 9/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 50ms/step - accuracy: 0.9177 - loss: 0.1918 - sparse_categorical_crossentropy: 0.3966 - weighted_accuracy: 0.9177 - weighted_sparse_categorical_crossentropy: 0.3966 - val_accuracy: 0.6612 - val_loss: 1.2506 - val_sparse_categorical_crossentropy: 3.5266 - val_weighted_accuracy: 0.6612 - val_weighted_sparse_categorical_crossentropy: 3.5266\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step\n",
      "Fold 1\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 56ms/step - accuracy: 0.4740 - loss: 1.0578 - sparse_categorical_crossentropy: 6.6885 - weighted_accuracy: 0.4740 - weighted_sparse_categorical_crossentropy: 6.6885 - val_accuracy: 0.5360 - val_loss: 0.9360 - val_sparse_categorical_crossentropy: 6.4834 - val_weighted_accuracy: 0.5360 - val_weighted_sparse_categorical_crossentropy: 6.4834\n",
      "Epoch 2/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - accuracy: 0.5696 - loss: 0.9154 - sparse_categorical_crossentropy: 5.3022 - weighted_accuracy: 0.5696 - weighted_sparse_categorical_crossentropy: 5.3022 - val_accuracy: 0.6159 - val_loss: 0.8695 - val_sparse_categorical_crossentropy: 4.1650 - val_weighted_accuracy: 0.6159 - val_weighted_sparse_categorical_crossentropy: 4.1650\n",
      "Epoch 3/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step - accuracy: 0.6792 - loss: 0.7678 - sparse_categorical_crossentropy: 4.0693 - weighted_accuracy: 0.6792 - weighted_sparse_categorical_crossentropy: 4.0693 - val_accuracy: 0.6735 - val_loss: 0.7788 - val_sparse_categorical_crossentropy: 4.3944 - val_weighted_accuracy: 0.6735 - val_weighted_sparse_categorical_crossentropy: 4.3944\n",
      "Epoch 4/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - accuracy: 0.7408 - loss: 0.6173 - sparse_categorical_crossentropy: 3.5803 - weighted_accuracy: 0.7408 - weighted_sparse_categorical_crossentropy: 3.5803 - val_accuracy: 0.6866 - val_loss: 0.7556 - val_sparse_categorical_crossentropy: 4.0187 - val_weighted_accuracy: 0.6866 - val_weighted_sparse_categorical_crossentropy: 4.0187\n",
      "Epoch 5/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step - accuracy: 0.8092 - loss: 0.4808 - sparse_categorical_crossentropy: 2.2211 - weighted_accuracy: 0.8092 - weighted_sparse_categorical_crossentropy: 2.2211 - val_accuracy: 0.7112 - val_loss: 0.8025 - val_sparse_categorical_crossentropy: 3.5632 - val_weighted_accuracy: 0.7112 - val_weighted_sparse_categorical_crossentropy: 3.5632\n",
      "Epoch 6/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - accuracy: 0.8526 - loss: 0.3491 - sparse_categorical_crossentropy: 1.2033 - weighted_accuracy: 0.8526 - weighted_sparse_categorical_crossentropy: 1.2033 - val_accuracy: 0.6941 - val_loss: 0.8726 - val_sparse_categorical_crossentropy: 3.3896 - val_weighted_accuracy: 0.6941 - val_weighted_sparse_categorical_crossentropy: 3.3896\n",
      "Epoch 7/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 46ms/step - accuracy: 0.8771 - loss: 0.2883 - sparse_categorical_crossentropy: 0.7747 - weighted_accuracy: 0.8771 - weighted_sparse_categorical_crossentropy: 0.7747 - val_accuracy: 0.6975 - val_loss: 1.0529 - val_sparse_categorical_crossentropy: 3.3970 - val_weighted_accuracy: 0.6975 - val_weighted_sparse_categorical_crossentropy: 3.3970\n",
      "Epoch 8/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - accuracy: 0.9034 - loss: 0.2275 - sparse_categorical_crossentropy: 0.5342 - weighted_accuracy: 0.9034 - weighted_sparse_categorical_crossentropy: 0.5342 - val_accuracy: 0.6815 - val_loss: 1.0810 - val_sparse_categorical_crossentropy: 3.6066 - val_weighted_accuracy: 0.6815 - val_weighted_sparse_categorical_crossentropy: 3.6066\n",
      "Epoch 9/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - accuracy: 0.8923 - loss: 0.2424 - sparse_categorical_crossentropy: 0.5805 - weighted_accuracy: 0.8923 - weighted_sparse_categorical_crossentropy: 0.5805 - val_accuracy: 0.6809 - val_loss: 1.1623 - val_sparse_categorical_crossentropy: 3.4319 - val_weighted_accuracy: 0.6809 - val_weighted_sparse_categorical_crossentropy: 3.4319\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step\n",
      "Fold 2\n",
      "Epoch 1/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 58ms/step - accuracy: 0.5170 - loss: 1.0415 - sparse_categorical_crossentropy: 2.8130 - weighted_accuracy: 0.5170 - weighted_sparse_categorical_crossentropy: 2.8130 - val_accuracy: 0.5360 - val_loss: 0.9524 - val_sparse_categorical_crossentropy: 2.8955 - val_weighted_accuracy: 0.5360 - val_weighted_sparse_categorical_crossentropy: 2.8955\n",
      "Epoch 2/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - accuracy: 0.5466 - loss: 0.9216 - sparse_categorical_crossentropy: 2.8952 - weighted_accuracy: 0.5466 - weighted_sparse_categorical_crossentropy: 2.8952 - val_accuracy: 0.6370 - val_loss: 0.8596 - val_sparse_categorical_crossentropy: 4.0927 - val_weighted_accuracy: 0.6370 - val_weighted_sparse_categorical_crossentropy: 4.0927\n",
      "Epoch 3/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - accuracy: 0.6427 - loss: 0.8079 - sparse_categorical_crossentropy: 3.7154 - weighted_accuracy: 0.6427 - weighted_sparse_categorical_crossentropy: 3.7154 - val_accuracy: 0.6587 - val_loss: 0.7806 - val_sparse_categorical_crossentropy: 3.6961 - val_weighted_accuracy: 0.6587 - val_weighted_sparse_categorical_crossentropy: 3.6961\n",
      "Epoch 4/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - accuracy: 0.7494 - loss: 0.6000 - sparse_categorical_crossentropy: 2.3093 - weighted_accuracy: 0.7494 - weighted_sparse_categorical_crossentropy: 2.3093 - val_accuracy: 0.6963 - val_loss: 0.6984 - val_sparse_categorical_crossentropy: 2.9058 - val_weighted_accuracy: 0.6963 - val_weighted_sparse_categorical_crossentropy: 2.9058\n",
      "Epoch 5/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - accuracy: 0.8174 - loss: 0.4467 - sparse_categorical_crossentropy: 1.3105 - weighted_accuracy: 0.8174 - weighted_sparse_categorical_crossentropy: 1.3105 - val_accuracy: 0.6992 - val_loss: 0.7777 - val_sparse_categorical_crossentropy: 2.6385 - val_weighted_accuracy: 0.6992 - val_weighted_sparse_categorical_crossentropy: 2.6385\n",
      "Epoch 6/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - accuracy: 0.8555 - loss: 0.3525 - sparse_categorical_crossentropy: 0.9046 - weighted_accuracy: 0.8555 - weighted_sparse_categorical_crossentropy: 0.9046 - val_accuracy: 0.6895 - val_loss: 0.8185 - val_sparse_categorical_crossentropy: 2.5212 - val_weighted_accuracy: 0.6895 - val_weighted_sparse_categorical_crossentropy: 2.5212\n",
      "Epoch 7/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 46ms/step - accuracy: 0.8898 - loss: 0.2574 - sparse_categorical_crossentropy: 0.5199 - weighted_accuracy: 0.8898 - weighted_sparse_categorical_crossentropy: 0.5199 - val_accuracy: 0.6752 - val_loss: 0.9088 - val_sparse_categorical_crossentropy: 2.6748 - val_weighted_accuracy: 0.6752 - val_weighted_sparse_categorical_crossentropy: 2.6748\n",
      "Epoch 8/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - accuracy: 0.9085 - loss: 0.2182 - sparse_categorical_crossentropy: 0.4253 - weighted_accuracy: 0.9085 - weighted_sparse_categorical_crossentropy: 0.4253 - val_accuracy: 0.6821 - val_loss: 1.0908 - val_sparse_categorical_crossentropy: 2.8783 - val_weighted_accuracy: 0.6821 - val_weighted_sparse_categorical_crossentropy: 2.8783\n",
      "Epoch 9/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 49ms/step - accuracy: 0.9146 - loss: 0.1872 - sparse_categorical_crossentropy: 0.3333 - weighted_accuracy: 0.9146 - weighted_sparse_categorical_crossentropy: 0.3333 - val_accuracy: 0.6707 - val_loss: 1.2018 - val_sparse_categorical_crossentropy: 3.0355 - val_weighted_accuracy: 0.6707 - val_weighted_sparse_categorical_crossentropy: 3.0355\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step\n",
      "Fold 0\n",
      "Epoch 1/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5023 - loss: 1.0615 - sparse_categorical_crossentropy: 4.4016 - weighted_accuracy: 0.5023 - weighted_sparse_categorical_crossentropy: 4.4016 - val_accuracy: 0.5368 - val_loss: 0.9719 - val_sparse_categorical_crossentropy: 3.9294 - val_weighted_accuracy: 0.5368 - val_weighted_sparse_categorical_crossentropy: 3.9294\n",
      "Epoch 2/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5445 - loss: 0.9472 - sparse_categorical_crossentropy: 3.7528 - weighted_accuracy: 0.5445 - weighted_sparse_categorical_crossentropy: 3.7528 - val_accuracy: 0.5596 - val_loss: 0.9219 - val_sparse_categorical_crossentropy: 3.6434 - val_weighted_accuracy: 0.5596 - val_weighted_sparse_categorical_crossentropy: 3.6434\n",
      "Epoch 3/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6033 - loss: 0.8902 - sparse_categorical_crossentropy: 3.5223 - weighted_accuracy: 0.6033 - weighted_sparse_categorical_crossentropy: 3.5223 - val_accuracy: 0.6104 - val_loss: 0.8891 - val_sparse_categorical_crossentropy: 3.6114 - val_weighted_accuracy: 0.6104 - val_weighted_sparse_categorical_crossentropy: 3.6114\n",
      "Epoch 4/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6387 - loss: 0.8484 - sparse_categorical_crossentropy: 3.2758 - weighted_accuracy: 0.6387 - weighted_sparse_categorical_crossentropy: 3.2758 - val_accuracy: 0.6269 - val_loss: 0.8656 - val_sparse_categorical_crossentropy: 3.6786 - val_weighted_accuracy: 0.6269 - val_weighted_sparse_categorical_crossentropy: 3.6786\n",
      "Epoch 5/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6457 - loss: 0.8164 - sparse_categorical_crossentropy: 3.3691 - weighted_accuracy: 0.6457 - weighted_sparse_categorical_crossentropy: 3.3691 - val_accuracy: 0.6246 - val_loss: 0.8459 - val_sparse_categorical_crossentropy: 3.7928 - val_weighted_accuracy: 0.6246 - val_weighted_sparse_categorical_crossentropy: 3.7928\n",
      "Epoch 6/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6859 - loss: 0.7572 - sparse_categorical_crossentropy: 2.9722 - weighted_accuracy: 0.6859 - weighted_sparse_categorical_crossentropy: 2.9722 - val_accuracy: 0.6418 - val_loss: 0.8277 - val_sparse_categorical_crossentropy: 3.6674 - val_weighted_accuracy: 0.6418 - val_weighted_sparse_categorical_crossentropy: 3.6674\n",
      "Epoch 7/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6912 - loss: 0.7538 - sparse_categorical_crossentropy: 3.1742 - weighted_accuracy: 0.6912 - weighted_sparse_categorical_crossentropy: 3.1742 - val_accuracy: 0.6515 - val_loss: 0.8107 - val_sparse_categorical_crossentropy: 3.6782 - val_weighted_accuracy: 0.6515 - val_weighted_sparse_categorical_crossentropy: 3.6782\n",
      "Epoch 8/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7137 - loss: 0.7072 - sparse_categorical_crossentropy: 2.8867 - weighted_accuracy: 0.7137 - weighted_sparse_categorical_crossentropy: 2.8867 - val_accuracy: 0.6554 - val_loss: 0.7952 - val_sparse_categorical_crossentropy: 3.7171 - val_weighted_accuracy: 0.6554 - val_weighted_sparse_categorical_crossentropy: 3.7171\n",
      "Epoch 9/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7180 - loss: 0.6753 - sparse_categorical_crossentropy: 2.6636 - weighted_accuracy: 0.7180 - weighted_sparse_categorical_crossentropy: 2.6636 - val_accuracy: 0.6646 - val_loss: 0.7793 - val_sparse_categorical_crossentropy: 3.6577 - val_weighted_accuracy: 0.6646 - val_weighted_sparse_categorical_crossentropy: 3.6577\n",
      "Epoch 10/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7416 - loss: 0.6513 - sparse_categorical_crossentropy: 2.5727 - weighted_accuracy: 0.7416 - weighted_sparse_categorical_crossentropy: 2.5727 - val_accuracy: 0.6657 - val_loss: 0.7645 - val_sparse_categorical_crossentropy: 3.5238 - val_weighted_accuracy: 0.6657 - val_weighted_sparse_categorical_crossentropy: 3.5238\n",
      "Epoch 11/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7420 - loss: 0.6327 - sparse_categorical_crossentropy: 2.3898 - weighted_accuracy: 0.7420 - weighted_sparse_categorical_crossentropy: 2.3898 - val_accuracy: 0.6714 - val_loss: 0.7518 - val_sparse_categorical_crossentropy: 3.4624 - val_weighted_accuracy: 0.6714 - val_weighted_sparse_categorical_crossentropy: 3.4624\n",
      "Epoch 12/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7648 - loss: 0.5824 - sparse_categorical_crossentropy: 2.1268 - weighted_accuracy: 0.7648 - weighted_sparse_categorical_crossentropy: 2.1268 - val_accuracy: 0.6811 - val_loss: 0.7404 - val_sparse_categorical_crossentropy: 3.4093 - val_weighted_accuracy: 0.6811 - val_weighted_sparse_categorical_crossentropy: 3.4093\n",
      "Epoch 13/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7778 - loss: 0.5748 - sparse_categorical_crossentropy: 2.1087 - weighted_accuracy: 0.7778 - weighted_sparse_categorical_crossentropy: 2.1087 - val_accuracy: 0.6840 - val_loss: 0.7301 - val_sparse_categorical_crossentropy: 3.3352 - val_weighted_accuracy: 0.6840 - val_weighted_sparse_categorical_crossentropy: 3.3352\n",
      "Epoch 14/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7910 - loss: 0.5494 - sparse_categorical_crossentropy: 1.9306 - weighted_accuracy: 0.7910 - weighted_sparse_categorical_crossentropy: 1.9306 - val_accuracy: 0.6805 - val_loss: 0.7214 - val_sparse_categorical_crossentropy: 3.2193 - val_weighted_accuracy: 0.6805 - val_weighted_sparse_categorical_crossentropy: 3.2193\n",
      "Epoch 15/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7961 - loss: 0.5304 - sparse_categorical_crossentropy: 1.7395 - weighted_accuracy: 0.7961 - weighted_sparse_categorical_crossentropy: 1.7395 - val_accuracy: 0.6834 - val_loss: 0.7159 - val_sparse_categorical_crossentropy: 3.1820 - val_weighted_accuracy: 0.6834 - val_weighted_sparse_categorical_crossentropy: 3.1820\n",
      "Epoch 16/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8162 - loss: 0.4941 - sparse_categorical_crossentropy: 1.5041 - weighted_accuracy: 0.8162 - weighted_sparse_categorical_crossentropy: 1.5041 - val_accuracy: 0.6800 - val_loss: 0.7121 - val_sparse_categorical_crossentropy: 3.1650 - val_weighted_accuracy: 0.6800 - val_weighted_sparse_categorical_crossentropy: 3.1650\n",
      "Epoch 17/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8212 - loss: 0.4833 - sparse_categorical_crossentropy: 1.4510 - weighted_accuracy: 0.8212 - weighted_sparse_categorical_crossentropy: 1.4510 - val_accuracy: 0.6805 - val_loss: 0.7083 - val_sparse_categorical_crossentropy: 3.0691 - val_weighted_accuracy: 0.6805 - val_weighted_sparse_categorical_crossentropy: 3.0691\n",
      "Epoch 18/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8322 - loss: 0.4672 - sparse_categorical_crossentropy: 1.2842 - weighted_accuracy: 0.8322 - weighted_sparse_categorical_crossentropy: 1.2842 - val_accuracy: 0.6828 - val_loss: 0.7056 - val_sparse_categorical_crossentropy: 2.9819 - val_weighted_accuracy: 0.6828 - val_weighted_sparse_categorical_crossentropy: 2.9819\n",
      "Epoch 19/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8409 - loss: 0.4401 - sparse_categorical_crossentropy: 1.2341 - weighted_accuracy: 0.8409 - weighted_sparse_categorical_crossentropy: 1.2341 - val_accuracy: 0.6857 - val_loss: 0.7061 - val_sparse_categorical_crossentropy: 2.9834 - val_weighted_accuracy: 0.6857 - val_weighted_sparse_categorical_crossentropy: 2.9834\n",
      "Epoch 20/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8368 - loss: 0.4331 - sparse_categorical_crossentropy: 1.2541 - weighted_accuracy: 0.8368 - weighted_sparse_categorical_crossentropy: 1.2541 - val_accuracy: 0.6885 - val_loss: 0.7068 - val_sparse_categorical_crossentropy: 3.0131 - val_weighted_accuracy: 0.6885 - val_weighted_sparse_categorical_crossentropy: 3.0131\n",
      "Epoch 21/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8492 - loss: 0.4037 - sparse_categorical_crossentropy: 1.0475 - weighted_accuracy: 0.8492 - weighted_sparse_categorical_crossentropy: 1.0475 - val_accuracy: 0.6885 - val_loss: 0.7074 - val_sparse_categorical_crossentropy: 2.9818 - val_weighted_accuracy: 0.6885 - val_weighted_sparse_categorical_crossentropy: 2.9818\n",
      "Epoch 22/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8485 - loss: 0.4117 - sparse_categorical_crossentropy: 1.1002 - weighted_accuracy: 0.8485 - weighted_sparse_categorical_crossentropy: 1.1002 - val_accuracy: 0.6885 - val_loss: 0.7116 - val_sparse_categorical_crossentropy: 2.9728 - val_weighted_accuracy: 0.6885 - val_weighted_sparse_categorical_crossentropy: 2.9728\n",
      "Epoch 23/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8544 - loss: 0.3869 - sparse_categorical_crossentropy: 1.0043 - weighted_accuracy: 0.8544 - weighted_sparse_categorical_crossentropy: 1.0043 - val_accuracy: 0.6840 - val_loss: 0.7131 - val_sparse_categorical_crossentropy: 2.9752 - val_weighted_accuracy: 0.6840 - val_weighted_sparse_categorical_crossentropy: 2.9752\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Fold 1\n",
      "Epoch 1/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5177 - loss: 1.0617 - sparse_categorical_crossentropy: 3.5410 - weighted_accuracy: 0.5177 - weighted_sparse_categorical_crossentropy: 3.5410 - val_accuracy: 0.5365 - val_loss: 0.9732 - val_sparse_categorical_crossentropy: 4.4099 - val_weighted_accuracy: 0.5365 - val_weighted_sparse_categorical_crossentropy: 4.4099\n",
      "Epoch 2/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5289 - loss: 0.9635 - sparse_categorical_crossentropy: 4.0406 - weighted_accuracy: 0.5289 - weighted_sparse_categorical_crossentropy: 4.0406 - val_accuracy: 0.5428 - val_loss: 0.9267 - val_sparse_categorical_crossentropy: 3.8694 - val_weighted_accuracy: 0.5428 - val_weighted_sparse_categorical_crossentropy: 3.8694\n",
      "Epoch 3/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5579 - loss: 0.9074 - sparse_categorical_crossentropy: 3.8429 - weighted_accuracy: 0.5579 - weighted_sparse_categorical_crossentropy: 3.8429 - val_accuracy: 0.5953 - val_loss: 0.8878 - val_sparse_categorical_crossentropy: 3.7645 - val_weighted_accuracy: 0.5953 - val_weighted_sparse_categorical_crossentropy: 3.7645\n",
      "Epoch 4/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6038 - loss: 0.8602 - sparse_categorical_crossentropy: 3.7271 - weighted_accuracy: 0.6038 - weighted_sparse_categorical_crossentropy: 3.7271 - val_accuracy: 0.6187 - val_loss: 0.8566 - val_sparse_categorical_crossentropy: 3.8531 - val_weighted_accuracy: 0.6187 - val_weighted_sparse_categorical_crossentropy: 3.8531\n",
      "Epoch 5/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6432 - loss: 0.8290 - sparse_categorical_crossentropy: 3.5634 - weighted_accuracy: 0.6432 - weighted_sparse_categorical_crossentropy: 3.5634 - val_accuracy: 0.6387 - val_loss: 0.8308 - val_sparse_categorical_crossentropy: 3.6216 - val_weighted_accuracy: 0.6387 - val_weighted_sparse_categorical_crossentropy: 3.6216\n",
      "Epoch 6/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6589 - loss: 0.7954 - sparse_categorical_crossentropy: 3.2519 - weighted_accuracy: 0.6589 - weighted_sparse_categorical_crossentropy: 3.2519 - val_accuracy: 0.6490 - val_loss: 0.8112 - val_sparse_categorical_crossentropy: 3.5425 - val_weighted_accuracy: 0.6490 - val_weighted_sparse_categorical_crossentropy: 3.5425\n",
      "Epoch 7/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6655 - loss: 0.7758 - sparse_categorical_crossentropy: 3.3027 - weighted_accuracy: 0.6655 - weighted_sparse_categorical_crossentropy: 3.3027 - val_accuracy: 0.6587 - val_loss: 0.7936 - val_sparse_categorical_crossentropy: 3.5353 - val_weighted_accuracy: 0.6587 - val_weighted_sparse_categorical_crossentropy: 3.5353\n",
      "Epoch 8/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6890 - loss: 0.7433 - sparse_categorical_crossentropy: 3.0508 - weighted_accuracy: 0.6890 - weighted_sparse_categorical_crossentropy: 3.0508 - val_accuracy: 0.6667 - val_loss: 0.7772 - val_sparse_categorical_crossentropy: 3.4641 - val_weighted_accuracy: 0.6667 - val_weighted_sparse_categorical_crossentropy: 3.4641\n",
      "Epoch 9/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7128 - loss: 0.7123 - sparse_categorical_crossentropy: 2.8450 - weighted_accuracy: 0.7128 - weighted_sparse_categorical_crossentropy: 2.8450 - val_accuracy: 0.6747 - val_loss: 0.7613 - val_sparse_categorical_crossentropy: 3.3729 - val_weighted_accuracy: 0.6747 - val_weighted_sparse_categorical_crossentropy: 3.3729\n",
      "Epoch 10/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7403 - loss: 0.6643 - sparse_categorical_crossentropy: 2.5653 - weighted_accuracy: 0.7403 - weighted_sparse_categorical_crossentropy: 2.5653 - val_accuracy: 0.6866 - val_loss: 0.7467 - val_sparse_categorical_crossentropy: 3.2577 - val_weighted_accuracy: 0.6866 - val_weighted_sparse_categorical_crossentropy: 3.2577\n",
      "Epoch 11/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7473 - loss: 0.6440 - sparse_categorical_crossentropy: 2.2595 - weighted_accuracy: 0.7473 - weighted_sparse_categorical_crossentropy: 2.2595 - val_accuracy: 0.6946 - val_loss: 0.7342 - val_sparse_categorical_crossentropy: 3.1887 - val_weighted_accuracy: 0.6946 - val_weighted_sparse_categorical_crossentropy: 3.1887\n",
      "Epoch 12/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7588 - loss: 0.6073 - sparse_categorical_crossentropy: 2.1217 - weighted_accuracy: 0.7588 - weighted_sparse_categorical_crossentropy: 2.1217 - val_accuracy: 0.7095 - val_loss: 0.7221 - val_sparse_categorical_crossentropy: 3.0845 - val_weighted_accuracy: 0.7095 - val_weighted_sparse_categorical_crossentropy: 3.0845\n",
      "Epoch 13/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7732 - loss: 0.5898 - sparse_categorical_crossentropy: 1.9990 - weighted_accuracy: 0.7732 - weighted_sparse_categorical_crossentropy: 1.9990 - val_accuracy: 0.7129 - val_loss: 0.7124 - val_sparse_categorical_crossentropy: 3.0199 - val_weighted_accuracy: 0.7129 - val_weighted_sparse_categorical_crossentropy: 3.0199\n",
      "Epoch 14/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7814 - loss: 0.5792 - sparse_categorical_crossentropy: 1.9210 - weighted_accuracy: 0.7814 - weighted_sparse_categorical_crossentropy: 1.9210 - val_accuracy: 0.7106 - val_loss: 0.7047 - val_sparse_categorical_crossentropy: 2.9768 - val_weighted_accuracy: 0.7106 - val_weighted_sparse_categorical_crossentropy: 2.9768\n",
      "Epoch 15/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7927 - loss: 0.5347 - sparse_categorical_crossentropy: 1.6950 - weighted_accuracy: 0.7927 - weighted_sparse_categorical_crossentropy: 1.6950 - val_accuracy: 0.7129 - val_loss: 0.6991 - val_sparse_categorical_crossentropy: 2.9806 - val_weighted_accuracy: 0.7129 - val_weighted_sparse_categorical_crossentropy: 2.9806\n",
      "Epoch 16/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8168 - loss: 0.5064 - sparse_categorical_crossentropy: 1.6294 - weighted_accuracy: 0.8168 - weighted_sparse_categorical_crossentropy: 1.6294 - val_accuracy: 0.7175 - val_loss: 0.6934 - val_sparse_categorical_crossentropy: 2.9474 - val_weighted_accuracy: 0.7175 - val_weighted_sparse_categorical_crossentropy: 2.9474\n",
      "Epoch 17/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8086 - loss: 0.5034 - sparse_categorical_crossentropy: 1.5113 - weighted_accuracy: 0.8086 - weighted_sparse_categorical_crossentropy: 1.5113 - val_accuracy: 0.7175 - val_loss: 0.6899 - val_sparse_categorical_crossentropy: 2.9015 - val_weighted_accuracy: 0.7175 - val_weighted_sparse_categorical_crossentropy: 2.9015\n",
      "Epoch 18/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8228 - loss: 0.4721 - sparse_categorical_crossentropy: 1.3455 - weighted_accuracy: 0.8228 - weighted_sparse_categorical_crossentropy: 1.3455 - val_accuracy: 0.7169 - val_loss: 0.6879 - val_sparse_categorical_crossentropy: 2.8707 - val_weighted_accuracy: 0.7169 - val_weighted_sparse_categorical_crossentropy: 2.8707\n",
      "Epoch 19/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8284 - loss: 0.4709 - sparse_categorical_crossentropy: 1.3498 - weighted_accuracy: 0.8284 - weighted_sparse_categorical_crossentropy: 1.3498 - val_accuracy: 0.7152 - val_loss: 0.6868 - val_sparse_categorical_crossentropy: 2.8223 - val_weighted_accuracy: 0.7152 - val_weighted_sparse_categorical_crossentropy: 2.8223\n",
      "Epoch 20/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8309 - loss: 0.4528 - sparse_categorical_crossentropy: 1.1858 - weighted_accuracy: 0.8309 - weighted_sparse_categorical_crossentropy: 1.1858 - val_accuracy: 0.7118 - val_loss: 0.6875 - val_sparse_categorical_crossentropy: 2.8281 - val_weighted_accuracy: 0.7118 - val_weighted_sparse_categorical_crossentropy: 2.8281\n",
      "Epoch 21/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8362 - loss: 0.4339 - sparse_categorical_crossentropy: 1.0872 - weighted_accuracy: 0.8362 - weighted_sparse_categorical_crossentropy: 1.0872 - val_accuracy: 0.7112 - val_loss: 0.6874 - val_sparse_categorical_crossentropy: 2.7768 - val_weighted_accuracy: 0.7112 - val_weighted_sparse_categorical_crossentropy: 2.7768\n",
      "Epoch 22/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8375 - loss: 0.4269 - sparse_categorical_crossentropy: 1.0870 - weighted_accuracy: 0.8375 - weighted_sparse_categorical_crossentropy: 1.0870 - val_accuracy: 0.7112 - val_loss: 0.6905 - val_sparse_categorical_crossentropy: 2.8452 - val_weighted_accuracy: 0.7112 - val_weighted_sparse_categorical_crossentropy: 2.8452\n",
      "Epoch 23/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8431 - loss: 0.4072 - sparse_categorical_crossentropy: 1.0003 - weighted_accuracy: 0.8431 - weighted_sparse_categorical_crossentropy: 1.0003 - val_accuracy: 0.7078 - val_loss: 0.6932 - val_sparse_categorical_crossentropy: 2.7653 - val_weighted_accuracy: 0.7078 - val_weighted_sparse_categorical_crossentropy: 2.7653\n",
      "Epoch 24/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8451 - loss: 0.3945 - sparse_categorical_crossentropy: 0.9420 - weighted_accuracy: 0.8451 - weighted_sparse_categorical_crossentropy: 0.9420 - val_accuracy: 0.7112 - val_loss: 0.6972 - val_sparse_categorical_crossentropy: 2.7590 - val_weighted_accuracy: 0.7112 - val_weighted_sparse_categorical_crossentropy: 2.7590\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Fold 2\n",
      "Epoch 1/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5171 - loss: 1.0559 - sparse_categorical_crossentropy: 4.7241 - weighted_accuracy: 0.5171 - weighted_sparse_categorical_crossentropy: 4.7241 - val_accuracy: 0.5377 - val_loss: 0.9649 - val_sparse_categorical_crossentropy: 5.6586 - val_weighted_accuracy: 0.5377 - val_weighted_sparse_categorical_crossentropy: 5.6586\n",
      "Epoch 2/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5493 - loss: 0.9369 - sparse_categorical_crossentropy: 5.3774 - weighted_accuracy: 0.5493 - weighted_sparse_categorical_crossentropy: 5.3774 - val_accuracy: 0.5611 - val_loss: 0.9168 - val_sparse_categorical_crossentropy: 4.3410 - val_weighted_accuracy: 0.5611 - val_weighted_sparse_categorical_crossentropy: 4.3410\n",
      "Epoch 3/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5952 - loss: 0.8908 - sparse_categorical_crossentropy: 4.1171 - weighted_accuracy: 0.5952 - weighted_sparse_categorical_crossentropy: 4.1171 - val_accuracy: 0.6301 - val_loss: 0.8825 - val_sparse_categorical_crossentropy: 3.8124 - val_weighted_accuracy: 0.6301 - val_weighted_sparse_categorical_crossentropy: 3.8124\n",
      "Epoch 4/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6331 - loss: 0.8589 - sparse_categorical_crossentropy: 3.9630 - weighted_accuracy: 0.6331 - weighted_sparse_categorical_crossentropy: 3.9630 - val_accuracy: 0.6484 - val_loss: 0.8533 - val_sparse_categorical_crossentropy: 3.8778 - val_weighted_accuracy: 0.6484 - val_weighted_sparse_categorical_crossentropy: 3.8778\n",
      "Epoch 5/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6464 - loss: 0.8192 - sparse_categorical_crossentropy: 3.8814 - weighted_accuracy: 0.6464 - weighted_sparse_categorical_crossentropy: 3.8814 - val_accuracy: 0.6592 - val_loss: 0.8288 - val_sparse_categorical_crossentropy: 3.8458 - val_weighted_accuracy: 0.6592 - val_weighted_sparse_categorical_crossentropy: 3.8458\n",
      "Epoch 6/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6669 - loss: 0.7879 - sparse_categorical_crossentropy: 3.6124 - weighted_accuracy: 0.6669 - weighted_sparse_categorical_crossentropy: 3.6124 - val_accuracy: 0.6747 - val_loss: 0.8097 - val_sparse_categorical_crossentropy: 3.5750 - val_weighted_accuracy: 0.6747 - val_weighted_sparse_categorical_crossentropy: 3.5750\n",
      "Epoch 7/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6840 - loss: 0.7574 - sparse_categorical_crossentropy: 3.1817 - weighted_accuracy: 0.6840 - weighted_sparse_categorical_crossentropy: 3.1817 - val_accuracy: 0.6775 - val_loss: 0.7885 - val_sparse_categorical_crossentropy: 3.5752 - val_weighted_accuracy: 0.6775 - val_weighted_sparse_categorical_crossentropy: 3.5752\n",
      "Epoch 8/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6941 - loss: 0.7260 - sparse_categorical_crossentropy: 3.1348 - weighted_accuracy: 0.6941 - weighted_sparse_categorical_crossentropy: 3.1348 - val_accuracy: 0.6895 - val_loss: 0.7717 - val_sparse_categorical_crossentropy: 3.4875 - val_weighted_accuracy: 0.6895 - val_weighted_sparse_categorical_crossentropy: 3.4875\n",
      "Epoch 9/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7166 - loss: 0.6952 - sparse_categorical_crossentropy: 2.8137 - weighted_accuracy: 0.7166 - weighted_sparse_categorical_crossentropy: 2.8137 - val_accuracy: 0.6929 - val_loss: 0.7560 - val_sparse_categorical_crossentropy: 3.3815 - val_weighted_accuracy: 0.6929 - val_weighted_sparse_categorical_crossentropy: 3.3815\n",
      "Epoch 10/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7395 - loss: 0.6576 - sparse_categorical_crossentropy: 2.4716 - weighted_accuracy: 0.7395 - weighted_sparse_categorical_crossentropy: 2.4716 - val_accuracy: 0.6884 - val_loss: 0.7424 - val_sparse_categorical_crossentropy: 3.3545 - val_weighted_accuracy: 0.6884 - val_weighted_sparse_categorical_crossentropy: 3.3545\n",
      "Epoch 11/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7521 - loss: 0.6410 - sparse_categorical_crossentropy: 2.3471 - weighted_accuracy: 0.7521 - weighted_sparse_categorical_crossentropy: 2.3471 - val_accuracy: 0.6929 - val_loss: 0.7294 - val_sparse_categorical_crossentropy: 3.2597 - val_weighted_accuracy: 0.6929 - val_weighted_sparse_categorical_crossentropy: 3.2597\n",
      "Epoch 12/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7723 - loss: 0.5994 - sparse_categorical_crossentropy: 2.0562 - weighted_accuracy: 0.7723 - weighted_sparse_categorical_crossentropy: 2.0562 - val_accuracy: 0.6912 - val_loss: 0.7190 - val_sparse_categorical_crossentropy: 3.1594 - val_weighted_accuracy: 0.6912 - val_weighted_sparse_categorical_crossentropy: 3.1594\n",
      "Epoch 13/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7783 - loss: 0.5827 - sparse_categorical_crossentropy: 2.0600 - weighted_accuracy: 0.7783 - weighted_sparse_categorical_crossentropy: 2.0600 - val_accuracy: 0.6975 - val_loss: 0.7104 - val_sparse_categorical_crossentropy: 3.0880 - val_weighted_accuracy: 0.6975 - val_weighted_sparse_categorical_crossentropy: 3.0880\n",
      "Epoch 14/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7943 - loss: 0.5409 - sparse_categorical_crossentropy: 1.6881 - weighted_accuracy: 0.7943 - weighted_sparse_categorical_crossentropy: 1.6881 - val_accuracy: 0.6969 - val_loss: 0.7047 - val_sparse_categorical_crossentropy: 2.9800 - val_weighted_accuracy: 0.6969 - val_weighted_sparse_categorical_crossentropy: 2.9800\n",
      "Epoch 15/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8103 - loss: 0.5196 - sparse_categorical_crossentropy: 1.5705 - weighted_accuracy: 0.8103 - weighted_sparse_categorical_crossentropy: 1.5705 - val_accuracy: 0.6969 - val_loss: 0.6977 - val_sparse_categorical_crossentropy: 2.9833 - val_weighted_accuracy: 0.6969 - val_weighted_sparse_categorical_crossentropy: 2.9833\n",
      "Epoch 16/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8189 - loss: 0.5014 - sparse_categorical_crossentropy: 1.3626 - weighted_accuracy: 0.8189 - weighted_sparse_categorical_crossentropy: 1.3626 - val_accuracy: 0.6969 - val_loss: 0.6940 - val_sparse_categorical_crossentropy: 2.9288 - val_weighted_accuracy: 0.6969 - val_weighted_sparse_categorical_crossentropy: 2.9288\n",
      "Epoch 17/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8301 - loss: 0.4777 - sparse_categorical_crossentropy: 1.3657 - weighted_accuracy: 0.8301 - weighted_sparse_categorical_crossentropy: 1.3657 - val_accuracy: 0.6986 - val_loss: 0.6908 - val_sparse_categorical_crossentropy: 2.8950 - val_weighted_accuracy: 0.6986 - val_weighted_sparse_categorical_crossentropy: 2.8950\n",
      "Epoch 18/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8245 - loss: 0.4645 - sparse_categorical_crossentropy: 1.1996 - weighted_accuracy: 0.8245 - weighted_sparse_categorical_crossentropy: 1.1996 - val_accuracy: 0.6986 - val_loss: 0.6890 - val_sparse_categorical_crossentropy: 2.8617 - val_weighted_accuracy: 0.6986 - val_weighted_sparse_categorical_crossentropy: 2.8617\n",
      "Epoch 19/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8356 - loss: 0.4513 - sparse_categorical_crossentropy: 1.2054 - weighted_accuracy: 0.8356 - weighted_sparse_categorical_crossentropy: 1.2054 - val_accuracy: 0.7009 - val_loss: 0.6897 - val_sparse_categorical_crossentropy: 2.8529 - val_weighted_accuracy: 0.7009 - val_weighted_sparse_categorical_crossentropy: 2.8529\n",
      "Epoch 20/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8428 - loss: 0.4355 - sparse_categorical_crossentropy: 1.0419 - weighted_accuracy: 0.8428 - weighted_sparse_categorical_crossentropy: 1.0419 - val_accuracy: 0.6963 - val_loss: 0.6930 - val_sparse_categorical_crossentropy: 2.8721 - val_weighted_accuracy: 0.6963 - val_weighted_sparse_categorical_crossentropy: 2.8721\n",
      "Epoch 21/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8590 - loss: 0.3997 - sparse_categorical_crossentropy: 0.9557 - weighted_accuracy: 0.8590 - weighted_sparse_categorical_crossentropy: 0.9557 - val_accuracy: 0.6969 - val_loss: 0.6933 - val_sparse_categorical_crossentropy: 2.8177 - val_weighted_accuracy: 0.6969 - val_weighted_sparse_categorical_crossentropy: 2.8177\n",
      "Epoch 22/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8558 - loss: 0.3999 - sparse_categorical_crossentropy: 0.9161 - weighted_accuracy: 0.8558 - weighted_sparse_categorical_crossentropy: 0.9161 - val_accuracy: 0.6941 - val_loss: 0.6967 - val_sparse_categorical_crossentropy: 2.8310 - val_weighted_accuracy: 0.6941 - val_weighted_sparse_categorical_crossentropy: 2.8310\n",
      "Epoch 23/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8634 - loss: 0.3867 - sparse_categorical_crossentropy: 0.8271 - weighted_accuracy: 0.8634 - weighted_sparse_categorical_crossentropy: 0.8271 - val_accuracy: 0.6929 - val_loss: 0.6995 - val_sparse_categorical_crossentropy: 2.8447 - val_weighted_accuracy: 0.6929 - val_weighted_sparse_categorical_crossentropy: 2.8447\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_a275d_row0_col1, #T_a275d_row0_col2, #T_a275d_row0_col3, #T_a275d_row0_col4, #T_a275d_row0_col5, #T_a275d_row2_col0 {\n",
       "  background-color: green;\n",
       "}\n",
       "#T_a275d_row1_col0, #T_a275d_row1_col1, #T_a275d_row1_col2, #T_a275d_row1_col3, #T_a275d_row1_col4, #T_a275d_row1_col5 {\n",
       "  background-color: red;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_a275d\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_a275d_level0_col0\" class=\"col_heading level0 col0\" >cv_accuracy</th>\n",
       "      <th id=\"T_a275d_level0_col1\" class=\"col_heading level0 col1\" >cv_balanced_accuracy</th>\n",
       "      <th id=\"T_a275d_level0_col2\" class=\"col_heading level0 col2\" >cv_f1_macro</th>\n",
       "      <th id=\"T_a275d_level0_col3\" class=\"col_heading level0 col3\" >cv_f1_weighted</th>\n",
       "      <th id=\"T_a275d_level0_col4\" class=\"col_heading level0 col4\" >cv_precision_weighted</th>\n",
       "      <th id=\"T_a275d_level0_col5\" class=\"col_heading level0 col5\" >cv_cohen_kappa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_a275d_level0_row0\" class=\"row_heading level0 row0\" >lstm</th>\n",
       "      <td id=\"T_a275d_row0_col0\" class=\"data row0 col0\" >0.698310</td>\n",
       "      <td id=\"T_a275d_row0_col1\" class=\"data row0 col1\" >0.603850</td>\n",
       "      <td id=\"T_a275d_row0_col2\" class=\"data row0 col2\" >0.607821</td>\n",
       "      <td id=\"T_a275d_row0_col3\" class=\"data row0 col3\" >0.689325</td>\n",
       "      <td id=\"T_a275d_row0_col4\" class=\"data row0 col4\" >0.685393</td>\n",
       "      <td id=\"T_a275d_row0_col5\" class=\"data row0 col5\" >0.464702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a275d_level0_row1\" class=\"row_heading level0 row1\" >lstm2</th>\n",
       "      <td id=\"T_a275d_row1_col0\" class=\"data row1 col0\" >0.685564</td>\n",
       "      <td id=\"T_a275d_row1_col1\" class=\"data row1 col1\" >0.568468</td>\n",
       "      <td id=\"T_a275d_row1_col2\" class=\"data row1 col2\" >0.549480</td>\n",
       "      <td id=\"T_a275d_row1_col3\" class=\"data row1 col3\" >0.658259</td>\n",
       "      <td id=\"T_a275d_row1_col4\" class=\"data row1 col4\" >0.643336</td>\n",
       "      <td id=\"T_a275d_row1_col5\" class=\"data row1 col5\" >0.410696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a275d_level0_row2\" class=\"row_heading level0 row2\" >simple_embed</th>\n",
       "      <td id=\"T_a275d_row2_col0\" class=\"data row2 col0\" >0.698881</td>\n",
       "      <td id=\"T_a275d_row2_col1\" class=\"data row2 col1\" >0.579058</td>\n",
       "      <td id=\"T_a275d_row2_col2\" class=\"data row2 col2\" >0.589419</td>\n",
       "      <td id=\"T_a275d_row2_col3\" class=\"data row2 col3\" >0.679890</td>\n",
       "      <td id=\"T_a275d_row2_col4\" class=\"data row2 col4\" >0.679604</td>\n",
       "      <td id=\"T_a275d_row2_col5\" class=\"data row2 col5\" >0.443532</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x78967e6f12b0>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "restab = {}\n",
    "for name, model in [\n",
    "    (\"lstm\", lstm),\n",
    "    (\"lstm2\", lstm2),\n",
    "    (\"simple_embed\", simple_embed),\n",
    "]:\n",
    "    restab[name] = score_dl(model,\n",
    "                            X,\n",
    "                            y,\n",
    "                            method=ScoringMethod.CROSS_VAL_SCORE,\n",
    "                            epochs=50,\n",
    "                            batch_size=100,\n",
    "                            early_stopping=True,)\n",
    "\n",
    "\n",
    "pd.DataFrame(restab).T.style.highlight_max(color=\"green\", axis=0).highlight_min(color=\"red\", axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb79e767-3d2b-4c2e-88af-6d67297461b2",
   "metadata": {},
   "source": [
    "Everytime I run the above cell, I get different results. But generally, these deep learning models are worse than traditional models in both performance and time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6bb55ea1-0276-4e22-af2e-ac3f631f4b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def standardize(text):\n",
    "    regex_url = re.escape(r\"(http|www)\\S+\")\n",
    "    regex_twitter_mentions = re.escape(r\"@\\w+\")\n",
    "    regex_ticker = re.escape(r\"\\$[A-Za-z]{1,5}(\\.[A-Za-z]{1,3})?\")\n",
    "    regex_punctuation = re.escape(r\"[^\\w\\s']+\")\n",
    "\n",
    "    replacements = [\n",
    "        (regex_url, \"\"),\n",
    "        (regex_twitter_mentions, \"\"),\n",
    "        #(regex_ticker, \"\"),\n",
    "        (regex_punctuation, \"\"),\n",
    "    ] \n",
    "\n",
    "    text = tf.strings.lower(text)\n",
    "    for regex, replacement in replacements:\n",
    "        text = tf.strings.regex_replace(text, regex, replacement)\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b603215-bc94-424e-8606-767dc8370eee",
   "metadata": {},
   "source": [
    "Need to re-write `preprocessor` function to take tensors as input. I would like to add type-hints to all my functions, but dealing with tf/keras is already a pain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e24717b5-e7b7-4646-9161-dad29961950a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0\n",
      "Epoch 1/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 44ms/step - accuracy: 0.5270 - loss: 1.0096 - sparse_categorical_crossentropy: 5.4875 - weighted_accuracy: 0.5270 - weighted_sparse_categorical_crossentropy: 5.4875 - val_accuracy: 0.6030 - val_loss: 0.8990 - val_sparse_categorical_crossentropy: 4.6497 - val_weighted_accuracy: 0.6030 - val_weighted_sparse_categorical_crossentropy: 4.6497\n",
      "Epoch 2/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.6493 - loss: 0.8304 - sparse_categorical_crossentropy: 4.0744 - weighted_accuracy: 0.6493 - weighted_sparse_categorical_crossentropy: 4.0744 - val_accuracy: 0.6349 - val_loss: 0.8555 - val_sparse_categorical_crossentropy: 4.8735 - val_weighted_accuracy: 0.6349 - val_weighted_sparse_categorical_crossentropy: 4.8735\n",
      "Epoch 3/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.7132 - loss: 0.6918 - sparse_categorical_crossentropy: 3.9170 - weighted_accuracy: 0.7132 - weighted_sparse_categorical_crossentropy: 3.9170 - val_accuracy: 0.6634 - val_loss: 0.7830 - val_sparse_categorical_crossentropy: 4.4949 - val_weighted_accuracy: 0.6634 - val_weighted_sparse_categorical_crossentropy: 4.4949\n",
      "Epoch 4/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.7860 - loss: 0.5089 - sparse_categorical_crossentropy: 2.7323 - weighted_accuracy: 0.7860 - weighted_sparse_categorical_crossentropy: 2.7323 - val_accuracy: 0.6823 - val_loss: 0.8025 - val_sparse_categorical_crossentropy: 3.4874 - val_weighted_accuracy: 0.6823 - val_weighted_sparse_categorical_crossentropy: 3.4874\n",
      "Epoch 5/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.8484 - loss: 0.3873 - sparse_categorical_crossentropy: 1.2244 - weighted_accuracy: 0.8484 - weighted_sparse_categorical_crossentropy: 1.2244 - val_accuracy: 0.6731 - val_loss: 0.8496 - val_sparse_categorical_crossentropy: 3.4715 - val_weighted_accuracy: 0.6731 - val_weighted_sparse_categorical_crossentropy: 3.4715\n",
      "Epoch 6/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.8858 - loss: 0.2771 - sparse_categorical_crossentropy: 0.7325 - weighted_accuracy: 0.8858 - weighted_sparse_categorical_crossentropy: 0.7325 - val_accuracy: 0.6646 - val_loss: 0.8964 - val_sparse_categorical_crossentropy: 3.3725 - val_weighted_accuracy: 0.6646 - val_weighted_sparse_categorical_crossentropy: 3.3725\n",
      "Epoch 7/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.8898 - loss: 0.2518 - sparse_categorical_crossentropy: 0.5952 - weighted_accuracy: 0.8898 - weighted_sparse_categorical_crossentropy: 0.5952 - val_accuracy: 0.6560 - val_loss: 1.0269 - val_sparse_categorical_crossentropy: 3.3214 - val_weighted_accuracy: 0.6560 - val_weighted_sparse_categorical_crossentropy: 3.3214\n",
      "Epoch 8/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.9189 - loss: 0.1926 - sparse_categorical_crossentropy: 0.4209 - weighted_accuracy: 0.9189 - weighted_sparse_categorical_crossentropy: 0.4209 - val_accuracy: 0.6651 - val_loss: 1.2124 - val_sparse_categorical_crossentropy: 3.6987 - val_weighted_accuracy: 0.6651 - val_weighted_sparse_categorical_crossentropy: 3.6987\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step\n",
      "Fold 1\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.5222 - loss: 1.0310 - sparse_categorical_crossentropy: 5.2996 - weighted_accuracy: 0.5222 - weighted_sparse_categorical_crossentropy: 5.2996 - val_accuracy: 0.5765 - val_loss: 0.8947 - val_sparse_categorical_crossentropy: 4.4034 - val_weighted_accuracy: 0.5765 - val_weighted_sparse_categorical_crossentropy: 4.4034\n",
      "Epoch 2/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.6185 - loss: 0.8651 - sparse_categorical_crossentropy: 4.2236 - weighted_accuracy: 0.6185 - weighted_sparse_categorical_crossentropy: 4.2236 - val_accuracy: 0.6518 - val_loss: 0.7984 - val_sparse_categorical_crossentropy: 4.3086 - val_weighted_accuracy: 0.6518 - val_weighted_sparse_categorical_crossentropy: 4.3086\n",
      "Epoch 3/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.6909 - loss: 0.7045 - sparse_categorical_crossentropy: 4.1593 - weighted_accuracy: 0.6909 - weighted_sparse_categorical_crossentropy: 4.1593 - val_accuracy: 0.7021 - val_loss: 0.7448 - val_sparse_categorical_crossentropy: 4.1918 - val_weighted_accuracy: 0.7021 - val_weighted_sparse_categorical_crossentropy: 4.1918\n",
      "Epoch 4/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.8071 - loss: 0.5025 - sparse_categorical_crossentropy: 2.4044 - weighted_accuracy: 0.8071 - weighted_sparse_categorical_crossentropy: 2.4044 - val_accuracy: 0.7021 - val_loss: 0.7347 - val_sparse_categorical_crossentropy: 3.2437 - val_weighted_accuracy: 0.7021 - val_weighted_sparse_categorical_crossentropy: 3.2437\n",
      "Epoch 5/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.8440 - loss: 0.3865 - sparse_categorical_crossentropy: 1.2969 - weighted_accuracy: 0.8440 - weighted_sparse_categorical_crossentropy: 1.2969 - val_accuracy: 0.6986 - val_loss: 0.7896 - val_sparse_categorical_crossentropy: 3.1689 - val_weighted_accuracy: 0.6986 - val_weighted_sparse_categorical_crossentropy: 3.1689\n",
      "Epoch 6/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.8657 - loss: 0.3162 - sparse_categorical_crossentropy: 0.9309 - weighted_accuracy: 0.8657 - weighted_sparse_categorical_crossentropy: 0.9309 - val_accuracy: 0.7032 - val_loss: 0.9482 - val_sparse_categorical_crossentropy: 3.1455 - val_weighted_accuracy: 0.7032 - val_weighted_sparse_categorical_crossentropy: 3.1455\n",
      "Epoch 7/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.8834 - loss: 0.2616 - sparse_categorical_crossentropy: 0.6635 - weighted_accuracy: 0.8834 - weighted_sparse_categorical_crossentropy: 0.6635 - val_accuracy: 0.6855 - val_loss: 0.9312 - val_sparse_categorical_crossentropy: 3.0914 - val_weighted_accuracy: 0.6855 - val_weighted_sparse_categorical_crossentropy: 3.0914\n",
      "Epoch 8/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.9206 - loss: 0.2033 - sparse_categorical_crossentropy: 0.4105 - weighted_accuracy: 0.9206 - weighted_sparse_categorical_crossentropy: 0.4105 - val_accuracy: 0.6946 - val_loss: 1.2220 - val_sparse_categorical_crossentropy: 3.2209 - val_weighted_accuracy: 0.6946 - val_weighted_sparse_categorical_crossentropy: 3.2209\n",
      "Epoch 9/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.9114 - loss: 0.1966 - sparse_categorical_crossentropy: 0.3911 - weighted_accuracy: 0.9114 - weighted_sparse_categorical_crossentropy: 0.3911 - val_accuracy: 0.6872 - val_loss: 1.1367 - val_sparse_categorical_crossentropy: 3.2938 - val_weighted_accuracy: 0.6872 - val_weighted_sparse_categorical_crossentropy: 3.2938\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step\n",
      "Fold 2\n",
      "Epoch 1/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.5149 - loss: 1.0321 - sparse_categorical_crossentropy: 3.1803 - weighted_accuracy: 0.5149 - weighted_sparse_categorical_crossentropy: 3.1803 - val_accuracy: 0.5388 - val_loss: 0.9254 - val_sparse_categorical_crossentropy: 3.0262 - val_weighted_accuracy: 0.5388 - val_weighted_sparse_categorical_crossentropy: 3.0262\n",
      "Epoch 2/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.5782 - loss: 0.8780 - sparse_categorical_crossentropy: 3.0396 - weighted_accuracy: 0.5782 - weighted_sparse_categorical_crossentropy: 3.0396 - val_accuracy: 0.6010 - val_loss: 0.8521 - val_sparse_categorical_crossentropy: 4.0534 - val_weighted_accuracy: 0.6010 - val_weighted_sparse_categorical_crossentropy: 4.0534\n",
      "Epoch 3/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.6656 - loss: 0.7479 - sparse_categorical_crossentropy: 3.2131 - weighted_accuracy: 0.6656 - weighted_sparse_categorical_crossentropy: 3.2131 - val_accuracy: 0.6507 - val_loss: 0.8084 - val_sparse_categorical_crossentropy: 3.6197 - val_weighted_accuracy: 0.6507 - val_weighted_sparse_categorical_crossentropy: 3.6197\n",
      "Epoch 4/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.7969 - loss: 0.5090 - sparse_categorical_crossentropy: 1.6402 - weighted_accuracy: 0.7969 - weighted_sparse_categorical_crossentropy: 1.6402 - val_accuracy: 0.6849 - val_loss: 0.7350 - val_sparse_categorical_crossentropy: 2.8372 - val_weighted_accuracy: 0.6849 - val_weighted_sparse_categorical_crossentropy: 2.8372\n",
      "Epoch 5/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.8528 - loss: 0.3508 - sparse_categorical_crossentropy: 0.9443 - weighted_accuracy: 0.8528 - weighted_sparse_categorical_crossentropy: 0.9443 - val_accuracy: 0.6941 - val_loss: 0.8143 - val_sparse_categorical_crossentropy: 2.5279 - val_weighted_accuracy: 0.6941 - val_weighted_sparse_categorical_crossentropy: 2.5279\n",
      "Epoch 6/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.8773 - loss: 0.2890 - sparse_categorical_crossentropy: 0.7939 - weighted_accuracy: 0.8773 - weighted_sparse_categorical_crossentropy: 0.7939 - val_accuracy: 0.6884 - val_loss: 0.8524 - val_sparse_categorical_crossentropy: 2.7568 - val_weighted_accuracy: 0.6884 - val_weighted_sparse_categorical_crossentropy: 2.7568\n",
      "Epoch 7/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.8998 - loss: 0.2359 - sparse_categorical_crossentropy: 0.4642 - weighted_accuracy: 0.8998 - weighted_sparse_categorical_crossentropy: 0.4642 - val_accuracy: 0.6804 - val_loss: 0.9860 - val_sparse_categorical_crossentropy: 2.9020 - val_weighted_accuracy: 0.6804 - val_weighted_sparse_categorical_crossentropy: 2.9020\n",
      "Epoch 8/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.9182 - loss: 0.1876 - sparse_categorical_crossentropy: 0.3342 - weighted_accuracy: 0.9182 - weighted_sparse_categorical_crossentropy: 0.3342 - val_accuracy: 0.6769 - val_loss: 1.1421 - val_sparse_categorical_crossentropy: 2.9783 - val_weighted_accuracy: 0.6769 - val_weighted_sparse_categorical_crossentropy: 2.9783\n",
      "Epoch 9/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.9216 - loss: 0.1615 - sparse_categorical_crossentropy: 0.2414 - weighted_accuracy: 0.9216 - weighted_sparse_categorical_crossentropy: 0.2414 - val_accuracy: 0.6695 - val_loss: 1.1306 - val_sparse_categorical_crossentropy: 2.9750 - val_weighted_accuracy: 0.6695 - val_weighted_sparse_categorical_crossentropy: 2.9750\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step\n",
      "Fold 0\n",
      "Epoch 1/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 45ms/step - accuracy: 0.5106 - loss: 1.0230 - sparse_categorical_crossentropy: 5.2146 - weighted_accuracy: 0.5106 - weighted_sparse_categorical_crossentropy: 5.2146 - val_accuracy: 0.6161 - val_loss: 0.8928 - val_sparse_categorical_crossentropy: 5.4678 - val_weighted_accuracy: 0.6161 - val_weighted_sparse_categorical_crossentropy: 5.4678\n",
      "Epoch 2/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.6601 - loss: 0.8096 - sparse_categorical_crossentropy: 4.3313 - weighted_accuracy: 0.6601 - weighted_sparse_categorical_crossentropy: 4.3313 - val_accuracy: 0.6429 - val_loss: 0.8095 - val_sparse_categorical_crossentropy: 4.2269 - val_weighted_accuracy: 0.6429 - val_weighted_sparse_categorical_crossentropy: 4.2269\n",
      "Epoch 3/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.7095 - loss: 0.6700 - sparse_categorical_crossentropy: 3.2471 - weighted_accuracy: 0.7095 - weighted_sparse_categorical_crossentropy: 3.2471 - val_accuracy: 0.7017 - val_loss: 0.7344 - val_sparse_categorical_crossentropy: 3.6705 - val_weighted_accuracy: 0.7017 - val_weighted_sparse_categorical_crossentropy: 3.6705\n",
      "Epoch 4/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.7994 - loss: 0.5142 - sparse_categorical_crossentropy: 2.0829 - weighted_accuracy: 0.7994 - weighted_sparse_categorical_crossentropy: 2.0829 - val_accuracy: 0.6823 - val_loss: 0.7620 - val_sparse_categorical_crossentropy: 3.4058 - val_weighted_accuracy: 0.6823 - val_weighted_sparse_categorical_crossentropy: 3.4058\n",
      "Epoch 5/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.8438 - loss: 0.3743 - sparse_categorical_crossentropy: 1.2427 - weighted_accuracy: 0.8438 - weighted_sparse_categorical_crossentropy: 1.2427 - val_accuracy: 0.6897 - val_loss: 0.8281 - val_sparse_categorical_crossentropy: 3.1383 - val_weighted_accuracy: 0.6897 - val_weighted_sparse_categorical_crossentropy: 3.1383\n",
      "Epoch 6/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - accuracy: 0.8790 - loss: 0.2668 - sparse_categorical_crossentropy: 0.6964 - weighted_accuracy: 0.8790 - weighted_sparse_categorical_crossentropy: 0.6964 - val_accuracy: 0.6828 - val_loss: 0.8734 - val_sparse_categorical_crossentropy: 3.0362 - val_weighted_accuracy: 0.6828 - val_weighted_sparse_categorical_crossentropy: 3.0362\n",
      "Epoch 7/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - accuracy: 0.9026 - loss: 0.2282 - sparse_categorical_crossentropy: 0.4217 - weighted_accuracy: 0.9026 - weighted_sparse_categorical_crossentropy: 0.4217 - val_accuracy: 0.6640 - val_loss: 0.9192 - val_sparse_categorical_crossentropy: 3.1217 - val_weighted_accuracy: 0.6640 - val_weighted_sparse_categorical_crossentropy: 3.1217\n",
      "Epoch 8/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - accuracy: 0.9102 - loss: 0.1898 - sparse_categorical_crossentropy: 0.2981 - weighted_accuracy: 0.9102 - weighted_sparse_categorical_crossentropy: 0.2981 - val_accuracy: 0.6629 - val_loss: 1.1489 - val_sparse_categorical_crossentropy: 3.4990 - val_weighted_accuracy: 0.6629 - val_weighted_sparse_categorical_crossentropy: 3.4990\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step\n",
      "Fold 1\n",
      "Epoch 1/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 46ms/step - accuracy: 0.4957 - loss: 1.0333 - sparse_categorical_crossentropy: 5.9970 - weighted_accuracy: 0.4957 - weighted_sparse_categorical_crossentropy: 5.9970 - val_accuracy: 0.6273 - val_loss: 0.8742 - val_sparse_categorical_crossentropy: 4.5689 - val_weighted_accuracy: 0.6273 - val_weighted_sparse_categorical_crossentropy: 4.5689\n",
      "Epoch 2/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.6337 - loss: 0.8489 - sparse_categorical_crossentropy: 4.1060 - weighted_accuracy: 0.6337 - weighted_sparse_categorical_crossentropy: 4.1060 - val_accuracy: 0.6724 - val_loss: 0.7834 - val_sparse_categorical_crossentropy: 4.4097 - val_weighted_accuracy: 0.6724 - val_weighted_sparse_categorical_crossentropy: 4.4097\n",
      "Epoch 3/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - accuracy: 0.7299 - loss: 0.6358 - sparse_categorical_crossentropy: 3.4481 - weighted_accuracy: 0.7299 - weighted_sparse_categorical_crossentropy: 3.4481 - val_accuracy: 0.7163 - val_loss: 0.6978 - val_sparse_categorical_crossentropy: 3.3151 - val_weighted_accuracy: 0.7163 - val_weighted_sparse_categorical_crossentropy: 3.3151\n",
      "Epoch 4/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.8126 - loss: 0.4620 - sparse_categorical_crossentropy: 1.9732 - weighted_accuracy: 0.8126 - weighted_sparse_categorical_crossentropy: 1.9732 - val_accuracy: 0.7106 - val_loss: 0.7300 - val_sparse_categorical_crossentropy: 3.2345 - val_weighted_accuracy: 0.7106 - val_weighted_sparse_categorical_crossentropy: 3.2345\n",
      "Epoch 5/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - accuracy: 0.8521 - loss: 0.3386 - sparse_categorical_crossentropy: 1.1317 - weighted_accuracy: 0.8521 - weighted_sparse_categorical_crossentropy: 1.1317 - val_accuracy: 0.7140 - val_loss: 0.8235 - val_sparse_categorical_crossentropy: 2.9809 - val_weighted_accuracy: 0.7140 - val_weighted_sparse_categorical_crossentropy: 2.9809\n",
      "Epoch 6/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - accuracy: 0.8841 - loss: 0.2528 - sparse_categorical_crossentropy: 0.5260 - weighted_accuracy: 0.8841 - weighted_sparse_categorical_crossentropy: 0.5260 - val_accuracy: 0.6975 - val_loss: 0.9033 - val_sparse_categorical_crossentropy: 3.1461 - val_weighted_accuracy: 0.6975 - val_weighted_sparse_categorical_crossentropy: 3.1461\n",
      "Epoch 7/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - accuracy: 0.9143 - loss: 0.1902 - sparse_categorical_crossentropy: 0.3817 - weighted_accuracy: 0.9143 - weighted_sparse_categorical_crossentropy: 0.3817 - val_accuracy: 0.6986 - val_loss: 1.0413 - val_sparse_categorical_crossentropy: 3.2010 - val_weighted_accuracy: 0.6986 - val_weighted_sparse_categorical_crossentropy: 3.2010\n",
      "Epoch 8/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step - accuracy: 0.9127 - loss: 0.1669 - sparse_categorical_crossentropy: 0.2436 - weighted_accuracy: 0.9127 - weighted_sparse_categorical_crossentropy: 0.2436 - val_accuracy: 0.6935 - val_loss: 1.3146 - val_sparse_categorical_crossentropy: 3.2300 - val_weighted_accuracy: 0.6935 - val_weighted_sparse_categorical_crossentropy: 3.2300\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step\n",
      "Fold 2\n",
      "Epoch 1/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 48ms/step - accuracy: 0.5296 - loss: 1.0167 - sparse_categorical_crossentropy: 3.9784 - weighted_accuracy: 0.5296 - weighted_sparse_categorical_crossentropy: 3.9784 - val_accuracy: 0.6393 - val_loss: 0.8599 - val_sparse_categorical_crossentropy: 4.3020 - val_weighted_accuracy: 0.6393 - val_weighted_sparse_categorical_crossentropy: 4.3020\n",
      "Epoch 2/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.6441 - loss: 0.8245 - sparse_categorical_crossentropy: 4.5808 - weighted_accuracy: 0.6441 - weighted_sparse_categorical_crossentropy: 4.5808 - val_accuracy: 0.6752 - val_loss: 0.7589 - val_sparse_categorical_crossentropy: 3.7605 - val_weighted_accuracy: 0.6752 - val_weighted_sparse_categorical_crossentropy: 3.7605\n",
      "Epoch 3/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.7227 - loss: 0.6593 - sparse_categorical_crossentropy: 3.1195 - weighted_accuracy: 0.7227 - weighted_sparse_categorical_crossentropy: 3.1195 - val_accuracy: 0.6963 - val_loss: 0.7093 - val_sparse_categorical_crossentropy: 3.5788 - val_weighted_accuracy: 0.6963 - val_weighted_sparse_categorical_crossentropy: 3.5788\n",
      "Epoch 4/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.8067 - loss: 0.4764 - sparse_categorical_crossentropy: 2.0530 - weighted_accuracy: 0.8067 - weighted_sparse_categorical_crossentropy: 2.0530 - val_accuracy: 0.7180 - val_loss: 0.6831 - val_sparse_categorical_crossentropy: 3.0616 - val_weighted_accuracy: 0.7180 - val_weighted_sparse_categorical_crossentropy: 3.0616\n",
      "Epoch 5/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.8481 - loss: 0.3607 - sparse_categorical_crossentropy: 1.3371 - weighted_accuracy: 0.8481 - weighted_sparse_categorical_crossentropy: 1.3371 - val_accuracy: 0.6986 - val_loss: 0.7351 - val_sparse_categorical_crossentropy: 2.9007 - val_weighted_accuracy: 0.6986 - val_weighted_sparse_categorical_crossentropy: 2.9007\n",
      "Epoch 6/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - accuracy: 0.8532 - loss: 0.3321 - sparse_categorical_crossentropy: 0.9645 - weighted_accuracy: 0.8532 - weighted_sparse_categorical_crossentropy: 0.9645 - val_accuracy: 0.7032 - val_loss: 0.7802 - val_sparse_categorical_crossentropy: 2.8602 - val_weighted_accuracy: 0.7032 - val_weighted_sparse_categorical_crossentropy: 2.8602\n",
      "Epoch 7/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - accuracy: 0.9010 - loss: 0.2365 - sparse_categorical_crossentropy: 0.5912 - weighted_accuracy: 0.9010 - weighted_sparse_categorical_crossentropy: 0.5912 - val_accuracy: 0.6924 - val_loss: 0.8718 - val_sparse_categorical_crossentropy: 2.8817 - val_weighted_accuracy: 0.6924 - val_weighted_sparse_categorical_crossentropy: 2.8817\n",
      "Epoch 8/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - accuracy: 0.9062 - loss: 0.2102 - sparse_categorical_crossentropy: 0.4497 - weighted_accuracy: 0.9062 - weighted_sparse_categorical_crossentropy: 0.4497 - val_accuracy: 0.6849 - val_loss: 1.0741 - val_sparse_categorical_crossentropy: 3.1396 - val_weighted_accuracy: 0.6849 - val_weighted_sparse_categorical_crossentropy: 3.1396\n",
      "Epoch 9/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step - accuracy: 0.9180 - loss: 0.1745 - sparse_categorical_crossentropy: 0.3318 - weighted_accuracy: 0.9180 - weighted_sparse_categorical_crossentropy: 0.3318 - val_accuracy: 0.6707 - val_loss: 1.2105 - val_sparse_categorical_crossentropy: 3.2732 - val_weighted_accuracy: 0.6707 - val_weighted_sparse_categorical_crossentropy: 3.2732\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_3b5bf_row0_col0, #T_3b5bf_row0_col3, #T_3b5bf_row0_col4, #T_3b5bf_row0_col5, #T_3b5bf_row1_col1, #T_3b5bf_row1_col2 {\n",
       "  background-color: red;\n",
       "}\n",
       "#T_3b5bf_row0_col1, #T_3b5bf_row0_col2, #T_3b5bf_row1_col0, #T_3b5bf_row1_col3, #T_3b5bf_row1_col4, #T_3b5bf_row1_col5 {\n",
       "  background-color: green;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_3b5bf\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_3b5bf_level0_col0\" class=\"col_heading level0 col0\" >cv_accuracy</th>\n",
       "      <th id=\"T_3b5bf_level0_col1\" class=\"col_heading level0 col1\" >cv_balanced_accuracy</th>\n",
       "      <th id=\"T_3b5bf_level0_col2\" class=\"col_heading level0 col2\" >cv_f1_macro</th>\n",
       "      <th id=\"T_3b5bf_level0_col3\" class=\"col_heading level0 col3\" >cv_f1_weighted</th>\n",
       "      <th id=\"T_3b5bf_level0_col4\" class=\"col_heading level0 col4\" >cv_precision_weighted</th>\n",
       "      <th id=\"T_3b5bf_level0_col5\" class=\"col_heading level0 col5\" >cv_cohen_kappa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_3b5bf_level0_row0\" class=\"row_heading level0 row0\" >lstm</th>\n",
       "      <td id=\"T_3b5bf_row0_col0\" class=\"data row0 col0\" >0.683473</td>\n",
       "      <td id=\"T_3b5bf_row0_col1\" class=\"data row0 col1\" >0.600084</td>\n",
       "      <td id=\"T_3b5bf_row0_col2\" class=\"data row0 col2\" >0.579975</td>\n",
       "      <td id=\"T_3b5bf_row0_col3\" class=\"data row0 col3\" >0.669220</td>\n",
       "      <td id=\"T_3b5bf_row0_col4\" class=\"data row0 col4\" >0.661498</td>\n",
       "      <td id=\"T_3b5bf_row0_col5\" class=\"data row0 col5\" >0.433781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3b5bf_level0_row1\" class=\"row_heading level0 row1\" >lstm+standardize</th>\n",
       "      <td id=\"T_3b5bf_row1_col0\" class=\"data row1 col0\" >0.712005</td>\n",
       "      <td id=\"T_3b5bf_row1_col1\" class=\"data row1 col1\" >0.574467</td>\n",
       "      <td id=\"T_3b5bf_row1_col2\" class=\"data row1 col2\" >0.569813</td>\n",
       "      <td id=\"T_3b5bf_row1_col3\" class=\"data row1 col3\" >0.680743</td>\n",
       "      <td id=\"T_3b5bf_row1_col4\" class=\"data row1 col4\" >0.701341</td>\n",
       "      <td id=\"T_3b5bf_row1_col5\" class=\"data row1 col5\" >0.439450</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7896e03b5d30>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from functools import partial\n",
    "\n",
    "restab = {}\n",
    "for name, model in [\n",
    "    (\"lstm\", lstm),\n",
    "    (\"lstm+standardize\", partial(lstm, standardize=standardize)),\n",
    "]:\n",
    "    restab[name] = score_dl(model,\n",
    "                            X,\n",
    "                            y,\n",
    "                            method=ScoringMethod.CROSS_VAL_SCORE,\n",
    "                            epochs=50,\n",
    "                            batch_size=100,\n",
    "                            early_stopping=True,)\n",
    "\n",
    "\n",
    "pd.DataFrame(restab).T.style.highlight_max(color=\"green\", axis=0).highlight_min(color=\"red\", axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4508f23-73b3-4472-ad91-de790ce3345b",
   "metadata": {},
   "source": [
    "Once again, the above cell gives different results everytime."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb3ca95b-b672-4ff6-b08e-f0402a50f05f",
   "metadata": {},
   "source": [
    "## Keras Tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "cb9b2a92-b02c-44ab-bd6e-81c1024db076",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 10 Complete [00h 00m 34s]\n",
      "val_loss: 0.678244948387146\n",
      "\n",
      "Best val_loss So Far: 0.6639225482940674\n",
      "Total elapsed time: 00h 06m 38s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/recurze/.local/lib/python3.12/site-packages/keras/src/saving/saving_lib.py:719: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 36 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">62</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │       <span style=\"color: #00af00; text-decoration-color: #00af00\">131,072</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">62</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">10,368</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,624</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,088</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">195</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m62\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │       \u001b[38;5;34m131,072\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional (\u001b[38;5;33mBidirectional\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m62\u001b[0m, \u001b[38;5;34m32\u001b[0m)         │        \u001b[38;5;34m10,368\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_1 (\u001b[38;5;33mBidirectional\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │         \u001b[38;5;34m2,624\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m1,088\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)              │           \u001b[38;5;34m195\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">145,347</span> (567.76 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m145,347\u001b[0m (567.76 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">145,347</span> (567.76 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m145,347\u001b[0m (567.76 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import keras_tuner\n",
    "import random\n",
    "import shutil\n",
    "\n",
    "def choice_lstm2(hp):\n",
    "    model = Sequential([\n",
    "        layers.Embedding(\n",
    "            VOCAB_SIZE,\n",
    "            hp.Choice(\"output_dim\", [8, 16, 32, 64, 128]),\n",
    "            mask_zero=True,\n",
    "        ),\n",
    "        layers.Bidirectional(layers.LSTM(\n",
    "            hp.Choice(\"units_1\", [8, 16, 32, 64, 128]),\n",
    "            return_sequences=True,\n",
    "        )),\n",
    "        layers.Bidirectional(layers.LSTM(\n",
    "            hp.Choice(\"units_2\", [8, 16, 32, 64, 128]),\n",
    "        )),\n",
    "        layers.Dense(\n",
    "            hp.Choice(\"units_3\", [8, 16, 32, 64, 128]),\n",
    "            activation=\"relu\"\n",
    "        ),\n",
    "        layers.Dense(3),\n",
    "    ])\n",
    "    compile(model)\n",
    "    return model\n",
    "\n",
    "def tuning_lstm(choice_model: Callable,\n",
    "                X: np.ndarray,\n",
    "                y: np.ndarray):\n",
    "    shutil.rmtree(\"untitled_project\")\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X,\n",
    "                                                      y,\n",
    "                                                      random_state=0,\n",
    "                                                      stratify=y,\n",
    "                                                      test_size=VALIDATION_SPLIT)\n",
    "\n",
    "    vectorizer = layers.TextVectorization(max_tokens=VOCAB_SIZE,\n",
    "                                          standardize=standardize)\n",
    "    vectorizer.adapt(X_train)\n",
    "    X_train, X_val = vectorizer(X_train), vectorizer(X_val)\n",
    "\n",
    "    tuner = keras_tuner.BayesianOptimization(\n",
    "        choice_model,\n",
    "        objective=\"val_loss\",\n",
    "    )\n",
    "    tuner.search(X_train,\n",
    "                 y_train,\n",
    "                 epochs=50,\n",
    "                 batch_size=100,\n",
    "                 validation_data=(X_val, y_val),\n",
    "                 callbacks=[\n",
    "                     callbacks.EarlyStopping(patience=5, restore_best_weights=True)\n",
    "                 ])\n",
    "\n",
    "    return tuner.get_best_models()[0]\n",
    "\n",
    "model = tuning_lstm(choice_lstm2, X, y)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc408f79-d78f-46c0-bc88-ec237692633d",
   "metadata": {},
   "source": [
    "Once again, different runs give different results. Is there a `random_state` I can set somewhere!?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2144a640-017c-4606-88e8-72af469e1e8d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0\n",
      "Epoch 1/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 105ms/step - accuracy: 0.5137 - loss: 1.0335 - sparse_categorical_crossentropy: 2.9957 - weighted_accuracy: 0.5137 - weighted_sparse_categorical_crossentropy: 2.9957 - val_accuracy: 0.5722 - val_loss: 0.9095 - val_sparse_categorical_crossentropy: 3.1265 - val_weighted_accuracy: 0.5722 - val_weighted_sparse_categorical_crossentropy: 3.1265\n",
      "Epoch 2/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 74ms/step - accuracy: 0.6320 - loss: 0.8601 - sparse_categorical_crossentropy: 3.2723 - weighted_accuracy: 0.6320 - weighted_sparse_categorical_crossentropy: 3.2723 - val_accuracy: 0.6241 - val_loss: 0.8261 - val_sparse_categorical_crossentropy: 4.1753 - val_weighted_accuracy: 0.6241 - val_weighted_sparse_categorical_crossentropy: 4.1753\n",
      "Epoch 3/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 75ms/step - accuracy: 0.7196 - loss: 0.6908 - sparse_categorical_crossentropy: 3.5340 - weighted_accuracy: 0.7196 - weighted_sparse_categorical_crossentropy: 3.5340 - val_accuracy: 0.6828 - val_loss: 0.7495 - val_sparse_categorical_crossentropy: 4.1492 - val_weighted_accuracy: 0.6828 - val_weighted_sparse_categorical_crossentropy: 4.1492\n",
      "Epoch 4/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 76ms/step - accuracy: 0.8015 - loss: 0.4978 - sparse_categorical_crossentropy: 2.0646 - weighted_accuracy: 0.8015 - weighted_sparse_categorical_crossentropy: 2.0646 - val_accuracy: 0.7062 - val_loss: 0.7264 - val_sparse_categorical_crossentropy: 3.4401 - val_weighted_accuracy: 0.7062 - val_weighted_sparse_categorical_crossentropy: 3.4401\n",
      "Epoch 5/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 73ms/step - accuracy: 0.8414 - loss: 0.3663 - sparse_categorical_crossentropy: 1.4081 - weighted_accuracy: 0.8414 - weighted_sparse_categorical_crossentropy: 1.4081 - val_accuracy: 0.6954 - val_loss: 0.8338 - val_sparse_categorical_crossentropy: 3.4464 - val_weighted_accuracy: 0.6954 - val_weighted_sparse_categorical_crossentropy: 3.4464\n",
      "Epoch 6/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 78ms/step - accuracy: 0.8778 - loss: 0.2779 - sparse_categorical_crossentropy: 0.7813 - weighted_accuracy: 0.8778 - weighted_sparse_categorical_crossentropy: 0.7813 - val_accuracy: 0.6845 - val_loss: 0.9706 - val_sparse_categorical_crossentropy: 3.4957 - val_weighted_accuracy: 0.6845 - val_weighted_sparse_categorical_crossentropy: 3.4957\n",
      "Epoch 7/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 77ms/step - accuracy: 0.9056 - loss: 0.2070 - sparse_categorical_crossentropy: 0.4649 - weighted_accuracy: 0.9056 - weighted_sparse_categorical_crossentropy: 0.4649 - val_accuracy: 0.6823 - val_loss: 1.0842 - val_sparse_categorical_crossentropy: 3.4935 - val_weighted_accuracy: 0.6823 - val_weighted_sparse_categorical_crossentropy: 3.4935\n",
      "Epoch 8/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 76ms/step - accuracy: 0.9117 - loss: 0.1798 - sparse_categorical_crossentropy: 0.3693 - weighted_accuracy: 0.9117 - weighted_sparse_categorical_crossentropy: 0.3693 - val_accuracy: 0.6800 - val_loss: 1.2130 - val_sparse_categorical_crossentropy: 3.5285 - val_weighted_accuracy: 0.6800 - val_weighted_sparse_categorical_crossentropy: 3.5285\n",
      "Epoch 9/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 77ms/step - accuracy: 0.9075 - loss: 0.1655 - sparse_categorical_crossentropy: 0.2780 - weighted_accuracy: 0.9075 - weighted_sparse_categorical_crossentropy: 0.2780 - val_accuracy: 0.6777 - val_loss: 1.3440 - val_sparse_categorical_crossentropy: 3.6154 - val_weighted_accuracy: 0.6777 - val_weighted_sparse_categorical_crossentropy: 3.6154\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step\n",
      "Fold 1\n",
      "Epoch 1/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 103ms/step - accuracy: 0.5099 - loss: 1.0277 - sparse_categorical_crossentropy: 5.1152 - weighted_accuracy: 0.5099 - weighted_sparse_categorical_crossentropy: 5.1152 - val_accuracy: 0.6239 - val_loss: 0.8780 - val_sparse_categorical_crossentropy: 4.2454 - val_weighted_accuracy: 0.6239 - val_weighted_sparse_categorical_crossentropy: 4.2454\n",
      "Epoch 2/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 80ms/step - accuracy: 0.6355 - loss: 0.8495 - sparse_categorical_crossentropy: 3.9416 - weighted_accuracy: 0.6355 - weighted_sparse_categorical_crossentropy: 3.9416 - val_accuracy: 0.6615 - val_loss: 0.7862 - val_sparse_categorical_crossentropy: 3.9999 - val_weighted_accuracy: 0.6615 - val_weighted_sparse_categorical_crossentropy: 3.9999\n",
      "Epoch 3/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 84ms/step - accuracy: 0.7200 - loss: 0.6630 - sparse_categorical_crossentropy: 3.5553 - weighted_accuracy: 0.7200 - weighted_sparse_categorical_crossentropy: 3.5553 - val_accuracy: 0.6906 - val_loss: 0.7661 - val_sparse_categorical_crossentropy: 4.1426 - val_weighted_accuracy: 0.6906 - val_weighted_sparse_categorical_crossentropy: 4.1426\n",
      "Epoch 4/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 76ms/step - accuracy: 0.7811 - loss: 0.5274 - sparse_categorical_crossentropy: 2.5934 - weighted_accuracy: 0.7811 - weighted_sparse_categorical_crossentropy: 2.5934 - val_accuracy: 0.7192 - val_loss: 0.7379 - val_sparse_categorical_crossentropy: 3.3090 - val_weighted_accuracy: 0.7192 - val_weighted_sparse_categorical_crossentropy: 3.3090\n",
      "Epoch 5/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 76ms/step - accuracy: 0.8565 - loss: 0.3559 - sparse_categorical_crossentropy: 1.2372 - weighted_accuracy: 0.8565 - weighted_sparse_categorical_crossentropy: 1.2372 - val_accuracy: 0.7215 - val_loss: 0.7723 - val_sparse_categorical_crossentropy: 3.0725 - val_weighted_accuracy: 0.7215 - val_weighted_sparse_categorical_crossentropy: 3.0725\n",
      "Epoch 6/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 72ms/step - accuracy: 0.8743 - loss: 0.2801 - sparse_categorical_crossentropy: 0.8546 - weighted_accuracy: 0.8743 - weighted_sparse_categorical_crossentropy: 0.8546 - val_accuracy: 0.6963 - val_loss: 0.9316 - val_sparse_categorical_crossentropy: 3.2426 - val_weighted_accuracy: 0.6963 - val_weighted_sparse_categorical_crossentropy: 3.2426\n",
      "Epoch 7/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 73ms/step - accuracy: 0.8990 - loss: 0.2216 - sparse_categorical_crossentropy: 0.5763 - weighted_accuracy: 0.8990 - weighted_sparse_categorical_crossentropy: 0.5763 - val_accuracy: 0.6969 - val_loss: 1.0335 - val_sparse_categorical_crossentropy: 3.2888 - val_weighted_accuracy: 0.6969 - val_weighted_sparse_categorical_crossentropy: 3.2888\n",
      "Epoch 8/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 70ms/step - accuracy: 0.8939 - loss: 0.2215 - sparse_categorical_crossentropy: 0.4590 - weighted_accuracy: 0.8939 - weighted_sparse_categorical_crossentropy: 0.4590 - val_accuracy: 0.6958 - val_loss: 1.1117 - val_sparse_categorical_crossentropy: 3.2631 - val_weighted_accuracy: 0.6958 - val_weighted_sparse_categorical_crossentropy: 3.2631\n",
      "Epoch 9/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 68ms/step - accuracy: 0.9053 - loss: 0.2092 - sparse_categorical_crossentropy: 0.5757 - weighted_accuracy: 0.9053 - weighted_sparse_categorical_crossentropy: 0.5757 - val_accuracy: 0.6906 - val_loss: 1.0438 - val_sparse_categorical_crossentropy: 3.3467 - val_weighted_accuracy: 0.6906 - val_weighted_sparse_categorical_crossentropy: 3.3467\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step\n",
      "Fold 2\n",
      "Epoch 1/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 70ms/step - accuracy: 0.5435 - loss: 1.0367 - sparse_categorical_crossentropy: 5.2472 - weighted_accuracy: 0.5435 - weighted_sparse_categorical_crossentropy: 5.2472 - val_accuracy: 0.6490 - val_loss: 0.8600 - val_sparse_categorical_crossentropy: 4.7810 - val_weighted_accuracy: 0.6490 - val_weighted_sparse_categorical_crossentropy: 4.7810\n",
      "Epoch 2/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 52ms/step - accuracy: 0.6453 - loss: 0.8425 - sparse_categorical_crossentropy: 4.8006 - weighted_accuracy: 0.6453 - weighted_sparse_categorical_crossentropy: 4.8006 - val_accuracy: 0.6632 - val_loss: 0.7881 - val_sparse_categorical_crossentropy: 4.6549 - val_weighted_accuracy: 0.6632 - val_weighted_sparse_categorical_crossentropy: 4.6549\n",
      "Epoch 3/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - accuracy: 0.7372 - loss: 0.6639 - sparse_categorical_crossentropy: 3.7431 - weighted_accuracy: 0.7372 - weighted_sparse_categorical_crossentropy: 3.7431 - val_accuracy: 0.6855 - val_loss: 0.7650 - val_sparse_categorical_crossentropy: 4.5898 - val_weighted_accuracy: 0.6855 - val_weighted_sparse_categorical_crossentropy: 4.5898\n",
      "Epoch 4/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 60ms/step - accuracy: 0.8043 - loss: 0.5104 - sparse_categorical_crossentropy: 2.7095 - weighted_accuracy: 0.8043 - weighted_sparse_categorical_crossentropy: 2.7095 - val_accuracy: 0.6986 - val_loss: 0.7698 - val_sparse_categorical_crossentropy: 3.6741 - val_weighted_accuracy: 0.6986 - val_weighted_sparse_categorical_crossentropy: 3.6741\n",
      "Epoch 5/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 58ms/step - accuracy: 0.8400 - loss: 0.3795 - sparse_categorical_crossentropy: 1.4022 - weighted_accuracy: 0.8400 - weighted_sparse_categorical_crossentropy: 1.4022 - val_accuracy: 0.7100 - val_loss: 0.7696 - val_sparse_categorical_crossentropy: 3.1176 - val_weighted_accuracy: 0.7100 - val_weighted_sparse_categorical_crossentropy: 3.1176\n",
      "Epoch 6/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 60ms/step - accuracy: 0.8733 - loss: 0.2930 - sparse_categorical_crossentropy: 0.8154 - weighted_accuracy: 0.8733 - weighted_sparse_categorical_crossentropy: 0.8154 - val_accuracy: 0.6872 - val_loss: 0.8977 - val_sparse_categorical_crossentropy: 3.1918 - val_weighted_accuracy: 0.6872 - val_weighted_sparse_categorical_crossentropy: 3.1918\n",
      "Epoch 7/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 57ms/step - accuracy: 0.8950 - loss: 0.2423 - sparse_categorical_crossentropy: 0.5508 - weighted_accuracy: 0.8950 - weighted_sparse_categorical_crossentropy: 0.5508 - val_accuracy: 0.6764 - val_loss: 0.9919 - val_sparse_categorical_crossentropy: 3.3714 - val_weighted_accuracy: 0.6764 - val_weighted_sparse_categorical_crossentropy: 3.3714\n",
      "Epoch 8/50\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 60ms/step - accuracy: 0.8963 - loss: 0.2401 - sparse_categorical_crossentropy: 0.5315 - weighted_accuracy: 0.8963 - weighted_sparse_categorical_crossentropy: 0.5315 - val_accuracy: 0.6861 - val_loss: 1.2457 - val_sparse_categorical_crossentropy: 3.7744 - val_weighted_accuracy: 0.6861 - val_weighted_sparse_categorical_crossentropy: 3.7744\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'cv_accuracy': 0.7036327591491341,\n",
       " 'cv_balanced_accuracy': 0.5904466601216283,\n",
       " 'cv_f1_macro': 0.5848323384746731,\n",
       " 'cv_f1_weighted': 0.6829437337372389,\n",
       " 'cv_precision_weighted': 0.694807263059649,\n",
       " 'cv_cohen_kappa': 0.43779264625472347}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def best():\n",
    "    return Sequential([\n",
    "        layers.TextVectorization(max_tokens=VOCAB_SIZE, standardize=standardize),\n",
    "        layers.Embedding(\n",
    "            input_dim=VOCAB_SIZE,\n",
    "            output_dim=64,\n",
    "            mask_zero=True,\n",
    "        ),\n",
    "        layers.Bidirectional(layers.LSTM(32, return_sequences=True)),\n",
    "        layers.Bidirectional(layers.LSTM(16)),\n",
    "        layers.Dense(64, activation=\"relu\"),\n",
    "        layers.Dense(3),\n",
    "    ])\n",
    "    \n",
    "score_dl(best, X, y, epochs=50, batch_size=100, early_stopping=True, method=ScoringMethod.CROSS_VAL_SCORE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dd302cb-8cfe-4c92-8b45-de122862d227",
   "metadata": {},
   "source": [
    "Definitely some improvements in macro-averaged f1 and balanced accuracy, so I'll take it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "56d345e2-e6e6-4e2d-8804-4b7bd0c9c3f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 60ms/step - accuracy: 0.5309 - loss: 1.0236 - sparse_categorical_crossentropy: 6.0196 - weighted_accuracy: 0.5309 - weighted_sparse_categorical_crossentropy: 6.0196 - val_accuracy: 0.6122 - val_loss: 0.8801 - val_sparse_categorical_crossentropy: 5.3382 - val_weighted_accuracy: 0.6122 - val_weighted_sparse_categorical_crossentropy: 5.3382\n",
      "Epoch 2/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - accuracy: 0.6550 - loss: 0.8160 - sparse_categorical_crossentropy: 4.8317 - weighted_accuracy: 0.6550 - weighted_sparse_categorical_crossentropy: 4.8317 - val_accuracy: 0.6793 - val_loss: 0.7566 - val_sparse_categorical_crossentropy: 4.0915 - val_weighted_accuracy: 0.6793 - val_weighted_sparse_categorical_crossentropy: 4.0915\n",
      "Epoch 3/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - accuracy: 0.7315 - loss: 0.6502 - sparse_categorical_crossentropy: 3.4130 - weighted_accuracy: 0.7315 - weighted_sparse_categorical_crossentropy: 3.4130 - val_accuracy: 0.7047 - val_loss: 0.7085 - val_sparse_categorical_crossentropy: 3.9875 - val_weighted_accuracy: 0.7047 - val_weighted_sparse_categorical_crossentropy: 3.9875\n",
      "Epoch 4/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - accuracy: 0.8148 - loss: 0.4602 - sparse_categorical_crossentropy: 2.2423 - weighted_accuracy: 0.8148 - weighted_sparse_categorical_crossentropy: 2.2423 - val_accuracy: 0.7186 - val_loss: 0.6767 - val_sparse_categorical_crossentropy: 3.4410 - val_weighted_accuracy: 0.7186 - val_weighted_sparse_categorical_crossentropy: 3.4410\n",
      "Epoch 5/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - accuracy: 0.8545 - loss: 0.3684 - sparse_categorical_crossentropy: 1.2804 - weighted_accuracy: 0.8545 - weighted_sparse_categorical_crossentropy: 1.2804 - val_accuracy: 0.7110 - val_loss: 0.7742 - val_sparse_categorical_crossentropy: 3.3822 - val_weighted_accuracy: 0.7110 - val_weighted_sparse_categorical_crossentropy: 3.3822\n",
      "Epoch 6/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - accuracy: 0.8773 - loss: 0.2993 - sparse_categorical_crossentropy: 0.8785 - weighted_accuracy: 0.8773 - weighted_sparse_categorical_crossentropy: 0.8785 - val_accuracy: 0.7072 - val_loss: 0.8321 - val_sparse_categorical_crossentropy: 3.2588 - val_weighted_accuracy: 0.7072 - val_weighted_sparse_categorical_crossentropy: 3.2588\n",
      "Epoch 7/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 50ms/step - accuracy: 0.8922 - loss: 0.2449 - sparse_categorical_crossentropy: 0.5295 - weighted_accuracy: 0.8922 - weighted_sparse_categorical_crossentropy: 0.5295 - val_accuracy: 0.6984 - val_loss: 0.8690 - val_sparse_categorical_crossentropy: 3.1623 - val_weighted_accuracy: 0.6984 - val_weighted_sparse_categorical_crossentropy: 3.1623\n",
      "Epoch 8/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 52ms/step - accuracy: 0.8791 - loss: 0.2504 - sparse_categorical_crossentropy: 0.6172 - weighted_accuracy: 0.8791 - weighted_sparse_categorical_crossentropy: 0.6172 - val_accuracy: 0.6907 - val_loss: 0.9803 - val_sparse_categorical_crossentropy: 3.2652 - val_weighted_accuracy: 0.6907 - val_weighted_sparse_categorical_crossentropy: 3.2652\n",
      "Epoch 9/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 50ms/step - accuracy: 0.9049 - loss: 0.1889 - sparse_categorical_crossentropy: 0.3396 - weighted_accuracy: 0.9049 - weighted_sparse_categorical_crossentropy: 0.3396 - val_accuracy: 0.7009 - val_loss: 1.0563 - val_sparse_categorical_crossentropy: 3.1623 - val_weighted_accuracy: 0.7009 - val_weighted_sparse_categorical_crossentropy: 3.1623\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 41,  55,  20],\n",
       "       [ 29, 368,  26],\n",
       "       [ 27,  65, 158]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_dl(best, X, y, epochs=50, batch_size=100, early_stopping=True, method=ScoringMethod.CONFUSION_MATRIX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "76fa1e99-af6f-40a1-a643-2375652e03f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 46ms/step - accuracy: 0.5351 - loss: 1.0083 - sparse_categorical_crossentropy: 5.5748 - weighted_accuracy: 0.5351 - weighted_sparse_categorical_crossentropy: 5.5748 - val_accuracy: 0.6388 - val_loss: 0.8381 - val_sparse_categorical_crossentropy: 4.9881 - val_weighted_accuracy: 0.6388 - val_weighted_sparse_categorical_crossentropy: 4.9881\n",
      "Epoch 2/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.6720 - loss: 0.7751 - sparse_categorical_crossentropy: 4.4008 - weighted_accuracy: 0.6720 - weighted_sparse_categorical_crossentropy: 4.4008 - val_accuracy: 0.6984 - val_loss: 0.7260 - val_sparse_categorical_crossentropy: 3.7418 - val_weighted_accuracy: 0.6984 - val_weighted_sparse_categorical_crossentropy: 3.7418\n",
      "Epoch 3/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - accuracy: 0.7550 - loss: 0.5947 - sparse_categorical_crossentropy: 2.9020 - weighted_accuracy: 0.7550 - weighted_sparse_categorical_crossentropy: 2.9020 - val_accuracy: 0.7212 - val_loss: 0.6586 - val_sparse_categorical_crossentropy: 2.9398 - val_weighted_accuracy: 0.7212 - val_weighted_sparse_categorical_crossentropy: 2.9398\n",
      "Epoch 4/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - accuracy: 0.8229 - loss: 0.4349 - sparse_categorical_crossentropy: 1.6133 - weighted_accuracy: 0.8229 - weighted_sparse_categorical_crossentropy: 1.6133 - val_accuracy: 0.7085 - val_loss: 0.6533 - val_sparse_categorical_crossentropy: 2.8855 - val_weighted_accuracy: 0.7085 - val_weighted_sparse_categorical_crossentropy: 2.8855\n",
      "Epoch 5/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - accuracy: 0.8544 - loss: 0.3372 - sparse_categorical_crossentropy: 0.9089 - weighted_accuracy: 0.8544 - weighted_sparse_categorical_crossentropy: 0.9089 - val_accuracy: 0.7136 - val_loss: 0.7224 - val_sparse_categorical_crossentropy: 2.8758 - val_weighted_accuracy: 0.7136 - val_weighted_sparse_categorical_crossentropy: 2.8758\n",
      "Epoch 6/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 46ms/step - accuracy: 0.8793 - loss: 0.2672 - sparse_categorical_crossentropy: 0.5814 - weighted_accuracy: 0.8793 - weighted_sparse_categorical_crossentropy: 0.5814 - val_accuracy: 0.6984 - val_loss: 0.7926 - val_sparse_categorical_crossentropy: 3.0079 - val_weighted_accuracy: 0.6984 - val_weighted_sparse_categorical_crossentropy: 3.0079\n",
      "Epoch 7/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - accuracy: 0.8772 - loss: 0.2446 - sparse_categorical_crossentropy: 0.4819 - weighted_accuracy: 0.8772 - weighted_sparse_categorical_crossentropy: 0.4819 - val_accuracy: 0.6996 - val_loss: 0.9456 - val_sparse_categorical_crossentropy: 2.8159 - val_weighted_accuracy: 0.6996 - val_weighted_sparse_categorical_crossentropy: 2.8159\n",
      "Epoch 8/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 37ms/step - accuracy: 0.9009 - loss: 0.2066 - sparse_categorical_crossentropy: 0.4051 - weighted_accuracy: 0.9009 - weighted_sparse_categorical_crossentropy: 0.4051 - val_accuracy: 0.7022 - val_loss: 0.9632 - val_sparse_categorical_crossentropy: 3.0524 - val_weighted_accuracy: 0.7022 - val_weighted_sparse_categorical_crossentropy: 3.0524\n",
      "Epoch 9/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - accuracy: 0.9080 - loss: 0.1838 - sparse_categorical_crossentropy: 0.3229 - weighted_accuracy: 0.9080 - weighted_sparse_categorical_crossentropy: 0.3229 - val_accuracy: 0.6882 - val_loss: 1.0950 - val_sparse_categorical_crossentropy: 3.0678 - val_weighted_accuracy: 0.6882 - val_weighted_sparse_categorical_crossentropy: 3.0678\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 28,  61,  27],\n",
       "       [ 20, 361,  42],\n",
       "       [ 20,  60, 170]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_dl(partial(lstm, standardize=standardize),\n",
    "         X,\n",
    "         y,\n",
    "         method=ScoringMethod.CONFUSION_MATRIX,\n",
    "         epochs=50,\n",
    "         batch_size=100,\n",
    "         early_stopping=True,)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb5994c2-66bc-48d9-af05-817a35248834",
   "metadata": {},
   "source": [
    "## Pre-trained Embeddings\n",
    "\n",
    "Embeddings make all the difference right? https://en.wikipedia.org/wiki/Word_embedding\n",
    "\n",
    "References:\n",
    "* https://keras.io/examples/nlp/text_classification_from_scratch/\n",
    "* https://keras.io/examples/nlp/tweet-classification-using-tfdf/\n",
    "* https://keras.io/examples/nlp/pretrained_word_embeddings/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "508006e8-c7b1-472b-a257-4228e506fa1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "EMBEDDING_DIM = 300\n",
    "\n",
    "def get_embedding_index(embedding_dim: int = EMBEDDING_DIM):\n",
    "    glove_file = f\"glove.6B.{embedding_dim}d.txt\"\n",
    "    with open(glove_file) as f:\n",
    "        def word_coeff():\n",
    "            for line in f:\n",
    "                line = line.split()\n",
    "                yield line[0], np.array(line[1:])\n",
    "        return {word: coeff for word, coeff in word_coeff()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7ecf9c56-f646-437d-9cf7-4c5bc69144b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_embedding_weights(vocabulary: list[str],\n",
    "                            embedding_index: dict[str, np.ndarray]):\n",
    "    vocab_size = len(vocabulary)\n",
    "    embedding_dim = len(embedding_index[\"the\"])\n",
    "    embedding_matrix = np.zeros((vocab_size + 2, embedding_dim))\n",
    "\n",
    "    known_words_count = 0\n",
    "    for index, word in enumerate(vocabulary):\n",
    "        if word in embedding_index:\n",
    "            embedding_matrix[index] = embedding_index[word]\n",
    "            known_words_count += 1\n",
    "\n",
    "    print(f\"Hits/Misses: {known_words_count}/{vocab_size - known_words_count}\")\n",
    "    return embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b9f0a033-5e85-4abc-bb77-d19dbe423f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_SIZE = 20000\n",
    "OUTPUT_SEQUENCE_LENGTH = 200\n",
    "\n",
    "vectorization_layer = layers.TextVectorization(\n",
    "    max_tokens=VOCAB_SIZE,\n",
    "    output_sequence_length=OUTPUT_SEQUENCE_LENGTH,\n",
    "    standardize=standardize\n",
    ")\n",
    "vectorization_layer.adapt(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ceeb3ef9-031b-45a9-995f-df0fbf083eed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['', '[UNK]']"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vlayer = layers.TextVectorization(\n",
    "    max_tokens=VOCAB_SIZE,\n",
    "    output_sequence_length=OUTPUT_SEQUENCE_LENGTH,\n",
    "    standardize=standardize\n",
    ")\n",
    "vlayer.get_vocabulary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "2e3641a8-f2b0-4b42-a6d2-9cfdf09d3f91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hits/Misses: 9204/2840\n"
     ]
    }
   ],
   "source": [
    "embedding_index = get_embedding_index(EMBEDDING_DIM)\n",
    "embedding_weights = build_embedding_weights(vectorization_layer.get_vocabulary(),\n",
    "                                            embedding_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "505a1641-6a3d-4942-8766-a8a69faad53b",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_layer = layers.Embedding(\n",
    "    input_dim=len(vectorization_layer.get_vocabulary()) + 2,\n",
    "    output_dim=EMBEDDING_DIM,\n",
    "    trainable=False,\n",
    ")\n",
    "embedding_layer.build((1, ))\n",
    "embedding_layer.set_weights([embedding_weights])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "5f4d75b1-a93e-484f-9d10-c464a1931a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretrained_embed_lstm():\n",
    "    return Sequential([\n",
    "        vectorization_layer,\n",
    "        embedding_layer,\n",
    "        layers.Bidirectional(layers.LSTM(32, return_sequences=True)),\n",
    "        layers.Bidirectional(layers.LSTM(32)),\n",
    "        layers.Dense(16, activation=\"relu\"),\n",
    "        layers.Dense(3),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "d063e212-72da-4009-9a9f-1e89cf7565f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_6\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_6\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ text_vectorization_5            │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TextVectorization</span>)             │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ embedding_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)               │     <span style=\"color: #00af00; text-decoration-color: #00af00\">3,613,800</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_11                │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_12                │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ text_vectorization_5            │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "│ (\u001b[38;5;33mTextVectorization\u001b[0m)             │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ embedding_6 (\u001b[38;5;33mEmbedding\u001b[0m)         │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m300\u001b[0m)               │     \u001b[38;5;34m3,613,800\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_11                │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "│ (\u001b[38;5;33mBidirectional\u001b[0m)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_12                │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "│ (\u001b[38;5;33mBidirectional\u001b[0m)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_12 (\u001b[38;5;33mDense\u001b[0m)                │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_13 (\u001b[38;5;33mDense\u001b[0m)                │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,613,800</span> (13.79 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m3,613,800\u001b[0m (13.79 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,613,800</span> (13.79 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m3,613,800\u001b[0m (13.79 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = pretrained_embed_lstm()\n",
    "compile(model)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b189f8b0-0fce-4de4-ad25-0aa3387d3514",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 139ms/step - accuracy: 0.4879 - loss: 1.0163 - sparse_categorical_crossentropy: 3.7704 - weighted_accuracy: 0.4879 - weighted_sparse_categorical_crossentropy: 3.7704 - val_accuracy: 0.6464 - val_loss: 0.8287 - val_sparse_categorical_crossentropy: 1.2858 - val_weighted_accuracy: 0.6464 - val_weighted_sparse_categorical_crossentropy: 1.2858\n",
      "Epoch 2/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 130ms/step - accuracy: 0.6481 - loss: 0.8148 - sparse_categorical_crossentropy: 1.7472 - weighted_accuracy: 0.6481 - weighted_sparse_categorical_crossentropy: 1.7472 - val_accuracy: 0.6831 - val_loss: 0.7517 - val_sparse_categorical_crossentropy: 1.3835 - val_weighted_accuracy: 0.6831 - val_weighted_sparse_categorical_crossentropy: 1.3835\n",
      "Epoch 3/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 134ms/step - accuracy: 0.6649 - loss: 0.7647 - sparse_categorical_crossentropy: 1.4304 - weighted_accuracy: 0.6649 - weighted_sparse_categorical_crossentropy: 1.4304 - val_accuracy: 0.6743 - val_loss: 0.7629 - val_sparse_categorical_crossentropy: 1.4165 - val_weighted_accuracy: 0.6743 - val_weighted_sparse_categorical_crossentropy: 1.4165\n",
      "Epoch 4/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 144ms/step - accuracy: 0.7068 - loss: 0.6877 - sparse_categorical_crossentropy: 1.1322 - weighted_accuracy: 0.7068 - weighted_sparse_categorical_crossentropy: 1.1322 - val_accuracy: 0.7326 - val_loss: 0.6439 - val_sparse_categorical_crossentropy: 1.0701 - val_weighted_accuracy: 0.7326 - val_weighted_sparse_categorical_crossentropy: 1.0701\n",
      "Epoch 5/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 151ms/step - accuracy: 0.7614 - loss: 0.5750 - sparse_categorical_crossentropy: 0.9514 - weighted_accuracy: 0.7614 - weighted_sparse_categorical_crossentropy: 0.9514 - val_accuracy: 0.7529 - val_loss: 0.6343 - val_sparse_categorical_crossentropy: 1.2687 - val_weighted_accuracy: 0.7529 - val_weighted_sparse_categorical_crossentropy: 1.2687\n",
      "Epoch 6/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 150ms/step - accuracy: 0.7897 - loss: 0.5004 - sparse_categorical_crossentropy: 0.8616 - weighted_accuracy: 0.7897 - weighted_sparse_categorical_crossentropy: 0.8616 - val_accuracy: 0.7427 - val_loss: 0.5920 - val_sparse_categorical_crossentropy: 1.0207 - val_weighted_accuracy: 0.7427 - val_weighted_sparse_categorical_crossentropy: 1.0207\n",
      "Epoch 7/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 149ms/step - accuracy: 0.8192 - loss: 0.4311 - sparse_categorical_crossentropy: 0.7753 - weighted_accuracy: 0.8192 - weighted_sparse_categorical_crossentropy: 0.7753 - val_accuracy: 0.7516 - val_loss: 0.6285 - val_sparse_categorical_crossentropy: 1.2596 - val_weighted_accuracy: 0.7516 - val_weighted_sparse_categorical_crossentropy: 1.2596\n",
      "Epoch 8/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 152ms/step - accuracy: 0.8345 - loss: 0.3818 - sparse_categorical_crossentropy: 0.6572 - weighted_accuracy: 0.8345 - weighted_sparse_categorical_crossentropy: 0.6572 - val_accuracy: 0.7262 - val_loss: 0.6580 - val_sparse_categorical_crossentropy: 1.2912 - val_weighted_accuracy: 0.7262 - val_weighted_sparse_categorical_crossentropy: 1.2912\n",
      "Epoch 9/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 152ms/step - accuracy: 0.8461 - loss: 0.3648 - sparse_categorical_crossentropy: 0.6774 - weighted_accuracy: 0.8461 - weighted_sparse_categorical_crossentropy: 0.6774 - val_accuracy: 0.7351 - val_loss: 0.6541 - val_sparse_categorical_crossentropy: 1.2572 - val_weighted_accuracy: 0.7351 - val_weighted_sparse_categorical_crossentropy: 1.2572\n",
      "Epoch 10/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 150ms/step - accuracy: 0.8633 - loss: 0.3015 - sparse_categorical_crossentropy: 0.5708 - weighted_accuracy: 0.8633 - weighted_sparse_categorical_crossentropy: 0.5708 - val_accuracy: 0.7250 - val_loss: 0.6793 - val_sparse_categorical_crossentropy: 1.2826 - val_weighted_accuracy: 0.7250 - val_weighted_sparse_categorical_crossentropy: 1.2826\n",
      "Epoch 11/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 166ms/step - accuracy: 0.8752 - loss: 0.2818 - sparse_categorical_crossentropy: 0.5858 - weighted_accuracy: 0.8752 - weighted_sparse_categorical_crossentropy: 0.5858 - val_accuracy: 0.7351 - val_loss: 0.7365 - val_sparse_categorical_crossentropy: 1.3483 - val_weighted_accuracy: 0.7351 - val_weighted_sparse_categorical_crossentropy: 1.3483\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 58ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.7427122940430925,\n",
       " 'balanced_accuracy': 0.6443824352599113,\n",
       " 'f1_macro': 0.6475984589461687,\n",
       " 'f1_weighted': 0.732140216769749,\n",
       " 'precision_weighted': 0.727849753330259,\n",
       " 'cohen_kappa': 0.5276024046535399}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_dl(pretrained_embed_lstm, X, y, epochs=50, batch_size=100, early_stopping=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa5929eb-dcb3-471a-9c37-d7c4e20663c2",
   "metadata": {},
   "source": [
    "Definitely better than the self-trained one! Let's tune further"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ab39b7ca-d5b9-4c7f-bf78-1d39abff6d7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 10 Complete [00h 01m 30s]\n",
      "val_loss: 0.6102324724197388\n",
      "\n",
      "Best val_loss So Far: 0.5960491299629211\n",
      "Total elapsed time: 00h 19m 57s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/recurze/.local/lib/python3.12/site-packages/keras/src/saving/saving_lib.py:719: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 34 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">3,613,800</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">85,248</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">197,632</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">16,448</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">195</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_6 (\u001b[38;5;33mEmbedding\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m300\u001b[0m)       │     \u001b[38;5;34m3,613,800\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional (\u001b[38;5;33mBidirectional\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │        \u001b[38;5;34m85,248\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_1 (\u001b[38;5;33mBidirectional\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │       \u001b[38;5;34m197,632\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │        \u001b[38;5;34m16,448\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)              │           \u001b[38;5;34m195\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,913,323</span> (14.93 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m3,913,323\u001b[0m (14.93 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">299,523</span> (1.14 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m299,523\u001b[0m (1.14 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,613,800</span> (13.79 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m3,613,800\u001b[0m (13.79 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import keras_tuner\n",
    "import random\n",
    "\n",
    "def choice_lstm3(hp):\n",
    "    model = Sequential([\n",
    "        embedding_layer,\n",
    "        layers.Bidirectional(layers.LSTM(\n",
    "            hp.Choice(\"units_1\", [8, 16, 32, 64, 128]),\n",
    "            return_sequences=True,\n",
    "        )),\n",
    "        layers.Bidirectional(layers.LSTM(\n",
    "            hp.Choice(\"units_2\", [8, 16, 32, 64, 128]),\n",
    "        )),\n",
    "        layers.Dense(\n",
    "            hp.Choice(\"units_3\", [8, 16, 32, 64, 128]),\n",
    "            activation=\"relu\"\n",
    "        ),\n",
    "        layers.Dense(3),\n",
    "    ])\n",
    "    compile(model)\n",
    "    return model\n",
    "\n",
    "def tuning_lstm_pretrained_embeds(choice_model: Callable,\n",
    "                                  X: np.ndarray,\n",
    "                                  y: np.ndarray):\n",
    "    shutil.rmtree(\"untitled_project\")\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X,\n",
    "                                                      y,\n",
    "                                                      random_state=0,\n",
    "                                                      stratify=y,\n",
    "                                                      test_size=VALIDATION_SPLIT)\n",
    "\n",
    "    X_train, X_val = vectorization_layer(X_train), vectorization_layer(X_val)\n",
    "\n",
    "    tuner = keras_tuner.BayesianOptimization(\n",
    "        choice_model,\n",
    "        objective=\"val_loss\",\n",
    "    )\n",
    "    tuner.search(X_train,\n",
    "                 y_train,\n",
    "                 epochs=50,\n",
    "                 batch_size=100,\n",
    "                 validation_data=(X_val, y_val),\n",
    "                 callbacks=[\n",
    "                     callbacks.EarlyStopping(patience=5, restore_best_weights=True)\n",
    "                 ])\n",
    "\n",
    "    return tuner.get_best_models()[0]\n",
    "\n",
    "model = tuning_lstm_pretrained_embeds(choice_lstm3, X, y)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "5d3d04f4-d11c-4d10-b47a-d59dee6c79c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_pretrained_embed():\n",
    "    return Sequential([\n",
    "        vectorization_layer,\n",
    "        embedding_layer,\n",
    "        layers.Bidirectional(layers.LSTM(64, return_sequences=True)),\n",
    "        layers.Bidirectional(layers.LSTM(256)),\n",
    "        layers.Dense(64, activation=\"relu\"),\n",
    "        layers.Dense(3),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "6f25214d-b1c3-4c3e-a724-96a2b1330820",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 714ms/step - accuracy: 0.5689 - loss: 0.9349 - sparse_categorical_crossentropy: 3.6247 - weighted_accuracy: 0.5689 - weighted_sparse_categorical_crossentropy: 3.6247 - val_accuracy: 0.6603 - val_loss: 0.7663 - val_sparse_categorical_crossentropy: 2.7869 - val_weighted_accuracy: 0.6603 - val_weighted_sparse_categorical_crossentropy: 2.7869\n",
      "Epoch 2/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 828ms/step - accuracy: 0.6692 - loss: 0.7369 - sparse_categorical_crossentropy: 2.9085 - weighted_accuracy: 0.6692 - weighted_sparse_categorical_crossentropy: 2.9085 - val_accuracy: 0.7275 - val_loss: 0.6567 - val_sparse_categorical_crossentropy: 1.9953 - val_weighted_accuracy: 0.7275 - val_weighted_sparse_categorical_crossentropy: 1.9953\n",
      "Epoch 3/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 848ms/step - accuracy: 0.7406 - loss: 0.6101 - sparse_categorical_crossentropy: 1.9217 - weighted_accuracy: 0.7406 - weighted_sparse_categorical_crossentropy: 1.9217 - val_accuracy: 0.7300 - val_loss: 0.6385 - val_sparse_categorical_crossentropy: 2.1633 - val_weighted_accuracy: 0.7300 - val_weighted_sparse_categorical_crossentropy: 2.1633\n",
      "Epoch 4/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 849ms/step - accuracy: 0.7774 - loss: 0.5078 - sparse_categorical_crossentropy: 1.4308 - weighted_accuracy: 0.7774 - weighted_sparse_categorical_crossentropy: 1.4308 - val_accuracy: 0.7376 - val_loss: 0.5980 - val_sparse_categorical_crossentropy: 1.7365 - val_weighted_accuracy: 0.7376 - val_weighted_sparse_categorical_crossentropy: 1.7365\n",
      "Epoch 5/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 851ms/step - accuracy: 0.8120 - loss: 0.4326 - sparse_categorical_crossentropy: 1.0438 - weighted_accuracy: 0.8120 - weighted_sparse_categorical_crossentropy: 1.0438 - val_accuracy: 0.7338 - val_loss: 0.6043 - val_sparse_categorical_crossentropy: 1.9834 - val_weighted_accuracy: 0.7338 - val_weighted_sparse_categorical_crossentropy: 1.9834\n",
      "Epoch 6/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 860ms/step - accuracy: 0.8313 - loss: 0.3806 - sparse_categorical_crossentropy: 0.7964 - weighted_accuracy: 0.8313 - weighted_sparse_categorical_crossentropy: 0.7964 - val_accuracy: 0.7110 - val_loss: 0.6986 - val_sparse_categorical_crossentropy: 2.0890 - val_weighted_accuracy: 0.7110 - val_weighted_sparse_categorical_crossentropy: 2.0890\n",
      "Epoch 7/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 895ms/step - accuracy: 0.8347 - loss: 0.3697 - sparse_categorical_crossentropy: 0.9303 - weighted_accuracy: 0.8347 - weighted_sparse_categorical_crossentropy: 0.9303 - val_accuracy: 0.6946 - val_loss: 0.6888 - val_sparse_categorical_crossentropy: 2.1134 - val_weighted_accuracy: 0.6946 - val_weighted_sparse_categorical_crossentropy: 2.1134\n",
      "Epoch 8/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 900ms/step - accuracy: 0.8548 - loss: 0.2898 - sparse_categorical_crossentropy: 0.5506 - weighted_accuracy: 0.8548 - weighted_sparse_categorical_crossentropy: 0.5506 - val_accuracy: 0.7098 - val_loss: 0.7472 - val_sparse_categorical_crossentropy: 1.9390 - val_weighted_accuracy: 0.7098 - val_weighted_sparse_categorical_crossentropy: 1.9390\n",
      "Epoch 9/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 935ms/step - accuracy: 0.8716 - loss: 0.2526 - sparse_categorical_crossentropy: 0.5378 - weighted_accuracy: 0.8716 - weighted_sparse_categorical_crossentropy: 0.5378 - val_accuracy: 0.7174 - val_loss: 0.7284 - val_sparse_categorical_crossentropy: 1.9759 - val_weighted_accuracy: 0.7174 - val_weighted_sparse_categorical_crossentropy: 1.9759\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 167ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.7376425855513308,\n",
       " 'balanced_accuracy': 0.6267940545093883,\n",
       " 'f1_macro': 0.6369024629835923,\n",
       " 'f1_weighted': 0.7223103536859881,\n",
       " 'precision_weighted': 0.7205334311572524,\n",
       " 'cohen_kappa': 0.5123793908053226}"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_dl(best_pretrained_embed, X, y, epochs=50, batch_size=100, early_stopping=True, method=ScoringMethod.SUMMARY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d284925f-7319-4844-aac8-6756a4388362",
   "metadata": {},
   "source": [
    "Seems great! Finally, let's try our best models on the test dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dc45d36-0403-43f8-86f2-6b52e69450df",
   "metadata": {},
   "source": [
    "## Test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "c0bf7677-e727-421b-8161-17e362696368",
   "metadata": {},
   "outputs": [],
   "source": [
    "restab = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "1b6a79bd-1b5d-40f5-bfe3-96ad10ab3e19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 833ms/step - accuracy: 0.5547 - loss: 0.9281 - sparse_categorical_crossentropy: 4.7888 - weighted_accuracy: 0.5547 - weighted_sparse_categorical_crossentropy: 4.7888 - val_accuracy: 0.6369 - val_loss: 0.8183 - val_sparse_categorical_crossentropy: 3.2209 - val_weighted_accuracy: 0.6369 - val_weighted_sparse_categorical_crossentropy: 3.2209\n",
      "Epoch 2/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 850ms/step - accuracy: 0.6707 - loss: 0.7180 - sparse_categorical_crossentropy: 2.8622 - weighted_accuracy: 0.6707 - weighted_sparse_categorical_crossentropy: 2.8622 - val_accuracy: 0.7072 - val_loss: 0.7073 - val_sparse_categorical_crossentropy: 2.4213 - val_weighted_accuracy: 0.7072 - val_weighted_sparse_categorical_crossentropy: 2.4213\n",
      "Epoch 3/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 849ms/step - accuracy: 0.7466 - loss: 0.5959 - sparse_categorical_crossentropy: 1.8440 - weighted_accuracy: 0.7466 - weighted_sparse_categorical_crossentropy: 1.8440 - val_accuracy: 0.6996 - val_loss: 0.6853 - val_sparse_categorical_crossentropy: 2.2380 - val_weighted_accuracy: 0.6996 - val_weighted_sparse_categorical_crossentropy: 2.2380\n",
      "Epoch 4/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 846ms/step - accuracy: 0.7804 - loss: 0.5023 - sparse_categorical_crossentropy: 1.3769 - weighted_accuracy: 0.7804 - weighted_sparse_categorical_crossentropy: 1.3769 - val_accuracy: 0.7015 - val_loss: 0.6669 - val_sparse_categorical_crossentropy: 1.9443 - val_weighted_accuracy: 0.7015 - val_weighted_sparse_categorical_crossentropy: 1.9443\n",
      "Epoch 5/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 848ms/step - accuracy: 0.8057 - loss: 0.4516 - sparse_categorical_crossentropy: 1.1482 - weighted_accuracy: 0.8057 - weighted_sparse_categorical_crossentropy: 1.1482 - val_accuracy: 0.7072 - val_loss: 0.7104 - val_sparse_categorical_crossentropy: 2.2000 - val_weighted_accuracy: 0.7072 - val_weighted_sparse_categorical_crossentropy: 2.2000\n",
      "Epoch 6/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 853ms/step - accuracy: 0.8187 - loss: 0.3973 - sparse_categorical_crossentropy: 0.8999 - weighted_accuracy: 0.8187 - weighted_sparse_categorical_crossentropy: 0.8999 - val_accuracy: 0.6901 - val_loss: 0.7401 - val_sparse_categorical_crossentropy: 2.1364 - val_weighted_accuracy: 0.6901 - val_weighted_sparse_categorical_crossentropy: 2.1364\n",
      "Epoch 7/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 856ms/step - accuracy: 0.8477 - loss: 0.3435 - sparse_categorical_crossentropy: 0.7451 - weighted_accuracy: 0.8477 - weighted_sparse_categorical_crossentropy: 0.7451 - val_accuracy: 0.6901 - val_loss: 0.7268 - val_sparse_categorical_crossentropy: 1.9292 - val_weighted_accuracy: 0.6901 - val_weighted_sparse_categorical_crossentropy: 1.9292\n",
      "Epoch 8/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 864ms/step - accuracy: 0.8500 - loss: 0.3015 - sparse_categorical_crossentropy: 0.6015 - weighted_accuracy: 0.8500 - weighted_sparse_categorical_crossentropy: 0.6015 - val_accuracy: 0.7205 - val_loss: 0.7892 - val_sparse_categorical_crossentropy: 2.2348 - val_weighted_accuracy: 0.7205 - val_weighted_sparse_categorical_crossentropy: 2.2348\n",
      "Epoch 9/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 881ms/step - accuracy: 0.8744 - loss: 0.2625 - sparse_categorical_crossentropy: 0.4803 - weighted_accuracy: 0.8744 - weighted_sparse_categorical_crossentropy: 0.4803 - val_accuracy: 0.7262 - val_loss: 0.9539 - val_sparse_categorical_crossentropy: 2.8460 - val_weighted_accuracy: 0.7262 - val_weighted_sparse_categorical_crossentropy: 2.8460\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 154ms/step\n"
     ]
    }
   ],
   "source": [
    "model = best_pretrained_embed()\n",
    "compile(model)\n",
    "model.fit(X,\n",
    "          y,\n",
    "          validation_split=TEST_SPLIT,\n",
    "          epochs=50,\n",
    "          batch_size=100,\n",
    "          callbacks=[\n",
    "              callbacks.EarlyStopping(patience=5, restore_best_weights=True)\n",
    "          ])\n",
    "\n",
    "y_pred = predict(model, X_test)\n",
    "\n",
    "restab[\"pretrained_embed_lstm\"] = custom_summary(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "a592136d-2d8a-42ee-bd52-87e667fcb32c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 73ms/step - accuracy: 0.5158 - loss: 1.0226 - sparse_categorical_crossentropy: 2.7890 - weighted_accuracy: 0.5158 - weighted_sparse_categorical_crossentropy: 2.7890 - val_accuracy: 0.6008 - val_loss: 0.8687 - val_sparse_categorical_crossentropy: 2.7941 - val_weighted_accuracy: 0.6008 - val_weighted_sparse_categorical_crossentropy: 2.7941\n",
      "Epoch 2/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 57ms/step - accuracy: 0.6526 - loss: 0.8000 - sparse_categorical_crossentropy: 2.8663 - weighted_accuracy: 0.6526 - weighted_sparse_categorical_crossentropy: 2.8663 - val_accuracy: 0.6787 - val_loss: 0.7812 - val_sparse_categorical_crossentropy: 3.7264 - val_weighted_accuracy: 0.6787 - val_weighted_sparse_categorical_crossentropy: 3.7264\n",
      "Epoch 3/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 57ms/step - accuracy: 0.8312 - loss: 0.4432 - sparse_categorical_crossentropy: 1.6605 - weighted_accuracy: 0.8312 - weighted_sparse_categorical_crossentropy: 1.6605 - val_accuracy: 0.6787 - val_loss: 0.7681 - val_sparse_categorical_crossentropy: 3.0315 - val_weighted_accuracy: 0.6787 - val_weighted_sparse_categorical_crossentropy: 3.0315\n",
      "Epoch 4/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 59ms/step - accuracy: 0.8998 - loss: 0.2247 - sparse_categorical_crossentropy: 0.4688 - weighted_accuracy: 0.8998 - weighted_sparse_categorical_crossentropy: 0.4688 - val_accuracy: 0.6673 - val_loss: 0.9526 - val_sparse_categorical_crossentropy: 2.8084 - val_weighted_accuracy: 0.6673 - val_weighted_sparse_categorical_crossentropy: 2.8084\n",
      "Epoch 5/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 59ms/step - accuracy: 0.9118 - loss: 0.1524 - sparse_categorical_crossentropy: 0.2014 - weighted_accuracy: 0.9118 - weighted_sparse_categorical_crossentropy: 0.2014 - val_accuracy: 0.6692 - val_loss: 1.2264 - val_sparse_categorical_crossentropy: 3.0559 - val_weighted_accuracy: 0.6692 - val_weighted_sparse_categorical_crossentropy: 3.0559\n",
      "Epoch 6/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 61ms/step - accuracy: 0.9309 - loss: 0.1249 - sparse_categorical_crossentropy: 0.1331 - weighted_accuracy: 0.9309 - weighted_sparse_categorical_crossentropy: 0.1331 - val_accuracy: 0.6293 - val_loss: 1.3732 - val_sparse_categorical_crossentropy: 3.1165 - val_weighted_accuracy: 0.6293 - val_weighted_sparse_categorical_crossentropy: 3.1165\n",
      "Epoch 7/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 61ms/step - accuracy: 0.9195 - loss: 0.1467 - sparse_categorical_crossentropy: 0.2054 - weighted_accuracy: 0.9195 - weighted_sparse_categorical_crossentropy: 0.2054 - val_accuracy: 0.6540 - val_loss: 1.4039 - val_sparse_categorical_crossentropy: 3.5511 - val_weighted_accuracy: 0.6540 - val_weighted_sparse_categorical_crossentropy: 3.5511\n",
      "Epoch 8/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 62ms/step - accuracy: 0.9271 - loss: 0.1171 - sparse_categorical_crossentropy: 0.1327 - weighted_accuracy: 0.9271 - weighted_sparse_categorical_crossentropy: 0.1327 - val_accuracy: 0.6825 - val_loss: 1.3149 - val_sparse_categorical_crossentropy: 2.8828 - val_weighted_accuracy: 0.6825 - val_weighted_sparse_categorical_crossentropy: 2.8828\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step\n"
     ]
    }
   ],
   "source": [
    "model = best()\n",
    "adapt_and_compile(model, X)\n",
    "model.fit(X,\n",
    "          y,\n",
    "          validation_split=TEST_SPLIT,\n",
    "          epochs=50,\n",
    "          batch_size=100,\n",
    "          callbacks=[\n",
    "              callbacks.EarlyStopping(patience=5, restore_best_weights=True)\n",
    "          ])\n",
    "\n",
    "y_pred = predict(model, X_test)\n",
    "restab[\"lstm2\"] = custom_summary(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "4709b696-8b0c-4d1c-ba20-1c18c8a42f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = LogisticRegression(n_jobs=-1, max_iter=200, solver=\"newton-cg\")\n",
    "vectorizer = TfidfVectorizer(max_features=2048, tokenizer=LemmaTokenizer(), token_pattern=None)\n",
    "\n",
    "model = Pipeline([\n",
    "    (\"vectorizer\", vectorizer),\n",
    "    (\"classifier\", classifier),\n",
    "])\n",
    "\n",
    "model.fit(X, y)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "restab[\"logistic\"] = custom_summary(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "a32067d7-650f-45a1-b879-a7f1ee1d341d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Pipeline([\n",
    "    ('vectorizer', vectorizer),\n",
    "    ('classifier', MultinomialNB(alpha=0.5))\n",
    "])\n",
    "\n",
    "model.fit(X, y)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "restab[\"multi_nb\"] = custom_summary(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "2876d3a3-49d2-48d0-b92f-6ac785c2c135",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_fd09b_row0_col1, #T_fd09b_row0_col2, #T_fd09b_row0_col3, #T_fd09b_row0_col4, #T_fd09b_row0_col5, #T_fd09b_row2_col0 {\n",
       "  background-color: green;\n",
       "}\n",
       "#T_fd09b_row3_col0, #T_fd09b_row3_col1, #T_fd09b_row3_col2, #T_fd09b_row3_col3, #T_fd09b_row3_col4, #T_fd09b_row3_col5 {\n",
       "  background-color: red;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_fd09b\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_fd09b_level0_col0\" class=\"col_heading level0 col0\" >accuracy</th>\n",
       "      <th id=\"T_fd09b_level0_col1\" class=\"col_heading level0 col1\" >balanced_accuracy</th>\n",
       "      <th id=\"T_fd09b_level0_col2\" class=\"col_heading level0 col2\" >f1_macro</th>\n",
       "      <th id=\"T_fd09b_level0_col3\" class=\"col_heading level0 col3\" >f1_weighted</th>\n",
       "      <th id=\"T_fd09b_level0_col4\" class=\"col_heading level0 col4\" >precision_weighted</th>\n",
       "      <th id=\"T_fd09b_level0_col5\" class=\"col_heading level0 col5\" >cohen_kappa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_fd09b_level0_row0\" class=\"row_heading level0 row0\" >pretrained_embed_lstm</th>\n",
       "      <td id=\"T_fd09b_row0_col0\" class=\"data row0 col0\" >0.705983</td>\n",
       "      <td id=\"T_fd09b_row0_col1\" class=\"data row0 col1\" >0.660225</td>\n",
       "      <td id=\"T_fd09b_row0_col2\" class=\"data row0 col2\" >0.656909</td>\n",
       "      <td id=\"T_fd09b_row0_col3\" class=\"data row0 col3\" >0.707352</td>\n",
       "      <td id=\"T_fd09b_row0_col4\" class=\"data row0 col4\" >0.708962</td>\n",
       "      <td id=\"T_fd09b_row0_col5\" class=\"data row0 col5\" >0.515659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_fd09b_level0_row1\" class=\"row_heading level0 row1\" >lstm2</th>\n",
       "      <td id=\"T_fd09b_row1_col0\" class=\"data row1 col0\" >0.690598</td>\n",
       "      <td id=\"T_fd09b_row1_col1\" class=\"data row1 col1\" >0.614824</td>\n",
       "      <td id=\"T_fd09b_row1_col2\" class=\"data row1 col2\" >0.615526</td>\n",
       "      <td id=\"T_fd09b_row1_col3\" class=\"data row1 col3\" >0.690833</td>\n",
       "      <td id=\"T_fd09b_row1_col4\" class=\"data row1 col4\" >0.691145</td>\n",
       "      <td id=\"T_fd09b_row1_col5\" class=\"data row1 col5\" >0.472087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_fd09b_level0_row2\" class=\"row_heading level0 row2\" >logistic</th>\n",
       "      <td id=\"T_fd09b_row2_col0\" class=\"data row2 col0\" >0.707692</td>\n",
       "      <td id=\"T_fd09b_row2_col1\" class=\"data row2 col1\" >0.595085</td>\n",
       "      <td id=\"T_fd09b_row2_col2\" class=\"data row2 col2\" >0.605717</td>\n",
       "      <td id=\"T_fd09b_row2_col3\" class=\"data row2 col3\" >0.695234</td>\n",
       "      <td id=\"T_fd09b_row2_col4\" class=\"data row2 col4\" >0.693474</td>\n",
       "      <td id=\"T_fd09b_row2_col5\" class=\"data row2 col5\" >0.478399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_fd09b_level0_row3\" class=\"row_heading level0 row3\" >multi_nb</th>\n",
       "      <td id=\"T_fd09b_row3_col0\" class=\"data row3 col0\" >0.683761</td>\n",
       "      <td id=\"T_fd09b_row3_col1\" class=\"data row3 col1\" >0.564276</td>\n",
       "      <td id=\"T_fd09b_row3_col2\" class=\"data row3 col2\" >0.576070</td>\n",
       "      <td id=\"T_fd09b_row3_col3\" class=\"data row3 col3\" >0.666134</td>\n",
       "      <td id=\"T_fd09b_row3_col4\" class=\"data row3 col4\" >0.667053</td>\n",
       "      <td id=\"T_fd09b_row3_col5\" class=\"data row3 col5\" >0.408838</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7897646f0e60>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(restab).T.style.highlight_max(color=\"green\", axis=0).highlight_min(color=\"red\", axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0159c069-ba3d-42f5-b36a-528aab11cc67",
   "metadata": {},
   "source": [
    "Where are the medals?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
